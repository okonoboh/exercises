Let $R$ be a ring with 1.
\begin{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.1%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.1]   Show that $(-1)^2 = 1$ in $R$.

      \textbf{Proof.} We have
      \begin{align*}
         (-1)^2 &= (-1)(-1) \\
                &= 1 \cdot 1 &[\text{Proposition }7.1 (3)] \\
                &= 1.        &[1 \text{ is the multiplicative identity}]
      \end{align*} \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.2%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.2]   Prove that if $u$ is a unit in $R$ then so is $-u$.

      \textbf{Proof.} Suppose that $u \in R$ is a unit. Let $v$ be the 
      multiplicative inverse of $u$. Since
      \begin{align*}
         (-v)(-u) &= vu          &[\text{Proposition }7.1 (3)] \\
                  &= 1           &[\text{By definition}] \\
                  &= uv          &[\text{By definition}] \\
                  &= (-u)(-v),   &[\text{Proposition }7.1 (3)]
      \end{align*}
      it follows that $-v$ is the multiplicative inverse of $-u$, so that $-u$
      is a unit in $R$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.3%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.3]   Let $R$ be a ring with identity and let $S$ be a subring of
                  $R$ containing the identity. Prove that if $u$ is a unit in
                  $S$ then $u$ is a unit in $R$. Show by example that the
                  converse is false.

      \textbf{Proof.} Let $1_R$ be the identity of $R$. Let $1_S$ be an identity
      in $S$ (we were given that $1_R \in S$, so $S$ contains at least one
      identity). But $1_R \cdot 1_S = 1_S$ because $1_R$ is the identity in
      $R$; also $1_R = 1_R \cdot 1_S$ because $1_S$ is an identity in $S$. Thus
      $1_R = 1_R \cdot 1_S = 1_S$. Now suppose that $u \in S$ is a unit. Then
      there exist $v \in S$ such that
      $$1_R = 1_S = uv = vu.$$
      Since $v \in S$ and $S \subseteq R$, it follows that $v \in R$. Thus the
      equalities above say that $u$ is also a unit in $R$.

      \textbf{Converse.} Let $R = \Q$ and $S = \Z$. The integer 2 is a unit in
      $\Q$ but not a unit in $\Z$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.4%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.4]   Prove that the intersecton of any nonempty collection of
                  subrings of a ring is also a subring.

      \textbf{Proof.} Let $R$ be a ring, $I$ a nonempty set, and
      $$S = \bigcap_{i \in I} R_i,$$
      where $R_i$ a subring of $R$ for each $i \in I$. We want to show that $S$
      is a subring of $R$.

      (\textit{S is a subgroup of R}.) Since $R_i$ is a subring
      of $R$, it follows that $R_i$ is a subgroup of $R$, for each $i \in I$. 
      Thus $S$ is a subgroup of $R$ by Exercise 2.1.10(b).

      (\textit{S is closed under multiplication}.) The set $S$ contains 0---so
      that it is nonempty---because each $R_i$ contains 0. So let $a$,
      $b \in S$. That is, $a, b \in R_i$ for all $i \in I$. Since each $R_i$ is
      a subring, it is closed under multiplication; thus, $ab \in R_i$ for each
      $i \in I$, so that $ab \in S$, and we conclude that $S$ is closed under
      multiplication.

      Now since $S$ is a subgroup of $R$ and is closed under multiplication, it
      follows by definition that $S$ is a subring of $R$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.5%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.5]   Decide which of the following (a)$-$(f) are subrings of $\Q$:
                  \begin{enumerate}
                     \item the set of all rational numbers with odd denominators
                           (when written in lowest terms)
                     \item the set of all rational numbers with even
                           denominators (when written in lowest terms)
                     \item the set of nonnegative rational numbers
                     \item the set of squares of rational numbers
                     \item the set of all rational numbers with odd numerators
                           (when written in lowest terms)
                     \item the set of all rational numbers with even numerators
                           (when written in lowest terms)
                  \end{enumerate}

      \textbf{Solution.} For convenience, denote each of the sets above as $S$.

      \begin{enumerate}
         \item We claim that $S$ is subring of $\Q$.

               \textbf{Proof.}

               (\textit{S is a subgroup of $\Q$}.) This follows from Exercise
               1.1.6(a). \\

               (\textit{S is closed under multiplication}.) Let $q_1$,
               $q_2 \in S$. Then there exist odd integers $s_1$ and $s_2$ and 
               integers $r_1$ and $r_2$, with
               $\gcd(r_1, s_1) = \gcd(r_2, s_2) = 1$ such that
               $$q_1 = \frac{r_1}{s_1} \text{ and } q_2 = \frac{r_2}{s_2}.$$
               So $q_1q_2 = \frac{r_1r_2}{s_1s_2}$. The integer $s_1s_2$ is odd
               because $s_1$ and $s_2$ are both odd. Hence, $s_1s_2$ has no
               factor of 2, so that, in lowest terms, the denominator of
               $q_1q_2$ will also be odd. That is, $q_1q_2 \in S$, so that $S$
               is closed under multiplication.
            
               Since $S$ is a subgroup of $\Q$ and is closed under
               multiplication, it follows by definition that $S$ is a subring of 
               $\Q$. \qed
         \item $S$ is not a subring of $\Q$ because it is not closed under
               addition. For example, we have $\frac{3}{2}, \frac{5}{2} \in S$,
               but their sum $\frac{4}{1} \notin S$.
         \item $S$ is not a subring of $\Q$ because it is not closed under
               additive inverses. For example $2 \in S$, but $-2 \notin S$.
         \item $S$ is not a subring of $\Q$ because it is not closed under
               addition. For example, we have $\frac{1}{9} \in S$, but
               $\frac{1}{9} + \frac{1}{9} = \frac{2}{9} \notin S$ because 2 is
               not a perfect square.
         \item $S$ is not a subring of $\Q$ because it does not contain 0.
         \item We claim that $S$ is subring of $\Q$.

               \textbf{Proof.} $S$ is nonempty because it contains $0/1$. So let
               $q_1$, $q_2 \in S$. Then there exist even integers $r_1$ and
               $r_2$ and nonzero integers $s_1$ and $s_2$, with
               $\gcd(r_1, s_1) = \gcd(r_2, s_2) = 1$ such that
               $$q_1 = \frac{r_1}{s_1} \text{ and } q_2 = \frac{r_2}{s_2}.$$
               Since $q_1$ and $q_2$ are in lowest terms, it follows that $s_1$
               and $s_2$ must be odd. 

               (\textit{S is a subgroup of $\Q$}.) Now
               $$q_1 - q_2 = \frac{r_1s_2 - r_2s_1}{s_1s_2}.$$
               Now $r_1s_2$ and $r_2s_1$ are both even so that $r_1s_2 - r_2s_1$
               is also even. Since $s_1s_2$ is odd, it has no factors of 2, so
               that the lowest term of $q_1 - q_2$ still has an even numerator.
               Hence, $q_1 - q_2 \in S$ so that $S$ is a subgroup of $\Q$ by the
               Subgroup Criterion. \\

               (\textit{S is closed under multiplication}.) We have that
               $q_1q_2 = \frac{r_1r_2}{s_1s_2}$, wherein $r_1r_2$ is even and
               $s_1s_2$ is odd, so that $s_1s_2$ has no factors of 2; hence, in
               lowest terms, the numerator of $q_1q_2$ will still have at least
               one factor of 2. That is, $q_1q_2 \in S$, so that $S$ is closed
               under multiplication.
            
               Since $S$ is a subgroup of $\Q$ and is closed under
               multiplication, it follows by definition that $S$ is a subring of 
               $\Q$. \qed
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.6%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.6]   Decide which of the following are subrings of the ring of all
                  functions from the closed interval $[0,1]$ to $\R$.
                  \begin{enumerate}
                     \item the set of all functions $f(x)$ such that $f(q) = 0$
                           for all $q \in \Q \cap [0, 1]$.
                     \item the set of all polynomial functions
                     \item the set of all functions which have only a finite
                           number of zeros, together with the zero function
                     \item the set of all functions which have an infinite
                           number of zeros
                     \item the set of all functions $f$ such that
                           $\lim_{x\rightarrow1^-}f(x) = 0$
                     \item the set of all rational linear combinations of the
                           functions $\sin nx$ and $\cos mx$, where
                           $m, n \in \{0, 1, 2, \ldots \}$.
                  \end{enumerate}

      \textbf{Solution.} For convenience, denote each of the sets above as $S$. 
      Let $F = \{\text{functions from } [0, 1] \text{ to } \R\}$.

      \begin{enumerate}
         \item We claim that $S$ is subring of $F$.

               \textbf{Proof.}

               (\textit{S is a subgroup of $F$}.) The additive identity of $F$
               is the zero function, 0. Also, $0 \in S$, so that $S$ is
               nonempty. So let $f, g \in S$. That is, $f(q) = g(q) = 0$ for 
               every rational number $q \in [0, 1]$.
               Thus $f(q) - g(q) = 0 - 0 = 0$ for every rational number
               $q \in [0, 1]$, so that $f - g \in S$. It follows by the Subgroup 
               Criterion that $S \le F$. \\

               (\textit{S is closed under multiplication}.) Similarly
               $f(q)g(q) = 0\cdot0 = 0$ for each $q \in [0, 1] \cap \Q$, so that
               $fg \in S$. Thus $S$ is closed under multiplication.
            
               Since $S$ is a subgroup of $F$ and is closed under
               multiplication, it follows by definition that $S$ is a subring of 
               $F$. \qed
         \item We claim that $S$ is subring of $F$.

               \textbf{Proof.}

               (\textit{S is a subgroup of $F$}.) The set $S$ is nonempty
               because it contains 0, the zero polynomial. So let $f, g \in S$. 
               Since $f$ and $g$ are polynomials, it follows that $f - g$ is 
               also a polynomial, so that $f - g \in S$. It follows by the 
               Subgroup Criterion that $S \le F$. \\

               (\textit{S is closed under multiplication}.) Similarly
               $fg \in S$ because the product of two polynomials is also a
               polynomial. Thus $S$ is closed under multiplication.
            
               Since $S$ is a subgroup of $F$ and is closed under
               multiplication, it follows by definition that $S$ is a subring of 
               $F$. \qed
         \item $S$ is not a subring of $F$ because it is not closed under
               addition. For example, let $i$ be the identity function on
               $[0, 1]$. The function $i$ has a single zero, namely at 0, so
               $i \in S$. Now let $g(x) = -x$ for every $x \in (0, 1]$ and
               $g(0) = 3$. The function $g$ has no zero so $g \in S$. But
               $g + i$ is not the zero function and $g + i$ has an infinite   
               number of zeros because $(g + i)(x) = 0$ for every
               $x \in (0, 1]$. Thus $S$ is not closed under addition.
         \item $S$ is not a subring of $F$ because it is not closed under
               addition. For example, consider the functions
               \begin{equation*}
                  g(x) = \left\{
                     \begin{array}{rl}
                        1 & \text{if } x \in [0, 1] \cap \Q,\\
                        0 & \text{if } x \in [0, 1] \cap (\R - \Q)
                     \end{array} \right.
               \end{equation*}
               and
               \begin{equation*}
                  h(x) = \left\{
                     \begin{array}{rl}
                        0 & \text{if } x \in [0, 1] \cap \Q,\\
                        1 & \text{if } x \in [0, 1] \cap (\R - \Q)
                     \end{array} \right.
               \end{equation*}
               Since there are an infinite number of rational and irrational
               numbers in $[0, 1]$, it follows that each of $g$ and $h$ has an
               infinite number of zeros. Now let $x$ be a rational number in
               $[0, 1]$, then we have that $(g + h)(x) = g(x) + h(x) = 1$; if
               $x$ were irrational, then we would have
               $(g + h)(x) = g(x) + h(x) = 1$, so that $g + h$ has no zeroes in
               $[0, 1]$; that is, $g + h \notin S$, so that $S$ is not closed
               under addition.
         \item We claim that $S$ is a subring of $F$.

               \textbf{Proof.}

               (\textit{S is a subgroup of $F$}.) We have that
               $\lim_{x\rightarrow1^-}0 = 0$, so that the zero function is in
               $S$. So let $f, g \in S$. Since the limit of a difference is the
               difference of the limits (if they exist), we have that
               $$\lim_{x\rightarrow1^-}(f(x) - g(x)) =
                 \lim_{x\rightarrow1^-}f(x) - \lim_{x\rightarrow1^-}g(x) =
                  0 - 0 = 0,$$
               so that $f - g \in S$. It follows by the Subgroup Criterion that 
               $S \le F$. \\

               (\textit{S is closed under multiplication}.) Similarly the limit 
               of a product is the product of the limits (if they exist), so
               $$\lim_{x\rightarrow1^-}f(x)g(x) =
                 \lim_{x\rightarrow1^-}f(x)\lim_{x\rightarrow1^-}g(x) =
                  0 \cdot 0 = 0,$$
               so that $fg \in S$. Thus $S$ is closed under multiplication.
            
               Since $S$ is a subgroup of $F$ and is closed under
               multiplication, it follows by definition that $S$ is a subring of 
               $F$. \qed
         \item Let $S' = \{\sin (ax) \text{ or } \cos (ax) : a \in \Z^{\ge 0}\}$ 
               and $S = \text{span}(S')$, where scalars are chosen from $\Q$. We 
               claim that $S$ is subring of $F$.

               \textbf{Proof.} 

               (\textit{S is a subgroup of $F$}.) The set $S$ is nonempty 
               because it contains the zero function (choose all the scalars to 
               be 0). So let $f$, $g \in S$. Then there exist positive integers 
               $n$ and $m$, rational scalars $r_1$, $\ldots$, $r_n$, $s_1$,
               $\ldots$, $s_m$, functions $f_1$, $\ldots$, $f_n$, $g_1$,
               $\ldots$, $g_m \in S'$ such that
               $$f = \sum_{i=1}^n r_if_i \text{ and }g = \sum_{i=1}^m s_ig_i.$$
               Let $r_{n+i} = -s_i$ and $f_{n+i} = g_i$, $1 \le i \le m$. Thus
               $$f - g = \sum_{i=1}^{n+m} r_if_i \in S$$
               because $f - g$ is a rational linear combination of $n + m$
               elements of $S'$. It follows by the Subgroup Criterion that
               $S \le F$. \\

               (\textit{S is closed under multiplication}.) The function $fg$ is 
               a sum of functions of the form $qf'g'$ where $q$ is a rational
               number and $f', g' \in S'$. So there exist nonnegative integers
               $a$ and $b$ such that exactly one of the following holds:

               \textbf{Case 1.} $f' = \cos (ax)$ and $g' = \cos (bx)$. So
               $$qf'g' = q\cos (ax) \cos (bx) = \frac{q}{2}\cos[(a+b)x] +
                 \frac{q}{2}\cos[(a-b)x] \in S$$
               because $\cos[(a+b)x], \cos[(a-b)x] \in S'$.

               \textbf{Case 2.} $f' = \sin (ax)$ and $g' = \sin (bx)$. So
               $$qf'g' = q\sin (ax) \sin (bx) =
                 \frac{q}{2}\cos[(a-b)x] - \frac{q}{2}
                 \cos[(a+b)x] \in S$$
               because $\cos[(a+b)x], \cos[(a-b)x] \in S'$.

               \textbf{Case 3.} $f' = \sin (ax)$ and $g' = \cos (bx)$. So
               $$qf'g' = q\sin (ax) \cos (bx) =
                 \frac{q}{2}\sin[(a+b)x] + \frac{q}{2}
                 \sin[(a-b)x] \in S$$
               because $\sin[(a+b)x], \sin[(a-b)x] \in S'$.

               \textbf{Case 4.} $f' = \cos (ax)$ and $g' = \sin (bx)$.
               Interchange the roles of $g'$ and $f'$ in Case 3 to conclude that
               $qf'g' \in S$.


               Thus every every term in the sum of $fg$ is in $S$. Since $S$ is
               closed under addition, it follows that $fg \in S$. Hence since
               $S$ is a subgroup of $F$ and is closed under multiplication, it 
               follows by definition that $S$ is a subring of $F$. \qed

               \textbf{Note.} We used the following trigonometry identities in
               the cases above:
               \begin{align*}
                  \cos(x)\cos(y) &= \frac{1}{2}\cos(x+y)+\frac{1}{2}\cos(x-y) \\
                  \sin(x)\sin(y) &= \frac{1}{2}\cos(x-y)-\frac{1}{2}\cos(x+y) \\
                  \sin(x)\cos(y) &= \frac{1}{2}\sin(x+y)+\frac{1}{2}\sin(x-y).
               \end{align*}
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.7%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.7]   The \textit{center} of a ring $R$ is
                  $\{z \in R : zr = rz \text{ for all } r \in R\}$ (i.e., is the
                  set of all elements which commute with every element of $R$).
                  Prove that the center of a ring is a subring that contains the
                  identity. Prove that the center of a division ring is a field.

      \textbf{Proof.} Denote the center of $R$ by $Z_R$. Since $1 \in R$, it
      follows that $1 \in Z_R$ since the identity commutes with every element by
      definition, so let $a, b \in Z_R$ and $r \in R$.

      (\textit{$Z_R$ is a subgroup of $R$}.) We have
      \begin{align*}
         (a - b)r &= ar - br \\
                  &= ra - rb &[a, b \in Z_R] \\
                  &= r(a - b),
      \end{align*}
      so that $a - b$ commutes with every element of $R$. Thus $a - b \in Z_R$.
      It follows by the Subgroup Criterion that $Z_R \le R$.

      (\textit{$Z_R$ is closed under multiplication}.) We have
      \begin{align*}
         (ab)r &= a(br) &[\text{Associativity}] \\
               &= a(rb) &[b \in Z_R] \\
               &= (ar)b &[\text{Associativity}] \\
               &= (ra)b &[a \in Z_R] \\
               &= r(ab), &[\text{Associativity}]
      \end{align*}
      so that $ab$ commutes with every element of $R$. Thus $ab \in Z_R$. Since
      $Z_R$ is a subgroup of $R$ and is closed under multiplication, it follows
      by definition that $Z_R$ is a subring of $R$.

      (\textit{$Z_R$ is a field if $R$ is a division ring}.) Now suppose that
      $R$ is a division ring. By definiton $Z_R$ is commutative, so it suffices 
      to show that every nonzero element of $Z_R$ is a unit. To that end, let
      $u$ be a nonzero element in $Z_R$. Since $R$ is a division ring, there 
      exists $v \in R$ such that $uv = vu = 1$. Thus
      \begin{align*}
         vr &= vr \cdot 1 \\
            & = vr (uv) \\
            &= v(ru)v \\
            &= v(ur)v &[u \in Z_R] \\
            &= (vu)rv \\
            &= 1 \cdot rv = rv,
      \end{align*}
      so that $v \in Z_R$. Thus $Z_R$ is a commutative division ring; that is,
      $Z_R$ is a field. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.8%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.8]   Describe the center of the real Hamilton Quaternions
                  $\mathbb{H}$. Prove that $\{a + bi : a, b \in \R\}$ is a
                  subring of $\mathbb{H}$ which is a field but is not contained
                  in the center of $\mathbb{H}$.

      \textbf{Proof.} Let $Z_\mathbb{H}$ be the center of $\mathbb{H}$. The set
      $Z_\mathbb{H}$ is nonempty because it contains 1. Let
      $r \in Z_\mathbb{H}$. Then $r = a + bi + cj + dk$ for some real numbers
      $a$, $b$, $c$, and $d$. Since $r$ commutes with all the elements of
      $\mathbb{H}$, it follows particularly that $ri = ir$; this implies that
      $$ai - b - ck + dj = ai - b + ck - dj,$$
      so that $2ck = 2dj$, and we conclude that $c = d = 0$. Thus $r = a + bi$.
      Now we must also have that $rj = jr$; that is $aj + bk = aj - bk$, so that
      $2bk = 0$, and we conclude that $b = 0$. It is clear that every real
      number commutes with $\mathbb{H}$. Thus $Z_\mathbb{H} = \R$. The set
      $\{a + bi : a, b \in \R\}$ is the set of complex number which is a field.
      Since $\C \subset \mathbb{H}$, it follows that $\C$ is a subring of
      $\mathbb{H}$. The set $\C$ is not contained in $\R = Z_\mathbb{H}$ since 
      the latter is a proper subset of the former. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.9%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.9]   For a fixed element $a \in R$ define
                  $C(a) = \{r \in R : ra = ar\}$. Prove that $C(a)$ is a subring
                  of $R$ containing $a$. Prove that the center of $R$ is the
                  intersection of the subrings $C(a)$ over all $a \in R$.

      \textbf{Proof.} Let $Z_R$ denote the center of $R$. Fix $a \in R$. Since 
      $aa = aa$, it follows that $a \in C(a)$, so let $c, d \in C(a)$.

      (\textit{$C(a)$ is a subgroup of $R$}.) We have
      \begin{align*}
         (c - d)a &= ca - da \\
                  &= ac - ad &[c, d \in C(a)] \\
                  &= a(c - d),
      \end{align*}
      so that $c - d \in C(a)$ and we conclude by the Subgroup Criterion that
      $C(a) \le R$. \\

      (\textit{$C(a)$ is closed under multiplication}.) We have
      \begin{align*}
         (cd)a &= c(da) &[\text{Associativity}] \\
               &= c(ad) &[d \in C(a)] \\
               &= (ca)d &[\text{Associativity}] \\
               &= (ac)d &[d \in C(a)] \\
               &= a(cd), &[\text{Associativity}]
      \end{align*}
      so that $cd \in C(a)$; i.e., $C(a)$ is closed under multiplication. \\

      Since $C(a) \le R$ and is closed under multiplication, it follows by 
      definition that $C(a)$ is a subring of $R$. \\

      Now we want to show that $Z_R = \bigcap_{r \in R}C(r)$.

      ($\subseteq$) Let $s \in Z_R$ (the center is nonempty because it contains 
      1) and $b \in R$. Then it follows by definition that $sb = bs$, so that
      $s \in C(b)$. That is, $r \in C(b)$ for every $b \in R$, so that
      $s \in \bigcap_{r \in R}C(r)$. Thus $Z_R \subseteq \bigcap_{r \in R}C(r)$.

      ($\supseteq$) Let $s \in \bigcap_{r \in R}C(r)$ and $t \in R$. Since
      $s \in \bigcap_{r \in R}C(r)$, it follows particularly that $s \in C(t)$,
      so that $st = ts$; i.e., $s$ commutes with every member of $R$ and we have
      that $s \in Z_R$, so that $Z_R \supseteq \bigcap_{r \in R}C(r)$.

      Conclude that $Z_R = \bigcap_{r \in R}C(r)$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.10%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.10]  Prove that if $D$ is a division ring then $C(a)$ is a division
                  ring for all $a \in D$ (cf. the preceding exercise).

      \textbf{Proof.} Suppose that $D$ is a division ring. Let $a \in D$. By
      Exercise 7.1.9 $C(a)$ is a subring of $D$, so it suffices to show that
      every nonzero element in $C(a)$ is a unit. So let $u$ be a nonzero element 
      in $C(a)$ ($1 \in C(a)$, so that $C(a)$ has a nonzero element). Since $D$ 
      is a division ring and $u$ is also in $D$, there exists $v \in D$ such 
      that $uv = vu = 1$. So
      \begin{align*}
         va &= va \cdot 1 \\
            &= va(uv) \\
            &= v(au)v \\
            &= v(ua)v &[u \in C(a)] \\
            &= (vu)(av) = 1 \cdot av = av,
      \end{align*}
      so that $v \in C(a)$. That is, $C(a)$ is a division ring.\qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.11%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.11]  Prove that if $R$ is an integral domain and $x^2 = 1$ for some
                  $x \in R$ then $x = \pm1$.

      \textbf{Proof.} Let $R$ be an integral domain. Suppose that $x^2 = 1$ for
      some $x \in R$. Then it follows that $x^2 - 1 = 0$; that is,
      $(x + 1)(x - 1) = 0$. Since $R$ is an integral domain, we have that
      $x + 1 = 0$ or $x - 1 = 0$, so that $x = \pm1$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.12%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.12]  Prove that any subring of a field which contains the identity
                  is an integral domain.

      \textbf{Proof.} Let $F$ be a field and suppose that $H$ is a subring of
      $F$ that contains the identity. Suppose that $gh = 0$ for some
      $g, h \in H$. If neither $g$ nor $h$ is zero, then $g$ and $h$ are zero
      divisors in $H$; in particular, they are zero divisors in $F$, a
      contradiction, since $F$ is an integral domain. Thus at least one of $g$
      and $h$ is zero, so that $H$ is also an integral domain. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.13%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.13]  An element $x$ in $R$ is called \textit{nilpotent} if
                  $x^m = 0$ for some $m \in \Z^+$.
                  \begin{enumerate}
                     \item Show that if $n = a^kb$ for some integers $a$ and $b$
                           then $\overline{ab}$ is a nilpotent element of
                           $\Z/n\Z$.
                     \item If $a \in \Z$ is an integer, show that the element
                           $\overline{a} \in \Z/n\Z$ is nilpotent if and only if
                           every prime divisor of $n$ is also a divisor of $a$.
                           In particular, determine the nilpotent elements of
                           $\Z/72\Z$ explicitly.
                     \item Let $R$ be the ring of functions from a nonempty set
                           $X$ to a field $F$. Prove that $R$ contains no
                           nonzero nilpotent elements.
                  \end{enumerate}

      \textbf{Solution.}

      \begin{enumerate}
         \item \textbf{Proof.} Suppose $n = a^kb$, where $a$ and $b$ are
               integers and $k$ is a nonnegative integer. Let $\overline{x}$
               denote the coset $x + n\Z$. Since
               \begin{align*}
                  \overline{ab}^{k+1} &= \overline{(ab)^{k+1}} \\
                     &= \overline{a^kbab^k} \\
                     &= \overline{a^kb} \cdot \overline{ab^k} \\
                     &= \overline{0} \cdot \overline{ab^k} = \overline{0}
               \end{align*}
               and $k + 1 \in \Z^+$, it follows that $\overline{ab}$ is a
               nilpotent element of $\Z/n\Z$. \qed
         \item \textbf{Proof.} Let $a \in \Z$.

               $(\Rightarrow)$ Suppose $\overline{a} \in \Z/n\Z$ is nilpotent.
               That is, there exists $k \in \Z^+$ such that
               $\overline{a}^k = \overline{0}$. Thus $a^k = nt$ for some integer
               $t$. Suppose that some prime $p$ divides $n$. Then since
               $a^k = nt$, it follows that $p$ divides $a^k$, so that $p$ is a
               prime factor of $a^k$; but the prime factors of $a^k$ are exactly
               the prime factors of $a$, so $p \mid a$.

               $(\Leftarrow)$ Suppose that every prime divisor of $n$ divides
               $a$. Let
               $${p_1}^{e_1}{p_2}^{e_2}\cdots {p_m}^{e_m}$$
               be the prime factorization of $n$, where each $p_i$ is a distinct
               prime and each $e_i$ is a positive integer. By hypothesis, each
               $p_i$ divides $a$. So there exists some integer $t$ such that
               $$a = t \cdot {p_1}^{d_1}{p_2}^{d_2}\cdots {p_m}^{d_m},$$
               where each $d_i$ is a positive integer and $\gcd(t, p_i) = 1$.
               Let $k$ be the minimum positive integer such that
               $d_ik - e_i \ge 0$ for every $i = 1, 2, \ldots m$. So it follows
               that
               \begin{align*}
                  \overline{a}^k &= \overline{a^k} \\
                     &= \overline{t^k{p_1}^{d_1k}{p_2}^{d_2k}\cdots
                        {p_m}^{d_mk}} \\
                     &= \overline{t^k} \cdot
                        \overline{{p_1}^{d_1k-e_1}{p_2}^{d_2k-e_2}\cdots
                        {p_m}^{d_mk-e_m}} \cdot
                        \overline{{p_1}^{e_1}{p_2}^{e_2}\cdots {p_m}^{e_m}} \\
                     &= \overline{t^k} \cdot
                        \overline{{p_1}^{d_1k-e_1}{p_2}^{d_2k-e_2}\cdots
                        {p_m}^{d_mk-e_m}} \cdot \overline{n} \\
                     &= \overline{t^k} \cdot
                        \overline{{p_1}^{d_1k-e_1}{p_2}^{d_2k-e_2}\cdots
                        {p_m}^{d_mk-e_m}} \cdot \overline{0} = \overline{0}.
               \end{align*}
               That is, $\overline{a} \in \Z/n\Z$ is nilpotent. \qed

               (\textit{The nilpotents of $\Z/72\Z$}.)The only primes dividing
               72 are 2 and 3, so the nilpotent elements of $\Z/72\Z$ are
               $\overline{0}$, $\overline{6}$, $\overline{12}$, $\overline{18}$, 
               $\overline{24}$, $\overline{30}$, $\overline{36}$,
               $\overline{42}$, $\overline{48}$, $\overline{54}$,
               $\overline{60}$, and $\overline{66}$.
         \item \textbf{Proof.} Let $f$ be a nonzero function in $R$. Thus, there
               exists $x \in R$ such that $f(x) \neq 0$. We want to show that
               $(f(x))^n \neq 0$ for all $n \in \Z^+$, so we will proceed by 
               induction on $n$. The base case ($n = 1$) trivially holds. Now 
               suppose that $(f(x))^k\neq 0$ for some positive integer $k$. Thus
               $(f(x))^{k+1} = (f(x))^k\cdot f(x) \neq 0$
               because $(f(x))^k$ and $f(x)$ are nonzero elements of the 
               integral domain $F$. Thus it follows by induction that
               $(f(x))^n \neq 0$ (so that $f^n \neq 0$) for all $n \in \Z^+$;
               in other words, $f$ cannot be nilpotent, and the proof is done. 
               \qed
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.14%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.14]  Let $x$ be a nilpotent element of the commutative ring $R$
                  (cf. the preceding exercise).
                  \begin{enumerate}
                     \item Prove that $x$ is either zero or a zero divisor.
                     \item Prove that $rx$ is nilpotent for all $r \in R$.
                     \item Prove that $1 + x$ is a unit in $R$.
                     \item Deduce that the sum of a nilpotent element and a unit
                           is a unit.
                  \end{enumerate}

      \textbf{Proof.} Let $k$ be the minimum positive integer such that
      $x^k = 0$.

      \begin{enumerate}
         \item If $x$ is 0, we are done, so assume that $x \neq 0$. Now $k > 1$ 
               because $x^1 \neq 0$ by assumption. So $x^k = x^{k-1} \cdot x$. 
               By minimality of $k$, it follows that $x^{k-1} \neq 0$. Thus the 
               product of two nonzero elements of $R$, namely $x^{k-1}$ and $x$, 
               is zero, so that $x$ is a zero divisor.
         \item Let $r \in R$. So $(rx)^k = r^kx^k = r^k \cdot 0 = 0$; i.e., $rx$
               is a zero divisor for all $r \in R$.
         \item For a nonnegative integer $n$, consider the identity
               $$(1+x)(1-x+x^2-x^3+\cdots+(-1)^nx^n) = 1 - (-1)^{n+1}x^{n+1}.$$
               Thus
               \begin{align*}
                  (1+x)(1-x+x^2-x^3+\cdots+(-1)^{k-1}x^{k-1}) &= 1 - (-1)^kx^k\\
                     &= 1 - (-1)^k \cdot 0 = 1,
               \end{align*}
               so that $1+x$ is a unit in $R$ and its inverse is
               $\sum_{i=0}^{k-1}(-1)^ix^i$.
         \item Let $u \in R$ be a unit. It suffices to show that $u + x$ is also
               a unit. Now we have that $u + x = u(1 + u^{-1}x)$. By (b),
               $u^{-1}x$ is nilpotent, and thus, $1 + u^{-1}x$ is a unit by
               (c). Since the product of two units is also a unit, it follows
               that $u + x = u(1 + u^{-1}x)$ is also a unit.
      \end{enumerate} \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.15%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.15]  A ring $R$ is called a \textit{Boolean ring} if $a^2 = a$ for
                  all $a \in R$. Prove that every Boolean ring is commutative.

      \textbf{Proof.} Suppose that $R$ us a Boolean ring. Let $a, b \in R$. By
      hypothesis, we have that $(a + b)^2 = (a + b)$; thus
      $$a^2 + ab + ba + b^2 = a + b.$$
      Also $a^2 = a$ and $b^2 = b$, so the equality above reduces to
      $$ab + ba = 0.$$
      By hypothesis we again have that $ba = (ba)^2 = (-ba)(-ba) = -ba$. Thus
      $ab + ba = 0$ implies that $ab - ba = 0$ and we conclude that $ab = ba$,
      so that $R$ is commutative. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.16%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.16]  Prove that the only Boolean ring that is an integral domain is
                  $\Z/2\Z$.

      \textbf{Proof.} Suppose that $R$ is a Boolean ring that is an integral
      domain. Let $r \in R$. Thus $r^2 = r$, so that $r^2 - r = 0$; that is,
      $r(r - 1) = 0$. Since $R$ is an integral domain, it follows that $r = 0$
      or $r - 1 = 0$, so that $r = 0$ or $r = 1$. Thus $R = \{0, 1\} = \Z/2\Z$.
      \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.17%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.17]  Let $R$ and $S$ be rings. Prove that the direct product
                  $R \times S$ is a ring under componentwise addition and
                  multiplication. Prove that $R \times S$ is commutative if and
                  only if both $R$ and $S$ are commutative. Prove that
                  $R \times S$ has an identity if and only if both $R$ and $S$
                  have identities.

      \textbf{Proof.} Let $a, b, c \in R \times S$. Then $a = (r_1, s_1)$,
      $b = (r_2, s_2)$, and $c = (r_3, s_3)$ for some $r_1, r_2, r_3 \in R$ and 
      $s_1, s_2, s_3 \in S$.

      (\textit{$(R \times S, +)$ is an abelian group}.) This follows from
      Exercises 1.1.28 and 1.1.29.

      (\textit{$R \times S$ is closed under multiplication}.) We have
      $$ab = (r_1, s_1)(r_2, s_2) = (r_1r_2, s_1s_2) \in R \times S$$
      because $r_1r_2 \in R$ and $s_1s_2 \in S$ by closure of $R$ and $S$. Thus
      $R \times S$ is closed under multiplication.

      (\textit{Associativity of multiplication in $R \times S$}.) We have
      \begin{align*}
         a(bc) &= (r_1, s_1)[(r_2, s_2)(r_3, s_3)] \\
            &= (r_1, s_1)(r_2r_3, s_2s_3) \\
            &= (r_1(r_2r_3), s_1(s_2s_3)) \\
            &= ((r_1r_2)r_3, (s_1s_2)s_3) \\
            &= (r_1r_2, s_1s_2)(r_3, s_3) \\
            &= [(r_1, s_1)(r_2, s_2)](r_3, s_3) \\
            &= (ab)c,
      \end{align*}
      so that componentwise multiplication is associative in $R \times S$.

      (\textit{Left distributivity in $R \times S$}.) We have
      \begin{align*}
         a(b + c) &= (r_1, s_1)[(r_2, s_2) + (r_3, s_3)] \\
            &= (r_1, s_1)(r_2 + r_3, s_2 + s_3) \\
            &= (r_1(r_2 + r_3), s_1(s_2 + s_3)) \\
            &= (r_1r_2 + r_1r_3, s_1s_2 + s_1s_3) \\
            &= (r_1r_2, s_1s_2) + (r_1r_3, s_1s_3) \\
            &= (r_1, s_1)(r_2, s_2) + (r_1, s_1)(r_3, s_3) \\
            &= ab + ac.
      \end{align*}


      (\textit{Right distributivity in $R \times S$}.) We have
      \begin{align*}
         (b + c)a &= [(r_2, s_2) + (r_3, s_3)](r_1, s_1) \\
            &= (r_2 + r_3, s_2 + s_3)(r_1, s_1) \\
            &= ((r_2 + r_3)r_1, (s_2 + s_3)s_1) \\
            &= (r_2r_1 + r_3r_1, s_2s_1 + s_3s_1) \\
            &= (r_2r_1, s_2s_1) + (r_3r_1, s_3s_1) \\
            &= (r_2, s_2)(r_1, s_1) + (r_3, s_3)(r_1, s_1) \\
            &= ba + ca.
      \end{align*}

      Thus $R \times S$ is a ring under componentwise addition and
      multiplication.

      ($\Rightarrow$) Suppose $R \times S$ is commutative. Let $r_4, r_5 \in R$
      and $s_4, s_5 \in S$. Since $R \times S$ is commutative, it follows that
      $$(r_4r_5, s_4s_5) = (r_4, s_4)(r_5, s_5) = (r_5, s_5)(r_4, s_4) =
        (r_5r_4, s_5s_4),$$
      so that $r_4r_5 = r_5r_4$ and $s_4s_5 = s_5s_4$. Thus $R$ and $S$ are
      commutative.

      ($\Leftarrow$) Suppose conversely that $R$ and $S$ are commutative. Let
      $a', b' \in R \times S$. Then $a' = (r_6, s_6)$ and $b' = (r_7, s_7)$ for
      some $r_6, r_7 \in R$ and $s_6, s_7 \in S$. So
      \begin{align*}
         a'b' &= (r_6, s_6)(r_7, s_7) \\
            &= (r_6r_7, s_6s_7) \\
            &= (r_7r_6, s_7s_6) &[R \text{ and } S \text{ are commutative}] \\
            &= (r_7, s_7)(r_6, s_6) \\
            &= b'a',
      \end{align*}
      so that $R \times S$ is commutative.

      ($\Rightarrow$) Suppose $R \times S$ has an identity, say $(r', s')$,
      where $r' \in R$ and $s' \in S$. Let $r_8 \in R$ and $s_8 \in S$. Thus we
      have that
      $$(r_8, s_8) = (r', s')(r_8, s_8) = (r'r_8, s's_8)$$
      and
      $$(r_8, s_8) = (r_8, s_8)(r', s') = (r_8r', s_8s').$$
      That is, $r_8 = r'r_8 = r_8r'$ and $s_8 = s's_8 = s_8s'$. Thus $r'$ is an
      identity in $R$ and $s'$ is an identity in $S$.

      ($\Leftarrow$) Suppose that $1_R \in R$ and $1_S \in S$ are identities.
      Let $a'' \in R \times S$. So $a'' = (r_9, s_9)$ for some $r_9 \in R$ and 
      $s_9 \in S$. Thus
      $$
         a''(1_R, 1_S) = (r_9, s_9)(1_R, 1_S) = (r_9 \cdot 1_R, s_9 \cdot 1_S) 
            = (r_9, s_9) = a''
      $$
      and
      $$
         (1_R, 1_S)a'' = (1_R, 1_S)(r_9, s_9) = (1_R \cdot r_9, 1_S \cdot s_9) 
            = (r_9, s_9) = a''.
      $$
      Hence $(1_R, 1_S)$ is an identity in $R \times S$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.18%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.18]  Prove that $\{(r, r) : r \in R\}$ is a subring of
                  $R \times R$.

      \textbf{Proof.} Let $H = \{(r, r) : r \in R\}$.

      (\textit{H is a subgroup of $R \times R$}.) This follows from Exercise 
      2.1.11(c).

      (\textit{H is closed under multiplication}.) Let $a, b \in H$. That is,
      $a = (r, r)$ and $b = (r', r')$ for some $r, r' \in R$. Thus
      $ab = (r, r)(r', r') = (rr', rr') \in H$ because $rr' \in R$ by closure.

      Since $H$ is a subgroup of $R \times R$ and is closed under
      multiplication, it follows by definition that $H$ is a subring of
      $R \times R$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.19%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.19]  Let $I$ be any nonempty index set and let $R_i$ be ring for
                  each $i \in I$. Prove that the direct product
                  $\prod_{i\in I} R_i$ is a ring under componentwise addition
                  and multiplication.

      \textbf{Proof.} Let $R = \prod_{i\in I} R_i$; for each $i \in I$ let
      $+_i$ and $\cdot_i$ be the addition and multplication of $R_i$.

      (\textit{$R$ is an abelian group}.) Exercise 5.1.15 says that $(R, +)$ is 
      a group; indeed, it is abelian because
      \begin{align*}
         \left(\prod_{i\in I}a_i\right) + \left(\prod_{i\in I}b_i\right)
            &= \prod_{i\in I}(a_i +_i b_i) \\
            &= \prod_{i\in I}(b_i +_i a_i) &[(R_i, +) \text{ is abelian}] \\
            &= \left(\prod_{i\in I}b_i\right) + \left(\prod_{i\in I}a_i\right),
      \end{align*}
      for all $\prod_{i\in I}a_i$, $\prod_{i\in I}b_i \in R$.

      (\textit{$R$ is closed under multiplication}.) This follows immediately
      because
      \begin{align*}
         \left(\prod_{i\in I}c_i\right)\left(\prod_{i\in I}d_i\right) &=
            \prod_{i\in I}(c_i \cdot_i d_i) \in R &[c_i \cdot_i d_i \in R_i]
      \end{align*}
      for all $\prod_{i\in I}c_i$, $\prod_{i\in I}d_i \in R$.

      (\textit{Distributivity in $R$}.) Distributivity holds in $R$ because
      \begin{align*}
         \left(\prod_{i\in I}a_i\right)\left[\left(\prod_{i\in I}b_i\right) +
            \left(\prod_{i\in I}c_i\right)\right] &=
         \left(\prod_{i\in I}a_i\right)
         \left(\prod_{i\in I}(b_i +_i c_i)\right) \\
         &= \prod_{i\in I}(a_i \cdot_i [b_i +_i c_i]) \\
         &= \prod_{i\in I}(a_i \cdot_i b_i +_i a_i \cdot_i c_i)
            &[\text{Left Distributivity in }R_i] \\
         &= \left(\prod_{i\in I}(a_i \cdot_i b_i)\right) +
            \left(\prod_{i\in I}(a_i \cdot_i c_i)\right) \\
         &= \left(\prod_{i\in I}a_i\right)\left(\prod_{i\in I}b_i\right) +
            \left(\prod_{i\in I}a_i\right)\left(\prod_{i\in I}c_i\right)
      \end{align*}
      and
      \begin{align*}
         \left[\left(\prod_{i\in I}b_i\right) +
            \left(\prod_{i\in I}c_i\right)\right]\left(\prod_{i\in I}a_i\right) 
         &= \left(\prod_{i\in I}(b_i +_i c_i)\right)
            \left(\prod_{i\in I}a_i\right) \\
         &= \prod_{i\in I}([b_i +_i c_i] \cdot_i a_i) \\
         &= \prod_{i\in I}(b_i \cdot_i a_i +_i c_i \cdot_i a_i)
            &[\text{Right Distributivity in }R_i] \\
         &= \left(\prod_{i\in I}(b_i \cdot_i a_i)\right) +
            \left(\prod_{i\in I}(c_i \cdot_i a_i)\right) \\
         &= \left(\prod_{i\in I}b_i\right)\left(\prod_{i\in I}a_i\right) +
            \left(\prod_{i\in I}c_i\right)\left(\prod_{i\in I}a_i\right)
      \end{align*}
      for all $\prod_{i\in I}a_i$, $\prod_{i\in I}b_i, \prod_{i\in I}c_i \in R$.
      
      Thus $(R, +, \cdot)$ is a ring. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.20%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.20]  Let $R$ be the collection of sequences
                  $(a_1, a_2, a_3, \ldots)$ of integers $a_1$, $a_2$, $a_3$,  
                  $\ldots$ where all but finitely many of the $a_i$ are 0 (called
                  the \textit{direct sum} of infinitely many copies of $\Z$).
                  Prove that $R$ is a ring under componentwise addition and
                  multiplication which does not have an identity.

      \textbf{Proof.} Let $R'$ be the collection of sequences of integers. By
      Exercise 7.1.19, $R'$ is a ring ($R'$ is the direct product of countably
      infinite number of $\Z$). Clearly $R \subseteq R'$, so it suffices to show
      that $R$ is a subring of $R'$.

      (\textit{$R$ is a subgroup of $R'$}.) The sequence consisting of only
      zeros is in $R$, so $R$ contains the additive identity. Let
      $a, b \in R$. So
      $$a = (a_1, a_2, a_3, \ldots) \text{ and } b = (b_1, b_2, b_3, \ldots),$$
      where $a_i, b_i \in \Z$ and finitely many $a_i$ and $b_i$ are nonzero. Let
      $j$ and $k$ be the maximum indices such that $a_j \neq 0$ and
      $b_k \neq 0$ and let $m = \max\{j, k\}$. Thus $a_{n+m} = b_{n+m} = 0$ for 
      all $n \in \Z^+$. We now have that
      $$a - b = (a_1 - b_1, a_2 - b_2, \ldots, a_m - b_m,
        a_{m+1} - b_{m+1}, \ldots) \in R$$
      because the first $m$ components of $a - b$ have finite nonzero elements
      and the remaining components are 0. So it follows by the Subgroup
      Criterion that $R$ is a subgroup of $R'$.

      (\textit{$R$ is closed under multiplication}.) Let $a$, $b$, and $m$ be as
      defined above. Similarly, it follows that
      $$ab = (a_1b_1, a_2b_2, \ldots, a_m b_m, a_{m+1}b_{m+1}, \ldots) \in R$$
      because the first $m$ components of $ab$ have finite nonzero elements
      and the remaining components are 0.

      Since $R$ is a subgroup of $R'$ and is closed under multiplication, it 
      follows by definition that $R$ is a subring of $R'$. The ring $R$ cannot
      contain the identity $(1, 1, 1, \ldots)$ because the identity has an
      infinite number of nonzero elements. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.21%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.21]  Let $X$ be any nonempty set and let $\mathcal{P}(X)$ be the
                  set of all subsets of $X$ (the \textit{power set} of $X$).
                  Define addition and multiplication on $\mathcal{P}(X)$ by
                  $$A + B = (A - B) \cup (B - A) \text{ and }
                    A \times B = A \cap B$$
                  i.e., addition is symmetric difference and multiplication is
                  intersection.
                  \begin{enumerate}
                     \item Prove that $\mathcal{P}(X)$ is a ring under these
                           operations ($\mathcal{P}(X)$ and its subring are
                           often referred to as \textit{ring of sets}).
                     \item Prove that this ring is commutative, has an identity
                           and is a Boolean ring.
                  \end{enumerate}

      \textbf{Proof.} Let $A, B, C \in \mathcal{P}(X)$.

      \begin{enumerate}
         \item Observe that addition and multiplication on $\mathcal{P}(X)$ are 
               commutative because
               \begin{align*}
                  A + B &= (A - B) \cup (B - A) \\
                     &= (B - A) \cup (A - B) &[\cup \text{ is commutative}] \\
                     &= B + A \\ \\
                  A \times B &= A \cap B \\
                     &= B \cap A &[\cap \text{ is commutative}] \\
                     &= B \times A.
               \end{align*}

               (\textit{Associativity of }+) $A + (B + C) = (A + B) + C$.

               $(\subseteq)$ Let $r \in A + (B + C)$. Then
               $r \in A - (B + C)$ or $r \in (B + C) - A$.

               \textbf{Case 1.} $r \in A - (B + C)$. So $r \in A$ and
               $r \notin B + C$. Now $r \notin B + C$ if and only if
               $(r \notin B$ and $r \notin C)$ or $(r \in B$ and $r \in C)$. So
               suppose first that $r \notin B$ and $r \notin C$. Hence the
               following statements hold:
               $$r \in A, r \notin B, \text{ and }r \notin C.$$
               The statements $r \in A$ and $r \notin B$ imply that
               $r \in A + B$; similarly, $r \in A + B$ and $r \notin C$ imply 
               that $r \in (A + B) + C$. Now suppose that
               $r \in B$ and $r \in C$. Hence the
               following statements hold:
               $$r \in A, r \in B, \text{ and }r \in C.$$
               The statements $r \in A$ and $r \in B$ imply that
               $r \notin A + B$, and consequently, the statements 
               $r \notin A + B$ and $r \in C$ imply that $r \in (A + B) + C$. \\

               \textbf{Case 2.} $r \in (B + C) - A$. So $r \in B + C$ and
               $r \notin A$. Now $r \in B + C$ if and only if
               $(r \in B$ and $r \notin C)$ or $(r \notin B$ and $r \in C)$. So
               suppose first that $r \in B$ and $r \notin C$. Hence the
               following statements hold:
               $$r \notin A, r \in B, \text{ and }r \notin C.$$
               The statements $r \notin A$ and $r \in B$ imply that
               $r \in A + B$; similarly, $r \in A + B$ and $r \notin C$ imply 
               that $r \in (A + B) + C$. Now suppose that
               $r \notin B$ and $r \in C$. Hence the
               following statements hold:
               $$r \notin A, r \notin B, \text{ and }r \in C.$$
               The statements $r \notin A$ and $r \notin B$ imply that
               $r \notin A + B$, and consequently, the statements 
               $r \notin A + B$ and $r \in C$ imply that $r \in (A + B) + C$. \\

               In both cases, we showed that $r \in (A + B) + C$ so
               we conclude that $$A + (B + C) \subseteq (A + B) + C.$$

               ($\supseteq$) We have
               \begin{align*}
                  (A + B) + C &= C + (A + B) &[\text{+ is commutative}] \\
                     &= C + (B + A) &[\text{+ is commutative}] \\
                     &\subseteq (C + B) + A &[\text{Recall that }
                     A + (B + C) \subseteq (A + B) + C] \\
                     &= (B + C) + A &[\text{+ is commutative}] \\
                     &= A + (B + C), &[\text{+ is commutative}]
               \end{align*}
               so we conclude that $A + (B + C) = (A + B) + C$.

               (\textit{$0$ and inverses under }+). The empty set is the
               0 element and every element is its own additive inverse. Thus
               $\mathcal{P}(X)$ is an abelian group.

               (\textit{Associativity of }$\times$.) This follows because 
               intersection of sets is associative

               (\textit{Distributivity}.) Since multiplication is commutative,
               it suffices to show that left distribution holds; i.e.,
               $$A \times (B + C) = (A \times B) + (A \times C).$$

               ($\subseteq$) Let $r \in A \times (B + C) = A \cap (B + C)$. So
               $r \in A$ and $r \in B + C$. Recall that $r \in B + C$ if and
               only if$(r \in B$ and $r \notin C)$ or $(r \notin B$ and
               $r \in C)$. So suppose first that $r \in B$ and $r \notin C$.
               Hence the following statements hold:
               $$r \in A, r \in B, \text{ and }r \notin C.$$
               The statements $r \in A$ and $r \in B$ imply that
               $r \in A \cap B$, so that $r \in A \times B$; also,
               $r \in A$ and $r \notin C$ imply that $r \notin A \cap C$, so
               that $r \notin A \times C$. Thus $r \in A \times B$ and
               $r \notin A \times C$ imply that
               $r \in (A \times B) + (A \times C)$. Now if $r \notin B$ and
               $r \in C$, we interchange the roles of $B$ and $C$ in the
               preceding paragraph to conclude that
               $$r \in (A \times C) + (A \times B) = (A \times B) +
                  (A \times C).$$
               Thus $A \times (B + C) \subseteq (A \times B) + (A \times C)$.

               ($\supseteq$) Let $r \in (A \times B) + (A \times C) =
               (A \cap B) + (A \cap C)$. We split
               the possibilities into cases:

               \textbf{Case 1.} $r \in A \cap B$ and $r \notin A \cap C$. The
               statement $r \in A \cap B$ implies that $r \in A$ and $r \in B$,
               while $r \notin A \cap C$ implies that $r \notin A$ or
               $r \notin C$; however, since $r \in A$, we must have
               $r \notin C$. Hence the following statements hold:
               $$r \in A, r \in B, \text{ and }r \notin C.$$
               The statements $r \in B$ and $r \notin C$ imply that
               $r \in B + C$; since $r \in A$, it follows that
               $r \in A \times (B + C)$.

               \textbf{Case 2.} $r \in A \cap C$ and $r \notin A \cap B$.
               Interchange the roles of $B$ and $C$ in case 1 to conclude that
               $$r \in A \times (C + B) = A \times (B + C).$$

               Thus $A \times (B + C) \supseteq (A \times B) + (A \times C)$, so
               that equality holds. We then conclude that $\mathcal{P}(X)$ is a
               ring.
         \item We already showed that multiplication is commutative. Since
               $X \times D = X \cap D = D$, and $D \times D = D \cap D = D$ for
               all $D \in \mathcal{P}(X)$, it follows that $\mathcal{P}(X)$ is a
               Boolean ring with identity $X$.
      \end{enumerate} \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.22%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.22]  Give an example of an infinite Boolean ring.

      \textbf{Example.} The Boolean ring $(\mathcal{P}(\Z), +, \times)$, where
      addition and multiplication are defined as in Exercise 7.1.21.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.23%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.23]  Let $D$ be a squarefree integer, and let $\mathcal{O}$ be the
                  ring of integers in the quadratic field $\Q(\sqrt{D})$. For 
                  any positive integer $f$ prove that the set
                  $\mathcal{O}_f = \Z[f\omega] = \{a + bf\omega : a, b \in \Z\}$
                  is a subring of $\mathcal{O}$ containing the identity. Prove
                  that $[\mathcal{O} : \mathcal{O}_f] = f$ (index as additive
                  abelian groups). Prove conversely that a subring of
                  $\mathcal{O}$ containing the identity and having finite index
                  $f$ in $\mathcal{O}$ (as additive abelian group) is equal to
                  $\mathcal{O}_f$. (The ring $\mathcal{O}_f$ is called the
                  \textit{order of conductor f} in the field $\Q(\sqrt{D})$. The
                  ring of integers $\mathcal{O}$ is called the
                  \textit{maximal order} in $\Q(\sqrt{D}).)$

      \textbf{Proof.} Let $f \in \Z^+$. The set $\mathcal{O}_f$ is nonempty
      because it contains the additive identity $0 = 0 + 0 \cdot f\omega$; note 
      that it also contains $1 = 1 + 0 \cdot f\omega$. Let
      $x,  y \in \mathcal{O}_f$, so that $x = x_1 + x_2f\omega$ and
      $y = y_1 + y_2f\omega$ for some integers $x_1, x_2, y_1$, and $y_2$.

      (\textit{$\mathcal{O}_f$ is a subgroup of $\mathcal{O}$.})  Since $\Z$ is 
      closed under subtraction, it follows that
      $$x - y = (x_1 - y_1) + (x_2 - y_2)f\omega \in \mathcal{O}_f,$$
      so that  $\mathcal{O}_f \le \mathcal{O}$ by the Subgroup Criterion.

      (\textit{$\mathcal{O}_f$ is closed under multiplication.}) We have
      \begin{equation*}
         xy = \left\{
         \begin{array}{rl}
            x_1y_1 + x_2y_2f^2D + (x_1y_2 + x_2y_1)f\omega & \text{if }
               D \equiv 2, 3 \text{ mod } 4, \\
            \left(x_1y_1 + x_2y_2f^2\frac{D-1}{4}\right) +
               (x_1y_2f + x_2y_1f +x_2y_2f^2)\omega, & \text{if }
               D \equiv 1 \text{ mod } 4
         \end{array} \right.
      \end{equation*}
      so that $xy \in \mathcal{O}_f$. Since $\mathcal{O}_f$ is a subgroup of
      $\mathcal{O}$ that is also closed under multiplication, it follows by 
      definition that $\mathcal{O}_f$ is a subring of $\mathcal{O}$.
      
      ($|\mathcal{O} :\mathcal{O}_f| = f$.) Consider the map
      $$\alpha : \mathcal{O} \rightarrow \Z/f\Z,$$
      defined by $a + b\omega \mapsto b + f\Z$. We want to show that $\alpha$ is
      a surjective (additive) group homomorphism. Let $r,  s \in \mathcal{O}f$, 
      so that $r = r_1 + r_2\omega$ and $s = s_1 + s_2\omega$ for some integers 
      $r_1, r_2, s_1$, and $s_2$. It follows that
      \begin{align*}
         \alpha(r + s) &= \alpha((r_1 + s_1) + (r_2 + s_2)\omega) \\
            &= (r_2 + s_2) + f\Z \\
            &= (r_2 + f\Z) + (s_2 + f\Z) \\
            &= \alpha(r_1 + r_2\omega) + \alpha(s_1 + s_2\omega) \\
            &= \alpha(r) + \alpha(s),
      \end{align*}
      so that $\alpha$ is a homomorphism. The map $\alpha$ is surjective because
      if $x$ is a representative of a coset in $\Z/f\Z$, then
      $\alpha(x\omega) = x + f\Z$. Now
      \begin{align*}
         \text{kernel}(\alpha) &= \{b_1 + b_2\omega \in \mathcal{O} :
            b_2 + f\Z = \alpha(b_1 + b_2\omega) = f\Z\} \\
            &= \{b_1 + b_2\omega \in \mathcal{O} : b_2 \in f\Z\} \\
            &= \{b_1 + tf\omega \in \mathcal{O} : t \in \Z\} \\
            &= \mathcal{O}_f.
      \end{align*}
      It follows by the First Isomorphism Theorem for groups that
      $\mathcal{O}/\mathcal{O}_f \cong \alpha(\mathcal{O}) = \Z/f\Z$. So 
      conclude that $|\mathcal{O} : \mathcal{O}_f| = |\Z/f\Z| = f$. Now let $F$
      be a unital subring of $\mathcal{O}$ and suppose that
      $[\mathcal{O} : F] = n \in \Z^+$. Since $1 \in F$, it follows that
      $\cyc{1} = \Z \subseteq F$. For $a, b \in \Z$, the cosets $a\omega + \Z$ 
      and $b\omega + \Z$ are equal if and only if $a\omega - b\omega \in \Z$ if 
      and only if $a = b$. Thus the following are an infinite number of cosets
      of $\Z$ in $\mathcal{O}$:
      $$1\omega + \Z, 2\omega + \Z, 3\omega + \Z, \ldots$$
      That is, $[\mathcal{O} : \Z]$ is not finite, so that $\Z \neq F$; thus
      $\Z$ is a proper subset of $F$, so there exists a noninteger
      $r_1 + r_2\omega\in F$, $r_1, r_2 \in \Z$ and $r_2 \neq 0$. By closure,
      $-r_1 - r_2\omega \in F$. Since either $-r_2$ or $r_2$ is positive, the
      set
      $$S = \{m \in \Z^+ : a' + m\omega \in F, \text{ for some }a' \in \Z\}$$
      is nonempty. The Well Ordering Principle guarantees that $k = \min(S)$
      exists. Since $k \in S$, we let $c$ be the integer such that
      $c + k\omega$. Since $\Z \subseteq F$, we have that $-c \in F$, so that
      $(c + k\omega) - c = k\omega \in F$. Now we want to show that
      $F = \mathcal{O}_k$.

      $(\subseteq)$ Let $s \in F$. Then $s = a + b\omega$ for some
      $a, b \in \Z$. By the Division Algorithm, there exist integers $q'$ and 
      $r'$ such that $b = q'k + r'$ and $0 \le r' < k$, so that
      $s = a + q'k\omega + r'\omega$. Now $q'$ is an integer so $q' \in F$; 
      since $k\omega \in F$, it follows that $q'k\omega$ is in $F$; thus
      $s - q'k\omega = a + r'w \in F$. By minimality of $k$, it follows that
      $r' = 0$, so that $s = a + q'k\omega \in \mathcal{O}_k$. Conclude that
      $F \subseteq \mathcal{O}_k$.

      $(\supseteq)$ Let $p \in \mathcal{O}_k$. So $p = p_1 + p_2k\omega$ for
      some integers $p_1$ and $p_2$. Recall that $k\omega \in F$ and
      $\Z \subseteq F$. Thus $p_1 \in F$ and $p_2k\omega \in F$; by closure, it
      follows by $p = p_1 + p_2k\omega \in F$. Thus $F \supseteq \mathcal{O}_k$.

      We conclude that $F = \mathcal{O}_k$, so that
      $$n = [\mathcal{O} : F] = [\mathcal{O} : \mathcal{O}_k] = k.$$
      That is, $F = \mathcal{O}_k = \mathcal{O}_n$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.24%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.24]  Show for $D = 3, 5, 6$, and 7 that the group of units
                  $\mathcal{O}^\times$ of the quadratic integer ring
                  $\mathcal{O}$  is infinite by exhibiting an explicit unit of
                  infinite (multiplicative) order in each ring.

      \textbf{Solution.} The elements $2 + \sqrt{3} \in \Z[\sqrt{3}]$,
      $1 + \frac{1 + \sqrt{5}}{2} \in \Z\left[\frac{1 + \sqrt{5}}{2}\right]$,
      $5 + 2\sqrt{6} \in \Z[\sqrt{6}]$, and $8 + 3\sqrt{7} \in \Z[\sqrt{7}]$ all
      have inifinite multiplicative order.      
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.25%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.25]  Let $I$ be the ring of integral Hamilton Quaternions and
                  define
                  $$N : I \rightarrow \Z \text{ by }
                    N(a + bi + cj + dk) = a^2 + b^2 + c^2 + d^2$$
                  (the map $N$ is called a \textit{norm}).
                  \begin{enumerate}
                     \item Prove that $N(\alpha) = \alpha\overline{\alpha}$ for
                           all $\alpha \in I$, where if
                           $\alpha = a + bi + cj + dk$ then
                           $\overline{\alpha} = a - bi - cj - dk$.
                     \item Prove that $N(\alpha\beta) = N(\alpha)N(\beta)$ for
                           all $\alpha$, $\beta \in I$.
                     \item Prove that an element of $I$ is a unit if and only if
                           it has norm $+1$. Show that $I^\times$ is isomorphic
                           to the quaternion group of order 8. [The inverse in
                           the ring of rational quaternions of a nonzero element
                           $\alpha$ is $\frac{\overline{\alpha}}{N(\alpha)}$.]
                  \end{enumerate}

      \textbf{Proof.} Let $\alpha, \beta \in I$. Then
      $\alpha = a + bi + cj + dk$ and $\beta = e + fi + gj + hk$ for some
      integers $a$, $b$, $c$, $d$, $e$, $f$, $g$, and $h$.

      \begin{enumerate}
         \item We have
               \begin{align*}
                  \alpha\overline{\alpha} &=
                     (a + bi + cj + dk)(a - bi - cj - dk) \\
                     &= [a + (bi + cj + dk)][a - (bi + cj + dk)] \\
                     &= a^2 - (bi + cj + dk)^2 \\
                     &= a^2 - [bi(bi + cj + dk) + cj(bi + cj + dk) +
                        dk(bi + cj + dk)] \\
                     &= a^2 - (-b^2 + bck - bdj - bck - c^2 + cdi +
                        bdj - cdi - d^2) \\
                     &= a^2 + b^2 + c^2 + d^2 = N(\alpha).
               \end{align*}
         \item We have
               \begin{IEEEeqnarray*}{rCl}
                  N(\alpha\beta) &=& N([a + bi + cj + dk][e + fi + gj + hk]) \\
                     &=& N(ae - bf - cg - dh + [af + be + ch - dg]i \\
                        && + \: [ag - bh + ce + df]j + [ah + bg - cf + de]k) \\
                     &=& (ae - bf - cg - dh)^2 + (af + be + ch - dg)^2 \\
                        && + \: (ag - bh + ce + df)^2 + (ah + bg - cf + de)^2 \\
                     &=& (a^2e^2 +b^2f^2 + c^2g^2 + d^2h^2 \\
                        && - \: 2abef - 2aceg - 2adeh +2bcfg+2bdfh + 2cdgh) + \\
                     && (a^2f^2 + b^2e^2 + c^2h^2 + d^2g^2 \\
                        && + \: 2abef + 2acfh - 2adfg + 2bceh -2bdeg-2cdgh) + \\
                     && (a^2g^2 + b^2h^2 + c^2e^2 + d^2f^2 \\
                        && - \: 2abgh + 2aceg + 2adfg - 2bceh -2bdfh+2cdef) + \\
                     && (a^2h^2 + b^2g^2 + c^2f^2 + d^2e^2 \\
                        && + \: 2abgh - 2acfh + 2adeh - 2bcfg +2bdeg-2cdef) \\
                     &=& a^2e^2 +b^2f^2 + c^2g^2 + d^2h^2 +
                        a^2f^2 + b^2e^2 + c^2h^2 + d^2g^2 + \\
                        && a^2g^2 + b^2h^2 + c^2e^2 + d^2f^2 +
                        a^2h^2 + b^2g^2 + c^2f^2 + d^2e^2 \\
                     &=& a^2(e^2 + f^2 + g^2 + h^2) + b^2(e^2 + f^2 +g^2+h^2) \\
                        && c^2(e^2 + f^2 + g^2 + h^2)+d^2(e^2 + f^2+g^2 +h^2) \\
                     &=& (a^2 + b^2 + c^2 + d^2)(e^2 + f^2 + g^2 + h^2) \\
                     &=& N(\alpha)N(\beta).
               \end{IEEEeqnarray*}
         \item ($\Rightarrow$) Suppose that $\alpha$ is a unit. Then we have
               that
               $$N(\alpha)N(\alpha^{-1}) = N(\alpha\alpha^{-1}) = N(1) =
                 N(1 + 0i + 0j + 0k) = 1^2 + 0^2 + 0^2 + 0^2 = 1.$$
               By definition $N(t)$ is nonnegative for all $t \in I$. Thus since
               $N(\alpha)N(\alpha^{-1}) = 1$, it follows that $N(\alpha) = 1$.

               ($\Leftarrow$) Suppose conversely that $N(\alpha) = 1$. It
               follows that
               $1 = N(\alpha) = a^2 + b^2 + c^2 + d^2$. That is, exactly one of
               $a$, $b$, $c$, and $d$ has absolute value of 1 while the rest are
               0. So $\alpha \in \{\pm1, \pm i, \pm j, \pm k\}$. This says that
               $I^\times = \{\pm1, \pm i, \pm j, \pm k\}$. The identity function
               gives an isomorphism from $I^\times$ to the quaternion group of
               order 8.
      \end{enumerate} \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.26%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.26]  Let $K$ be a field. A \textit{discrete valuation} on $K$ is a
                  function $\nu : K^\times \rightarrow \Z$ satisfying
                  \begin{enumerate}\renewcommand{\labelenumii}{(\roman{enumii})}
                     \item $\nu(ab) = \nu(a) + \nu(b)$ (i.e., $\nu$ is a
                           homomorphism from the multiplicative group of nonzero
                           elements of $K$ to $\Z$),
                     \item $\nu$ is surjective, and
                     \item $\nu(x + y) \ge \min\{\nu(x), \nu(y)\}$ for all
                           $x, y \in K^\times$ with $x + y \neq 0$.
                  \end{enumerate}
                  The set $R = \{x \in K^\times : \nu(x) \ge 0\} \cup \{0\}$ is
                  called the \textit{valuation ring} of $\nu$.
                  \begin{enumerate}
                     \item Prove that $R$ is a subring of $K$ which contains the
                           identity. (In general, a ring $R$ is called a
                           \textit{discrete valuation ring} if there is some
                           field $K$ and some discrete valuation $\nu$ on $K$
                           such that $R$ is the valuation ring of $\nu$.)
                     \item Prove that for each nonzero element $x \in K$ either
                           $x$ or $x^{-1}$ is in $R$.
                     \item Prove that an element $x$ is a unit of $R$ if and only
                           if $\nu(x) = 0$.
                  \end{enumerate}

      \textbf{Solution.} Observation: since $\nu$ is a homomorphism, we have
      $\nu(1) = 0$; thus,
      $$0 = \nu(1) = \nu(-1 \cdot -1) = \nu(-1) + \nu(-1),$$
      so that $\nu(-1) = 0$. That is
      $$\nu(-z) = \nu(-1 \cdot z) = \nu(-1) + \nu(z) = \nu(z)$$
      for every $z \in K^\times$.

      \begin{enumerate}
         \item \textbf{Proof.} The set $R$ is nonempty because it contains 0, so 
               let $x, y \in R$.

               (\textit{$R$ is closed under subtraction}.) Let us investigate 
               the following cases.

               \textbf{Case 1.} $x = y = 0$. It follows that $x - y = 0 \in R$.

               \textbf{Case 2.} $x = 0$ and $y \neq 0$. Thus $y \in K^\times$,
               so that $-y$ is also a unit in $K$. So $\nu(-y) = \nu(y) \ge 0$.
               That is, $x - y = -y \in R$.

               \textbf{Case 3.} $x \neq 0$ and $y = 0$. So $x - y = x \in R$.

               \textbf{Case 4.} $x \neq 0$ and $y \neq 0$. Thus $x$ and $y$ are
               units in $K$. If $x = y$, then $x - y = 0 \in R$, so suppose that
               $x - y \neq 0$. By the 3rd property of $\nu$, we have that
               $$\nu(x + (-y)) \ge \min\{\nu(x), \nu(-y)\} =
                 \min\{\nu(x), \nu(y)\} \ge 0.$$
               The last inequality holds because $\nu(x)$ and $\nu(y)$ are both
               nonnegative integers. Thus $x + (-y) = x - y \in R$. \\
      
               In all cases, we showed that $R$ is closed under subtraction; so 
               since $R$ is nonempty and closed under subtraction, it follows by
               the Subgroup Criterion that $R \le K$.

               (\textit{$R$ is closed under multiplication}.) If either $x$ or
               $y$ is 0, then $xy = 0 \in R$, so assume that both $x$ and $y$
               are units in $K$. Thus
               \begin{align*}
                  \nu(xy) &= \nu(x) + \nu(y) &[\nu\text{ is a homomorphism}] \\
                     &\ge 0 + 0 = 0, &[\nu(x) \ge 0 \text{ and }\nu(y) \ge 0]
               \end{align*}
               so that $xy \in R$. Thus $R$ is closed under multiplication.
               Since $R$ is a subgroup of $K$ that is also closed under
               multiplication, it follows that $R$ is a subring of $K$. Indeed,
               $R$ is a unital subring because since $\nu(1) = 0$, we have that
               $1 \in R$. \qed
         \item \textbf{Proof.} Let $z$ be a nonzero element in $K$ and suppose 
               that $z \neq R$. It suffices to show that $z^{-1} \in R$. Since 
               $z \notin R$, it follows by definition of $R$ that $\nu(z) < 0$, 
               so that $-\nu(z) > 0$. But $-\nu(z) = \nu(z^{-1})$ because $\nu$ 
               is a homomorphism. Thus $\nu(z^{-1}) > 0$, so that
               $\nu(z^{-1}) \in R$. \qed
         \item \textbf{Proof.}

               ($\Rightarrow$) Suppose that $x$ is a unit of $R$. That is
               $x^{-1} \in R$. So we have that
               $$0 = \nu(1) = \nu(xx^{-1}) = \nu(x) + \nu(x^{-1}).$$
               But both $\nu(x)$ and $\nu(x^{-1})$ are nonnegative integers 
               because $x$ and $x^{-1}$ are units of $K$ that are in $R$. So
               conclude that $\nu(x) = 0$.

               ($\Leftarrow$) Suppose conversely that $\nu(x) = 0$ for some
               unit $x$ in $F$. It suffices to show that $x^{-1} \in R$. This
               follows immediately because $\nu(x^{-1}) = -\nu(x) = -0 = 0$, so 
               that $x^{-1} \in R$. \qed

      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.27%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.27]  A specific example of a discrete valuation ring (cf. the
                  preceding exercise) is obtained when $p$ is a prime, $K = \Q$
                  and
                  $$\nu_p : \Q^\times \rightarrow \Z \text{ by }
                    \nu_p\left(\frac{a}{b}\right) = \alpha \text{ where }
                    \frac{a}{b} = p^\alpha\frac{c}{d}, \qquad p \nmid c
                    \text{ and } p \nmid d.$$
                  Prove that the corresponding valuation ring $R$ is the ring of
                  all rational numbers whose denominators are relatively prime
                  to $p$. Describe the units of this valuation ring.

      \textbf{Proof.} Let $R' = \left\{\frac{a}{b} \in \Q^\times : a, b \in \Z, 
      \gcd(b, p) = 1, a \neq 0, \text{ and } b \neq 0\right\} \cup \{0\}$. We 
      want to show that $R' = R$.

      $(\subseteq)$ Let $s_1 \in R'$. Then $s_1 = q_1/r_1$ for some integers
      $q_1$ and $r_1$ that satisfy the requirements in the definition of $R'$. 
      Since $p$ and $r_1$ are relatively prime, it follows that $p \nmid r_1$. 
      Let $\alpha_1$ be the largest integer such that $p^{\alpha_1}$ divides
      $q_1$. Observe that $\alpha_1 \ge 0$ because, for every negative integer
      $t$, $p^t$ is not an integer. Thus $s_1 = p^{\alpha_1}\frac{q_1'}{r_1}$, 
      where $q_1 = p^{\alpha_1}q_1'$ and $p \nmid q_1'$. Thus
      $\nu_p(s_1) = \alpha_1 \ge 0$, so that $s_1 \in R$ and we conclude that
      $R' \subseteq R$.
   
      $(\supseteq)$ Let $s_2 \in R$. Then $s_2 = q_2/r_2$, where $q_2$ and $r_2$
      are nonzero integers. Let $\alpha_2$ and $\beta_2$ be the largest integers
      such that $p^{\alpha_2} \mid q_2$ and $p^{\beta_2} \mid r_2$. Thus
      $s_2 = p^{\alpha_2-\beta_2}\frac{q_2'}{r_2'}$, where
      $q_2 = p^{\alpha_2}q_2'$, $r_2 = p^{\beta_2}r_2'$, $p \nmid q_2'$, and
      $p \nmid r_2'$. Since $s_2 \in R$, it follows that
      $\nu_p(s_2) = \alpha_2 - \beta_2 \ge 0$; i.e., $\alpha_2 \ge \beta_2$ and
      thus $p^{\alpha_2-\beta_2}$ is an integer. This says that
      $$s_2 = \frac{p^{\alpha_2-\beta_2}q_2'}{r_2'} \in R',$$
      so that $R' \supseteq R$.

      Since $R' \subseteq R$ and $R' \supseteq R$, we conclude that $R' = R$.

      (\textit{Units of $R$}.) By Exercise 7.1.26 (c), an element $x \in R$ is
      a unit in $R$ if and only if $\nu_p(x) = 0$ if and only if the numerator
      and denominator of $x$ are relatively prime to $p$.

      \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.28%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.28]  Let $R$ be a ring with $1 \neq 0$. A nonzero element $a$ is
                  called a \textit{left zero divisor} in $R$ if there is a
                  nonzero element $x \in R$ such that $ax = 0$. Symmetrically,
                  $b \neq 0$ is a \textit{right zero divisor} if there is a
                  nonzero $y \in R$ such that $yb = 0$ (so a zero divisor is an
                  element which is either a left or right zero divisor). An
                  element $u \in R$ has a \textit{left inverse} in $R$ if there
                  is some $s \in R$ such that $su = 1$. Symmetrically, $v$ has
                  a \textit{right inverse} if $vt = 1$ for some $t \in R$.
                  \begin{enumerate}
                     \item Prove that $u$ is a unit if and only if it has both a
                           right and a left inverse (i.e., $u$ must have a two
                           sided inverse).
                     \item Prove that if $u$ has right inverse then $u$ is not
                           a right zero divisor.
                     \item Prove that if $u$ has more than one right inverse
                           then $u$ is a left zero divisor.
                     \item Prove that if $R$ is a finite ring then every element
                           that has a right inverse is a unit (i.e., has a
                           two-sided inverse).
                  \end{enumerate}

      \textbf{Solution.}

      \begin{enumerate}
         \item \textbf{Proof.}

               ($\Rightarrow$) Suppose that $u \in R$ is a unit. Then it follows
               that $uu^{-1} = u^{-1}u = 1$, so that $u^{-1}$ is a both a right
               and left inverse of $u$.

               ($\Leftarrow$) Suppose conversely that $v$ is a left inverse and 
               $t$ is a right inverse of $u$. So we have that
               $$v = v \cdot 1 = v (ut) = (vu)t = 1 \cdot t = t.$$
               Thus $v$ is a left and right inverse of $u$, so that $u$ is a
               unit. \qed
         \item \textbf{Proof.} Suppose that $u \in R$ has a right inverse, say
               $x$. Now suppose to the contrary that $u$ is a right zero
               divisor. That is, there exists nonzero $y \in R$ such that
               $yu = 0$. So
               $$y = y \cdot 1 = y (ux) = (yu)x = 0 \cdot x = 0,$$
               a contradiction since $y \neq 0$. So $u$ is not a right zero
               divisor. \qed
         \item \textbf{Proof.} Suppose that for some $u \in R$, there exist two 
               nonequal elements in $R$, say $u'$ and $u''$ such that
               $uu' = uu'' = 1$. So $uu' - uu'' = 0$; that is,
               $u(u' - u'') = 0$. Now $u$ is nonzero because $0$ has no right 
               inverses and since $u' \neq u''$, it follows that
               $u' - u'' \neq 0$. Thus $u(u' - u'') = 0$ implies that $u$ is a 
               zero divisor. \qed
         \item Suppose that $R$ is finite. Let $x \in R$ be an element that has
               a right inverse (at least one exists, namely 1). Consider the map 
               $\alpha_x : R \rightarrow R$, defined by $r \mapsto rx$. We want
               to show that $\alpha_x$ is a bijection. Since $R$ is finite, it
               suffices to show that $\alpha_x$ is injective. So suppose that
               $\alpha_x(r_1) = \alpha_x(r_2)$ for some $r_1, r_2 \in R$. Thus
               $r_1x = r_2x$. Right multiply both sides of the equality
               $r_1x = r_2x$ by a right inverse of $x$ to conclude that
               $r_1 = r_2$. That is, $\alpha_x$ is injective, and thus, as we
               explained above, it is also bijective. So there exists $y \in R$
               such that $\alpha_x(y) = 1$. This says that $yx = 1$, so that
               $y$ is a left inverse of $x$. Since $x$ has left and right
               inverses, we conclude by (a) that $x$ is a unit. Thus every
               element in $R$ that has a right inverse is a unit. \qed
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.29%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.29]  Let $A$ be any commutative ring with identity $1 \neq 0$. Let
                  $R$ be the set of all group homomorphisms of the additive
                  group $A$ to itself with addition defined as pointwise
                  addition of functions and multiplication defined as function
                  composition. Prove that these operations make $R$ into a ring
                  with identity. Prove that the units of $R$ are the group
                  automorphisms of $A$ (cf. Exercise 20, Section 1.6).

      \textbf{Proof.} The set $R$ is nonempty because it contains the zero
      homomorphism; so let $f, g, h \in R$ and $a_1, a_2, a_3 \in A$.

      \textit{$(R, +)$ is an abelian group}.
      \begin{itemize}
         \item (\textit{$R$ is closed and commutative under addition}.) So we 
               have that
               \begin{align*}
                  (f + g)(a_1 + a_2) &= f(a_1 + a_2) + g(a_1 + a_2) \\
                     &= f(a_1) + f(a_2) + g(a_1) + g(a_2) &[f, g
                        \text{ are homomorphisms}] \\
                     &= f(a_1) + g(a_1) + f(a_2) + g(a_2) \\
                     &= (f + g)(a_1) + (f + g)(a_2),
               \end{align*}
               so that $f + g$ is a homomorphism and thus $f + g \in R$. That 
               is, $R$ is closed under addition. Interchanging the roles of
               $a_1$ and $a_2$ above and using the commutativity of addition in
               $A$, we get
               $$(f + g)(a_2 + a_1) = (f + g)(a_2) + (f + g)(a_1) =
                (f + g)(a_1) + (f + g)(a_2) = (f + g)(a_1 + a_2),$$
               so that $R$ is commutative under addition.
         \item (\textit{$R$ is associative under addition}.) Addition in $R$ is 
               associative because addition is associative in $A$.
         \item (\textit{Additive identity of $R$}.) The additive identity of $R$ 
               is the zero homomorphism.
         \item (\textit{Additive inverses of $R$}.) Consider
               $f' : A \rightarrow A$, $a \mapsto -f(a)$. So
               \begin{align*}
                  f'(a_1 + a_2) &= -[f(a_1 + a_2)] \\
                     &= -[f(a_1) + f(a_2)] &[f \text{ is an homomorphism}] \\
                     &= -f(a_1) + -f(a_2)   &[\text{Distributivity in }A] \\
                     &= f'(a_1) + f'(a_2)
               \end{align*}
               for every $a_1, a_2$ so that $f'$ is a homomorphism and this
               $f' \in R$. Clearly $f'$ is the additive inverse of $f$, so that 
               every element of $R$ has an additive inverse.         
      \end{itemize}
      We conclude from the arguments above that $R$ is an abelian group.

      (\textit{$R$ is closed under multiplication}.) Because
      \begin{align*}
         (fg)(a_1 + a_2) &= f(g(a_1 + a_2)) \\
                     &=  f(g(a_1) + g(a_2)) &[g \text{ is a homomorphism}] \\
                     &=  f(g(a_1)) + f(g(a_2)) &[f \text{ is a homomorphism}] \\
                     &= (fg)(a_1) + (fg)(a_2),
      \end{align*}
      $fg$ is a homomorphism, so that $fg \in R$. That is, $R$ is closed under
      multiplication.

      (\textit{$R$ is associative under multiplication}.) $R$ is associative 
      under multiplication because function composition is generally 
      associative.

      (\textit{Distributivity in $R$}.) Left distributivity holds because
      \begin{align*}
         (f(g + h))(a_1) &= f((g + h)(a_1)) \\
            &= f(g(a_1) + h(a_1)) \\
            &= f(g(a_1)) + f(h(a_1)) &[f \text{ is a homomorphism}] \\
            &= (fg)(a_1) + (fh)(a_1),
      \end{align*}
      so that $f(g + h) = fg + fh$; similarly, Left distributivity holds because
      \begin{align*}
         ((g + h)f)(a_1) &= (g + h)(f(a_1)) \\
            &= g(f(a_1)) + g(f(a_1)) \\
            &= (gf)(a_1) + (gf)(a_1),
      \end{align*}
      so that $(g + h)f = gf + hf$. Thus distributivity holds in $R$.

      (\textit{The multiplicative identity of $R$}.) The multiplicative identity 
      of $R$ is the identity homomorphism.

      We conclude from the above that $R$ is a unital ring.

      (\textit{The units of $R$}.) Let $\alpha$ be a unit of $R$. (there exists
      at least one, namely the identity homomorphism) So there exists
      $\beta \in R$ such that $\alpha\beta = \beta\alpha = 1$. That is, $\alpha$
      has a left and right inverse. Thus $\alpha$ is bijective by Proposition
      0.1 (3); i.e., $\alpha$ is an automorphism of $A$. Conversely, if $\alpha$
      is an automorphism of $A$, then it is bijective, so that it has a left and
      right inverse, and thus, is a unit. Thus the units in $R$ are the
      automorphisms of $A$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.1.30%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.1.30]  Let $A = \Z \times \Z \times \Z \times \cdots$ be the direct
                  product of copies of $\Z$ indexed by the positive integers (so
                  $A$ is a ring under componentwise addition and muliplication)
                  and let $R$ be the ring of all group homomorphisms from $A$ to
                  itself as described in the preceding exercise. Let $\varphi$
                  be the element of $R$ defined by
                  $\varphi(a_1, a_2, a_3, \ldots) = (a_2, a_3, \ldots)$. Let
                  $\psi$ be the element of $R$ defined by
                  $\psi(a_1, a_2, a_3, \ldots) = (0, a_1, a_2, a_3, \ldots)$.
                  \begin{enumerate}
                     \item Prove that $\varphi\psi$ is the identity of $R$ but
                           $\psi\varphi$ is not the identity of $R$ (i.e.,
                           $\psi$ is a \textit{right inverse} for $\varphi$ but
                           not a left inverse).
                     \item Exhibit infinitely many right inverses for $\varphi$.
                     \item Find a nonzero element $\pi$ in $R$ such that
                           $\varphi\pi = 0$ but $\pi\varphi \neq 0$.
                     \item Prove that there is no nonzero element
                           $\lambda \in R$ such that $\lambda\varphi = 0$ (i.e.,
                           $\varphi$ is a left zero divisor but not a right zero
                           divisor).
                  \end{enumerate}

      \textbf{Solution.} Let $a = (a_1, a_2, a_3, \ldots)$ and
      $b = (b_1, b_2, b_3, \ldots)$ be sequences of integers in $A$.

      \begin{enumerate}
         \item \textbf{Proof.} We have
               \begin{align*}
                  (\varphi\psi)(a) &= \varphi(\psi(a)) \\
                     &= \varphi(0, a_1, a_2, a_3, \ldots) \\
                     &= (a_1, a_2, a_3, \ldots) \\
                     &= a.
               \end{align*}
               That is, $\varphi\psi$ is the identity of $R$. But $\psi\varphi$
               is not the identity of $R$ because
               \begin{align*}
                  (\psi\varphi)(1, 0, 0, \ldots) &=
                     \psi(\varphi(1, 0, 0, \ldots)) \\
                     &= \psi(0, 0, 0, \ldots) \\
                     &= (0, 0, 0, \ldots) \\
                     &\neq (1, 0, 0, \ldots).
               \end{align*} \qed
         \item \textbf{Proof.} For every $z \in \Z^+$, let
               $\psi_z(a_1, a_2, a_3, \ldots) = (a_z, a_1, a_2, a_3, \ldots)$.
               The map $\psi_z$ is a homomorphism because
               \begin{align*}
                  \psi_z(a + b) &= \psi(a_1 +b_1, a_2+b_2, a_3 + b_3, \ldots) \\
                     &= (a_z + b_z, a_1 + b_1, a_2 + b_2, a_3 + b_3, \ldots) \\
                     &= (a_z, a_1, a_2, a_3, \ldots) +
                        (b_z, b_1, b_2, b_3, \ldots) \\
                     &= \psi_z(a_1, a_2, a_3, \ldots) +
                        \psi_z(b_1, b_2, b_3, \ldots) \\
                     &= \psi_z(a) + \psi_z(b).
               \end{align*}

               Now follow the procedure in (a) to conclude that $\psi_z$ is a 
               right inverse for $\varphi$ for each positive integer $z$. Let
               $x$ and $y$ be different positive integers and
               $c = (c_1, c_2, c_3, \ldots)$ the sequence of 
               integers such that $c_x = x$ and $c_y = y$; then the element in
               the 1st slot of $\psi_x(c)$ is $x$ while the first element of
               $\psi_y(c) = y$, so that $\psi_x \neq \psi_y$. Thus there are an
               infinite number of right inverses $\psi_z$. \qed
         \item \textbf{Proof.} Let $\pi = \psi_2 - \psi_1$. The function $\pi$ 
               is nonzero because it maps $(1, 0, 0, \ldots)$ to
               $(-1, 0, 0, \ldots)$. So we have that
               \begin{align*}
                  (\varphi\pi)(a_1, a_2, a_3, \ldots) &=
                     \varphi(\pi(a_1, a_2, a_3, \ldots)) \\
                     &= \varphi((\psi_2 - \psi_1)(a_1, a_2, a_3, \ldots)) \\
                     &= \varphi(\psi_2(a_1, a_2, a_3, \ldots) -
                        \psi_1(a_1, a_2, a_3, \ldots)) \\
                     &= \varphi((a_2, a_1, a_2, a_3, \ldots) -
                           (a_1, a_1, a_2, a_3, \ldots)) \\
                     &= \varphi(a_2-a_1, 0, 0, 0, \ldots) \\
                     &= 0.
               \end{align*}
               But $\pi\varphi$ is not 0 because
               \begin{align*}
                  (\pi\varphi)(0, 1, 0, 0, 0, \ldots) &=
                     \pi(\varphi(0, 1, 0, 0, 0 \ldots)) \\
                     &= \pi(1, 0, 0, 0, \ldots) \\
                     &= (\psi_2 - \psi_1)(1, 0, 0, 0, \ldots) \\
                     &= \psi_2(1, 0, 0, 0, \ldots)-\psi_1(1, 0, 0, 0, \ldots) \\
                     &= (0, 1, 0, 0, 0, \ldots) - (1, 1, 0, 0, 0, \ldots) \\
                     &= (-1, 0, 0, 0, 0, \ldots) \\
                     &\neq (0, 0, 0, \ldots).
               \end{align*} \qed
         \item \textbf{Proof.} By Exercise 7.1.28 (b), $\varphi$ is not a right 
               zero divisor; thus no nonzero $\lambda \in R$ exists such that
               $\lambda\varphi = 0$. \qed
      \end{enumerate}
\end{enumerate}
