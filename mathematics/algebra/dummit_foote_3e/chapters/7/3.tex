Let $R$ be a ring with identity $1 \neq 0$.

%%%%%%%%%%%%%%%%%%10c is wrong%%%%%%%%%%%%%%%%%%

\begin{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.1%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.1]   Prove that the rings $2\Z$ and $3\Z$ are not isomorphic.

      \textbf{Proof.} Suppose to the contrary that $2\Z$ and $3\Z$ are
      isomorphic. Thus there exists a ring isomorphism
      $\alpha : 2\Z \rightarrow 3\Z$. Let $a \in 2\Z$, so that $a = 2a'$ for
      some integer $a'$. Since $\alpha$ is also an additive group homomorphism,
      it follows by Exercise 1.6.1(b) that
      $\alpha(a) = \alpha(a' \cdot 2) = a' \cdot \alpha(2)$. If $\alpha(2) = 0$,
      then $\alpha$ is the zero homomorphism so that $\alpha$ is not surjective,
      a contradiction; thus $\alpha(2) \neq 0$. Now we have that
      $$\alpha(4) = \alpha(2 \cdot 2) = \alpha(2) \cdot
        \alpha(2) = \alpha(2)^2$$
      and
      $$\alpha(4) = \alpha(2 \cdot 2) = 2 \cdot \alpha(2)$$
      so that $\alpha(2)^2 = 2\cdot\alpha(2)$, and thus, $\alpha(2) = 2$, a
      contradiction because $2 \notin 3\Z$. So no such isomorphism exists, and
      we conclude that $2\Z \not\cong 3\Z$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.2%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.2]   Prove that the rings $\Z[x]$ and $\Q[x]$ are not isomorphic.

      \textbf{Proof.} Suppose to the contrary that $\Z[x]$ and $\Q[x]$ are
      isomorphic. Thus there exists a ring isomorphism
      $\alpha : \Z[x] \rightarrow \Q[x]$. Since $\Q$ is an integral domain, it
      follows by Proposition 7.4(3) that $\Q[x]$ is an integral domain, so that
      $\alpha(1) = 1$ by Exercise 7.3.17(a). Let $z$ be an integer. Since
      $\alpha$ is also an additive group homomorphism, it follows by Exercise
      1.6.1(b) that $\alpha(z) = \alpha(z \cdot 1) = z \cdot \alpha(1) = z$. Let
      $q$ be an arbitrary nonintegral rational constant polynomial in $\Q[x]$.
      Since $\alpha$ is surjective, there exists a polynomial of degree $n$, say
      $y = y_0 + y_1x + \cdots + y_nx^n \in \Z[x]$ such that $\alpha(y) = q$.
      Observe that $n \ge 1$, for if $n = 0$, then $\alpha(y_0) = y_0 \neq q$
      because $y_0$ is an integer. Since $\alpha$ is a ring homomorphism, it 
      follows that
      \begin{align*}
         \alpha(y) &= \alpha(y_0 + y_1x + \cdots + y_nx^n) \\
            &= \alpha(y_0) + \alpha(y_1x) + \cdots + \alpha(y_nx^n) \\
            &= \alpha(y_0) + \alpha(y_1)\alpha(x) + \cdots +
               \alpha(y_n)\alpha(x^n) \\
            &= y_0 + y_1\alpha(x) + \cdots + y_n\alpha(x)^n.
      \end{align*}
      If $\alpha(x) = 0$, then $\alpha(y) = y_0$, a contradiction since $y_0$ is
      an integer. So $\alpha(x) \neq 0$; now let $m$ be the degree of
      $\alpha(x)$. Thus, the degree of $\alpha(y)$ is $mn$. But since the degree
      of $q$ is 0, it follows that $mn = 0$. Hence $m = 0$ because $n \neq 0$.
      That is, the degree of $\alpha(x)$ is 0, so that $\alpha(x)$ is a nonzero
      rational number. Thus $\alpha(\Z[x]) \subseteq \Q$, so that $\alpha$ is
      not surjective, a contradition. We thus conclude that
      $\Z[x]\not\cong \Q[x]$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.3%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.3]   Find all homomorphic images of $\Z$.

      \textbf{Solution.} Let $S$ be a ring and let $\alpha : \Z \rightarrow S$
      be an homomorphism of rings. Let $K$ be the kernel of $\Z$. Then it
      follows by Example 3 (Page 243) that $K = n\Z$ for some nonnegative
      integer $n$. By The First Isomorphism Theorem for Rings, we have that
      $\Z/n\Z \cong \alpha(\Z)$. Thus the image of every ring homomorphism from
      $\Z$ to another ring is isomorphic to $\Z/n\Z$ for some nonnegative
      integer $n$. For a nonnegative integer $m$, let $S = \Z/m\Z$, so that
      $\alpha(\Z) \cong \Z/m\Z$ by Theorem 7.7.2. That is, the set of the
      homomorphic images of $\Z$ is:
      $\{\Z/x\Z : x \text{ is a nonnegative integer}\}$.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.4%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.4]   Find all ring homomorphisms from $\Z$ to $\Z/30\Z$. In each
                  case describe the kernel and the image.

      \textbf{Solution.} There exist at least two ring homomorphisms from $\Z$
      to $\Z/30\Z$, namely the zero ring homomorphism and natural projection, so
      let $\alpha : \Z \rightarrow \Z/30\Z$ be a ring homomorphism. Let
      $a, b \in \Z$. Exercise 1.6.1(b) tells us that
      $\alpha(n) = \alpha(n \cdot 1) = \overline{n} \cdot \alpha(1)$ for every 
      integer $n$. So $\alpha$ is completely determined by $\alpha(1)$. Observe 
      that $\alpha$ is a group homomorphism for any value of $\alpha(1)$ because
      \begin{align*}
         \alpha(a + b) &= (\overline{a + b}) \cdot \alpha(1) \\
            &= (\overline{a} + \overline{b}) \cdot \alpha(1) \\
            &= \overline{a} \cdot \alpha(1) + \overline{b} \cdot \alpha(1) \\
            &= \alpha(a) + \alpha(b).            
      \end{align*}
      Now we must also have that
      \begin{align*}
         \overline{ab} \cdot \alpha(1) &= \alpha(ab) \\
            &= \alpha(a)\alpha(b) \\
            &= \overline{a}\cdot\alpha(1)\cdot\overline{b}\cdot\alpha(1) \\ 
            &= \overline{ab}\cdot\alpha(1)^2,           
      \end{align*}
      so that $\overline{ab}(\alpha(1)^2 - \alpha(1)) = \overline{0}$ for all
      $\overline{a}, \overline{b} \in \Z/30\Z$. That is,
      $\alpha(1)^2 - \alpha(1) = \overline{0}$, and we conclude that $\alpha$ is
      a ring homomorphism if and only if $\alpha(1)$ is idempotent under
      multiplication. The idempotents in $\Z/30\Z$ are:
      $$0, 1, 6, 10, 15, 16, 21, \text{ and } 25,$$
      so that there are 8 homomorphisms from $\Z$ to $\Z/30$. We summarize our
      findings below:
      $$
      \begin{tabular}{@{}|c|c|@{}} \hline
         $\alpha(1)$ & Kernel \\ \hline
         0 & $\Z$ \\ \hline
         1 & $30\Z$ \\ \hline
         6 & $5\Z$ \\ \hline
         10 & $3\Z$ \\ \hline
         15 & $2\Z$ \\ \hline
         16 & $15\Z$ \\ \hline
         21 & $10\Z$ \\ \hline
         25 & $6\Z$ \\ \hline
      \end{tabular}
      $$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.5%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.5]   Describe all ring homomorphisms from the ring $\Z \times \Z$
                  to $\Z$. In each case describe the kernel and the image.

      \textbf{Solution.} We want to find a nonzero ring homomorphism from
      $\Z\times\Z$ to $\Z$. Suppose one exists and call it $\alpha$. Let
      $a, b \in \Z\times\Z$, so that $a = (a_1, a_2)$ and $b = (b_1, b_2)$ for
      some integers $a_1, a_2, b_1$, and $b_2$. So we have that
      \begin{align*}
         \alpha(a) &= \alpha(a_1, a_2) \\
            &= \alpha((a_1, 0) + (0, a_2)) \\
            &= \alpha(a_1, 0) + \alpha(0, a_2) &[\alpha
                  \text{ is a group homomorphism}] \\
            &= \alpha(a_1 \cdot( 1, 0)) + \alpha(a_2 \cdot (0, 1))  \\
            &= a_1 \cdot \alpha(1, 0) + a_2 \cdot \alpha(0, 1),
                  &[\text{Exercise 1.6.1(b)}]
      \end{align*}
      so that $\alpha$ is completely determined by $\alpha(1, 0)$ and
      $\alpha(0, 1)$. Now observe that $\alpha$ is a group homomorphism
      independent of the values of $\alpha(1, 0)$ and $\alpha(0, 1)$ because
      \begin{align*}
         \alpha(a + b) &= \alpha((a_1, a_2) + (b_1, b_2)) \\
            &= \alpha(a_1 + b_1, a_2 + b_2) \\
            &= (a_1 + b_1) \cdot \alpha(1, 0) + (a_2 + b_2) \cdot\alpha(0, 1) \\
            &= a_1 \cdot \alpha(1, 0) + b_1 \cdot \alpha(1, 0) +
               a_2 \cdot \alpha(0, 1) + b_2 \cdot \alpha(0, 1) \\
            &= \alpha(a_1, 0) +\alpha(b_1, 0) +\alpha(0, a_2) +\alpha(0, b_2) \\
            &= \alpha(a_1, 0) +\alpha(0, a_2) +\alpha(b_1, 0) +\alpha(0, b_2) \\
            &= \alpha(a_1, a_2) + \alpha(b_1, b_2) \\
            &= \alpha(a) + \alpha(b).
      \end{align*}
   
      Since $\Z$ is an integral domain an $\alpha$ is nonzero, it follows by
      Exercise 7.3.17(a) that $\alpha(1, 1) = 1$. So
      $1 = \alpha(1, 1) = \alpha(1, 0) + \alpha(0, 1)$. Also
      \begin{align*}
         \alpha(1, 0) &= \alpha((1, 0) \cdot (1, 0)) \\
            &= \alpha(1, 0) \cdot \alpha(1, 0)
                  &[\alpha \text{ is a ring homomorphism}] \\
            &= \alpha(1, 0)^2,
      \end{align*}
      so that $\alpha(1, 0)^2 - \alpha(1, 0) = 0$; i.e.,
      $\alpha(1, 0) \cdot (\alpha(1, 0) - 1) = 0$. Since $\Z$ is an integral
      domain, it follows that $\alpha(1, 0) = 0$ or $\alpha(1, 0) = 1$.
      Replace $(1, 0)$ with $(0, 1)$ in the procedure above to conclude
      similarly that  $\alpha(0, 1) = 0$ or $\alpha(0, 1) = 1$. Recall that
      $\alpha(1, 0) + \alpha(0, 1) = 1$, so it follows that
      $$\alpha(1, 0) = 1 \text{ and } \alpha(0, 1) = 0$$
      or
      $$\alpha(1, 0) = 0 \text{ and } \alpha(0, 1) = 1.$$

      Suppose first that the former holds. So we have that
      \begin{align*}
         \alpha(ab) &= \alpha((a_1, a_2)(b_1, b_2)) \\
            &= \alpha(a_1b_1, a_2b_2) \\
            &= a_1b_1 \cdot \alpha(1, 0) + a_2b_2 \cdot \alpha(0, 1) \\
            &= a_1b_1 \cdot 1 + a_2b_2 \cdot 0 \\
            &= a_1b_1 \\
            &= (a_1 \cdot 1 + a_2 \cdot 0)(b_1 \cdot 1 + b_2 \cdot 0) \\
            &= (a_1 \cdot \alpha(1, 0) + a_2 \cdot \alpha(0, 1))
               (b_1 \cdot \alpha(1, 0) + b_2 \cdot \alpha(0, 1)) \\
            &= (\alpha(a_1, 0) + \alpha(0, a_2))
               (\alpha(b_1, 0) + \alpha(0, b_2)) \\
            &= (\alpha(a_1, a_2))(\alpha(b_1, b_2)) \\
            &= \alpha(a)\alpha(b).
      \end{align*}
      However, if the latter holds, use the same procedure above to conclude
      that $\alpha(ab) = \alpha(a)\alpha(b)$. Thus we have shown that $\alpha$
      is a nonzero ring homomorphism if and only if exactly one of
      $\alpha(1, 0)$ and $\alpha(0, 1)$ is 0 while the other is 1. So there are
      two such nonzero ring homomorphisms for a total of three ring
      homomorphisms (if we include the zero homomorphism). We tabulate our
      results:
      $$
      \begin{tabular}{@{}|c|c|c|@{}} \hline
         $\alpha(1, 0)$ & $\alpha(0, 1)$ & Kernel \\ \hline
         0 & 0 & $\Z\times\Z$ \\ \hline
         1 & 0 & $\{0\}\times\Z$ \\ \hline
         0 & 1 & $\Z\times\{0\}$ \\ \hline
      \end{tabular}
      $$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.6%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.6]   Decide which of the following are ring homomorphisms from
                  $M_2(\Z)$ to $\Z$:
                  \begin{enumerate}
                     \item $\left(\begin{tabular}{@{}cc@{}}
                              $a$ & $b$ \\
                              $c$ & $d$
                           \end{tabular}\right) \mapsto a$ (projection onto the
                           1,1 entry)
                     \item $\left(\begin{tabular}{@{}cc@{}}
                              $a$ & $b$ \\
                              $c$ & $d$
                           \end{tabular}\right) \mapsto a + d$ (the
                           \textit{trace} of the matrix)
                     \item $\left(\begin{tabular}{@{}cc@{}}
                              $a$ & $b$ \\
                              $c$ & $d$
                           \end{tabular}\right) \mapsto ad - bc$ (the
                           \textit{determinant} of the matrix).
                  \end{enumerate}

      \textbf{Solution.}

      \begin{enumerate}
         \item Consider the map $\alpha : M_2(\Z) \rightarrow \Z$, defined by
               $(a_{ij}) \mapsto a_{11}$. Let $A \in M_2(\Z)$, such that every
               entry of $A$ is 1. It follows immediately that $\alpha$ is not a
               ring homomorphism because
               $$\alpha(A^2) = 2 \neq 1 = \alpha(A) \cdot \alpha(A).$$
         \item Consider the map $\alpha : M_2(\Z) \rightarrow \Z$, defined by
               $(a_{ij}) \mapsto a_{11} + a_{22}$. Let $A, B \in M_2(\Z)$, such 
               that the only nonzero entry of $A$ is the 2, 1 entry which is 1
               and the only nonzero entry of $B$ is the 1, 2 entry which is also
               1. It follows immediately that $\alpha$ is not a ring
               homomorphism because
               $$\alpha(AB) = 1 \neq 0 = \alpha(A) \cdot \alpha(B).$$
         \item Consider the map $\alpha : M_2(\Z) \rightarrow \Z$, defined by
               $(a_{ij}) \mapsto a_{11}a_{22} - a_{12}a_{21}$. Let
               $A \in M_2(\Z)$ be an upper triangular matrix such that every
               entry on and above the main diagonal is 1. It follows immediately 
               that $\alpha$ is not a ring homomorphism because
               $$\alpha(A + A) = 4 \neq 2 = \alpha(A) + \alpha(A).$$
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.7%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.7]   Let $R = \left\{\left(\begin{tabular}{@{}cc@{}}
                     $a$ & $b$ \\
                     0 & $d$
                  \end{tabular}\right) : a, b, d \in \Z\right\}$ be the subring
                  of $M_2(\Z)$ of upper triangular matrices. Prove that the map
                  $$\varphi : R \rightarrow \Z \times \Z \text{ defined by }
                    \varphi : \left(\begin{tabular}{@{}cc@{}}
                     $a$ & $b$ \\
                      0  & $d$
                  \end{tabular}\right) \rightarrow (a, d)$$
                  is a surjective homomorphism and describe its kernel.

      \textbf{Proof.} Let $A = \left(\begin{tabular}{@{}cc@{}}
         $a_{11}$ & $a_{12}$ \\
         0  & $a_{22}$
      \end{tabular}\right) \text{ and } B =  \left(\begin{tabular}{@{}cc@{}}
         $b_{11}$ & $b_{12}$ \\
         0  & $b_{22}$
      \end{tabular}\right)$ be elements of $R$. It follows that $\varphi$ is a
      surjective ring homomorphism because
      
      \textbf{additive:}
      \begin{align*}
         \varphi(A + B) &= \varphi\left(\begin{tabular}{@{}cc@{}}
            $a_{11} + b_{11}$ & $a_{12} + b_{12}$ \\
            0  & $a_{22} + b_{22}$
         \end{tabular}\right) \\
         &= (a_{11} + b_{11}, a_{22} + b_{22}) \\
         &= (a_{11}, a_{22}) + (b_{11}, b_{22}) \\
         &= \varphi\left(\begin{tabular}{@{}cc@{}}
            $a_{11}$ & $a_{12}$ \\
            0 & $a_{22}$
         \end{tabular}\right) + \varphi\left(\begin{tabular}{@{}cc@{}}
            $b_{11}$ & $b_{12}$ \\
            0 & $b_{22}$
         \end{tabular}\right) \\
         &= \varphi(A) + \varphi(B)
      \end{align*}
      
      \textbf{multiplicative:}
      \begin{align*}
         \varphi(AB) &= \varphi\left(\begin{tabular}{@{}cc@{}}
            $a_{11}b_{11}$ & $a_{11}b_{12} + a_{12}b_{22}$  \\
            0  & $a_{22}b_{22}$
         \end{tabular}\right) \\
         &= (a_{11}b_{11}, a_{22}b_{22}) \\
         &= (a_{11}, a_{22}) \cdot (b_{11}, b_{22}) \\
         &= \varphi\left(\begin{tabular}{@{}cc@{}}
            $a_{11}$ & $a_{12}$ \\
            0 & $a_{22}$
         \end{tabular}\right)\varphi\left(\begin{tabular}{@{}cc@{}}
            $b_{11}$ & $b_{12}$ \\
            0 & $b_{22}$
         \end{tabular}\right) \\
         &= \varphi(A)\varphi(B)
      \end{align*}
      
      \textbf{surjective:} for $(x, y) \in \Z\times\Z$, we have that
      $\varphi\left(\begin{tabular}{@{}cc@{}}
            $x$ & 0 \\
            0 & $y$
      \end{tabular}\right) = (x, y)$.

      The kernel of $\varphi$ is the set of strictly upper triangular matrices
      in $R$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.8%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.8]   Decide which of the following are ideals of the ring
                  $\Z \times \Z$:
                  \begin{enumerate}
                     \item $\{(a, a) : a \in \Z\}$
                     \item $\{(2a, 2b) : a, b \in \Z\}$
                     \item $\{(2a, 0) : a \in \Z\}$
                     \item $\{(a, -a) : a \in \Z\}$.
                  \end{enumerate}

      \begin{enumerate}
         \item The set $I = \{(a, a) : a \in \Z\}$ is not an ideal of
               $\Z\times\Z$ because $(1, 1) \in I$ but
               $(1, 0) \cdot (1, 1) = (1, 0) \notin I$.
         \item We claim that $I = \{(2a, 2b) : a, b \in \Z\}$ is an ideal of
               $\Z\times\Z$.

               \textbf{Proof.} Let $x, y \in I$, so that $x = (2c, 2d)$ and
               $y = (2s, 2t)$ for some integers $c, d, s$, and $t$.

               \textbf{nonempty:} $(0, 0) \in I$.

               \textbf{closure under addition:} We have that
               $$x + y = (2c, 2d) + (2s, 2t) = (2c', 2d') \in I,$$
               where $c' = c + s$ and $d' = d + t$.

               \textbf{closure under multiplication by elements of
               $\Z\times\S$:} Since $\Z\times\Z$ is commutative, we shall only
               show closure by left multiplication; so let $r \in \Z\times\Z$.
               Then $r = (2p, 2q)$ for some integers $p$ and $q$. It follows
               that
               $$r\cdot x = (2p, 2q)(2c, 2d) = (2p', 2q') \in I,$$
               where $p' = 2pc$ and $q' = 2dq$. Thus $I$ is an ideal of
               $\Z\times\Z$. \qed
         \item We claim that $I = \{(2a, 0) : a \in \Z\}$ is an ideal of
               $\Z\times\Z$.

               \textbf{Proof.}

               \textbf{nonempty:} $(0, 0) \in I$, so let $x, y \in I$, so that
               $x = (2b, 0)$ and $y = (2c, 0)$ for some integers $b$ and $c$.

               \textbf{closure under addition:} We have that
               $$x + y = (2b, 0) + (2c, 0) = (2b', 0) \in I,$$
               where $b' = b + c$.

               \textbf{closure under multiplication by elements of
               $\Z\times\Z$:} Since $\Z\times\Z$ is commutative, we shall only
               show closure by left multiplication; so let $r \in \Z\times\Z$.
               Then $r = (2d, 0)$ for some integer $d$. It follows that
               $$r\cdot x = (2d, 0)(2b, 0) = (2t, 0) \in I,$$
               where $t = 2bd$. Thus $I$ is an ideal of $\Z\times\Z$. \qed
         \item The set $I = \{(a, -a) : a \in \Z\}$ is not an ideal of
               $\Z\times\Z$ because $(1, -1) \in I$ but
               $(1, 0) \cdot (1, -1) = (1, 0) \notin I$.
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.9%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.9]   Decide which of the sets in Exercise 6 of Section 1 are ideals
                  of the ring of all functions from $[0, 1]$ to $\R$.

      \textbf{Solution.} We shall let $S$ denote each of the sets (as we did in
      Exercise 7.1.6) and let $R$ denote the ring of all functions from $[0, 1]$
      to $\R$.

      \begin{enumerate}
         \item We claim that $S$ is an ideal $R$.

               \textbf{Proof.}

               \textbf{nonempty and closure under addition:} This follows from 
               Exercise 7.1.6(a).

               \textbf{closure under multiplication by elements of $R$:} Let
               $f \in R$ and $g \in S$. Let $q$ be a rational number in
               $[0, 1]$. Since $\R$ is commutative and $g(q) = 0$, it follows
               that $(fg)(q) = f(q)g(q) = 0 = g(q)f(q) = (gf)(q)$, so that
               $fg, gf \in S$. We conclude that $S$ is an ideal of $R$. \qed
         \item The set $S$ is not an ideal of $R$ because the function
               $f(x) = x \in S$, but $\sin(x)f(x)$ is not a member of $S$.
         \item Exercise 7.1.6(c) says that $S$ is not closed under addition, so
               it is not an ideal of $R$.
         \item Exercise 7.1.6(d) says that $S$ is not closed under addition, so
               it is not an ideal of $R$.
         \item Consider the function
               \begin{equation*}
                  g(x) = \left\{
                     \begin{array}{cl}
                        0 & \text{if } x = 1,\\ \\
                        \frac{1}{x-1} & \text{if } x \in [0, 1)
                     \end{array} \right.
               \end{equation*}
               Clearly, $g \in R$ and $f(x) = x - 1 \in S$, but $gf \notin S$ 
               because $\lim_{x\rightarrow1^-}g(x)f(x) = 1 \neq 0$. Thus $S$ is
               not an ideal of $R$.
         \item The set $S$ is not an ideal of $R$ because $\sin(x) \in S$ but
               $x \cdot \sin(x) \notin S$.
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.10%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.10]  Decide which of the following are ideals of the ring $\Z[x]$:
                  \begin{enumerate}
                     \item the set of all polynomials whose constant term is a
                           multiple of 3
                     \item the set of all polynomials whose coefficient of $x^2$
                           is a multiple of 3
                     \item the set of all polynomials whose constant term,
                           coefficient of $x$ and coefficient of $x^2$ are zero
                     \item $\Z[x^2]$ (i.e., the polynomials in which only even
                           powers of $x$ appear)
                     \item the set of polynomials whose coefficients sum to
                           zero
                     \item the set of polynomials $p(x)$ such that $p'(0) = 0$,
                           where $p'(x)$ is the usual first derivative of $p(x)$
                           with respect to $x$.
                  \end{enumerate}

      \textbf{Solution.} For convenience, we shall let $S$ denote each of the
      sets. Let
      $$p(x) = \sum_{k=0}^tp_kx^k \in \Z[x]$$
      be a polynomial of degree $t$. For those that are ideals, we shall only
      show closure under left multiplication by elements of $\Z[x]$ because
      $\Z[x]$ is commutative.

      \begin{enumerate}
         \item We claim that $S$ is an ideal of $\Z[x]$.

               \textbf{Proof.} 

               \textbf{nonempty:} $S$ contains the constant polynomial 3, so let
               $q, r \in S$, where $q_0$ and $r_0$ are the constant terms of $q$
               and $r$. 

               \textbf{closure under addition:} The constant
               term of $q + r$ is $q_0 + r_0$, a multiple of 3 since $q_0$ and
               $r_0$ are both multiples of 3; thus $q + r \in S$.

               \textbf{closure under multiplication by elements of $R$:} The
               constant term of $p \cdot q$ is $p_0q_0$, a multiple of 3 since
               $q_0$ is a multiple of 3. Thus $pq \in S$. We conclude that $S$
               is an ideal of $\Z[x]$. \qed
         \item The set $S$ is not an ideal because it is not closed under
               muliplication.

               \textbf{counterexample:} $x \in S$, but
               $x \cdot x = x^2 \notin S$.
         \item The set $S$ is not an ideal because it is not closed under
               addition.

               \textbf{counterexample:} $x^3, -x^3 \in S$, but
               $x^3 + (-x^3) = 0 \notin S$.
         \item The set $S$ is not an ideal because it is not closed under
               multiplication by elements of $\Z[x]$.

               \textbf{counterexample:} For $x \in \Z[x]$ and $x^2 \in S$, we
               have $x \cdot x^2 = x^3 \notin S$.
         \item We claim that $S$ is an ideal of $\Z[x]$.

               \textbf{Proof.} 

               \textbf{nonempty:} $S$ contains 0; so let
               $$q = q_0 + \cdots + q_nx^n, r = r_0 + \cdots + r_mx^m \in S$$
               be polynomials of degree $n$ and $m$ in $S$, where $n \le m$;
               i.e., $q_0 + \cdots + q_n = r_0 + \cdots + r_m = 0$.

               \textbf{closure under addition:} Assume without loss of
               generality that $n \le m$. It follows immediately that
               $q + r \in S$ because its coefficient is 0; that is,
               $$(q_0 + r_0) + \cdots + (q_m + r_m) = 0.$$

               \textbf{closure under multiplication by elements of $R$:} The
               sum of the coefficients of $p \cdot q$ is
               $(p_0 + \cdots + p_t)(q_0 + \cdots + q_n)$ and this product
               equals 0 because the sum of the coefficients of $q$ is 0. Thus
               $p \cdot q \in S$. Thus $S$ is an ideal of $\Z[x]$. \qed
         \item The set $S$ is not an ideal because it is not closed under
               multiplication by elements of $\Z[x]$.

               \textbf{counterexample:} Let $q(x) = x^2 + 1$ and $r(x) = 7x$ be
               polynomials in $\Z[x]$. Since $q'(0) = 0$, it follows that
               $q(x) \in S$; using the chain rule, we have that
               $$(rq)'(0) = r'(0)q(0) + r(0)q'(0) = 7 \neq 0,$$
               so that $r \cdot q \notin S$.
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.11%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.11]  Let $R$ be the ring of all continuous real valued functions on
                  the closed interval $[0, 1]$. Prove that the map
                  $\varphi : R \rightarrow \R$ defined by
                  $\varphi(f) = \int_0^1f(t)dt$ is a homomorphism of additive
                  groups but not a ring homomorphism.

      \textbf{Proof.} Let $f, g \in R$. Since $f$ and $g$ are continuous real
      valued functions on $[0, 1]$, it follows by the Linearity Property of the
      integral that
      $$\int_0^1f(t)\,dt + \int_0^1g(t)\,dt = \int_0^1[f(t) + g(t)]\,dt,$$
      so that $\varphi(f) + \varphi(g) = \varphi(f + g)$. Thus $\varphi$ is a
      homomorphism of additive groups; however $\varphi$ is not a ring
      homomorphism because for $h \in \R$, where $h(x) = x$, we have
      $$\varphi(h\cdot h) = \int_0^1 t^2\,dt = \frac{1}{3} \neq \frac{1}{4} =
        \int_0^1 t\,dt \cdot \int_0^1 t\,dt = \varphi(h) \cdot \varphi(h).$$
      \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.12%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.12]  Let $D$ be an integer that is not a perfect square in $\Z$ and
                  let $S = \left\{\left(\begin{tabular}{@{}cc@{}}
                     $a$ & $b$ \\
                     $Db$  & $a$
                  \end{tabular}\right) : a, b \in \Z\right\}$.
                  \begin{enumerate}
                     \item Prove that $S$ is a subring of $M_2(\Z)$.
                     \item If $D$ is not a perfect square in $\Z$ prove that the
                           map $\varphi : \Z[\sqrt{D}] \rightarrow S$ defined by
                           $\varphi(a + b\sqrt{D}) =
                            \left(\begin{tabular}{@{}cc@{}}
                               $a$ & $b$ \\
                               $Db$  & $a$
                           \end{tabular}\right)$ is a ring isomorphism.
                     \item If $D \equiv 1$ mod 4 is squarefree, prove that the
                           set $\left\{\left(\begin{tabular}{@{}cc@{}}
                              $a$ & $b$ \\
                              $(D-1)b/4$  & $a+b$
                           \end{tabular}\right) : a, b \in \Z\right\}$ is a
                           subring of $M_2(\Z)$ and is isomorphic to the 
                           quadratic integer ring $\mathcal{O}$.
                  \end{enumerate}

      \textbf{Solution.}

      \begin{enumerate}
         \item \textbf{Proof.} $S$ contains the zero matrix so it is nonempty;
               so let $A, B \in S$. Thus there exist integers
               $a_1, a_2, b_1$, and $b_2$ such that
               $$A = \left(\begin{tabular}{@{}cc@{}}
                  $a_1$ & $a_2$ \\
                  $Da_2$ & $a_1$
               \end{tabular}\right) \text{ and }
                 B = \left(\begin{tabular}{@{}cc@{}}
                  $b_1$ & $b_2$ \\
                  $Db_2$ & $b_1$
               \end{tabular}\right).$$

               \textbf{closure under subtraction:} We have that
               $$A - B = \left(\begin{tabular}{@{}cc@{}}
                  $a_1 - b_1$ & $a_2 - b_2$ \\
                  $D(a_2 - b_2)$ & $a_1 - b_1$
               \end{tabular}\right) \in S.$$
         
               Thus $(S, +)$ is an abelian subgroup by the Subgroup Criterion. 

               \textbf{closure under multiplication:} We have that
               $$AB = \left(\begin{tabular}{@{}cc@{}}
                  $a_1b_1 + Da_2b_2$ & $a_1b_2 + a_2b_1$ \\
                  $D(a_1b_2 + a_2b_1)$ & $a_1b_1 + Da_2b_2$
               \end{tabular}\right) \in S.$$
               So conclude that $S$ is a subring of $M_2(\Z)$. \qed
         \item \textbf{Proof.} Let $x, y \in \Z[\sqrt{D}]$. So
               $x = x_1 + x_2\sqrt{D}$ and $y = y_1 + y_2\sqrt{D}$ for some 
               integers $x_1, x_2, y_1$, and $y_2$. First we show that
               $\varphi$ is a ring homomorphism.

               \textbf{additivity of $\varphi$:} We have that
               \begin{align*}
                  \varphi(x + y)&=\varphi((x_1+x_2\sqrt{D})+(y_1+y_2\sqrt{D}))\\
                     &= \varphi((x_1 + y_1) +(x_2 + y_2)\sqrt{D}) \\
                     &= \left(\begin{tabular}{@{}cc@{}}
                           $x_1 + y_1$ & $x_2 + y_2$ \\
                           $D(x_2 + y_2)$ & $x_1 + y_1$
                     \end{tabular}\right) \\
                     &= \left(\begin{tabular}{@{}cc@{}}
                           $x_1$ & $x_2$ \\
                           $Dx_2$ & $x_1$
                     \end{tabular}\right) + \left(\begin{tabular}{@{}cc@{}}
                           $y_1$ & $y_2$ \\
                           $Dy_2$ & $y_1$
                     \end{tabular}\right) \\
                     &= \varphi(x_1 + x_2\sqrt{D})+\varphi(y_1 + y_2\sqrt{D}) \\
                     &= \varphi(x) + \varphi(y).
               \end{align*}

               \textbf{multiplicativity of $\varphi$:} We have that
               \begin{align*}
                  \varphi(xy) &= \varphi((x_1+x_2\sqrt{D})(y_1+y_2\sqrt{D})) \\
                     &= \varphi((x_1y_1 + Dx_2y_2)+(x_1y_2 + x_2y_1)\sqrt{D}) \\
                     &= \left(\begin{tabular}{@{}cc@{}}
                           $x_1y_1 + Dx_2y_2$ & $x_1y_2 + x_2y_1$ \\
                           $D(x_1y_2 + x_2y_1)$ & $x_1y_1 + Dx_2y_2$
                     \end{tabular}\right) \\
                     &= \left(\begin{tabular}{@{}cc@{}}
                           $x_1$ & $x_2$ \\
                           $Dx_2$ & $x_1$
                     \end{tabular}\right)\left(\begin{tabular}{@{}cc@{}}
                           $y_1$ & $y_2$ \\
                           $Dy_2$ & $y_1$
                     \end{tabular}\right) \\
                     &= \varphi(x_1 + x_2\sqrt{D})\varphi(y_1 + y_2\sqrt{D}) \\
                     &= \varphi(x)\varphi(y).
               \end{align*}

               Thus $\varphi$ is a ring homomorphism, so it remains to show that 
               $\varphi$ is bijective. \\

               \textbf{injectivity of $\varphi$:} Suppose that
               $\varphi(x) = \varphi(y)$. By equating the entries of the
               matrices $\varphi(x)$ and $\varphi(y)$, we conclude that
               $x_1 = y_1$ and $x_2 = y_2$, so that $x = y$. Thus $\varphi$ is
               injective. \\

               \textbf{surjectivity of $\varphi$:} Consider the matrix $A$ from
               (a). Since $A$ is an arbitary matrix in $S$ and since
               $\varphi(a_1 + a_2\sqrt{D}) = A$, it follows that $\varphi$ is
               onto. So conclude that $\varphi$ is an isomorphism. \qed
         \item Let $D$ be a squarefree integer such that $D \equiv 1$ mod 4 and
               let
               $$T = \left\{\left(\begin{tabular}{@{}cc@{}}
                  $a$ & $b$ \\
                  $(D-1)b/4$  & $a+b$
               \end{tabular}\right) : a, b \in \Z\right\}.$$
               We want to show that $\mathcal{O}$ is isomorphic to $T$, where
               $\mathcal{O} = \Z\left[\frac{1 + \sqrt{D}}{2}\right]$. Consider
               the map $\beta : \mathcal{O} \rightarrow T$, defined by
               $a + b \frac{1 + \sqrt{D}}{2} \mapsto
               \left(\begin{tabular}{@{}cc@{}}
                  $a$ & $b$ \\
                  $(D-1)b/4$  & $a+b$
               \end{tabular}\right)$. First we will show that $\beta$ is a ring
               homomorphism. To that end, we let $x, y \in \mathcal{O}$, so that
               $$x = a + b\frac{1 + \sqrt{D}}{2} \text{ and }
                 y = c + d \frac{1 + \sqrt{D}}{2}$$
               for some integers $a$, $b$, $c$, and $d$. \\

               \textbf{additivity of $\varphi$:} It follows that
               \begin{align*}
                  \beta(x + y) &= \beta\left(\left(a + b
                     \frac{1 + \sqrt{D}}{2}\right) +
                     \left(c + d\frac{1 + \sqrt{D}}{2}\right)\right) \\
                     &= \beta\left((a + c) + (b + d)
                     \frac{1 + \sqrt{D}}{2}\right) \\
                     &= \left(\begin{tabular}{@{}cc@{}}
                        $a + c$ & $b + d$ \\
                        $(D-1)(b + d)/4$  & $(a + c)+(b + d)$
                     \end{tabular}\right) \\
                     &= \left(\begin{tabular}{@{}cc@{}}
                        $a$ & $b$ \\
                        $(D-1)b/4$  & $a + b$
                     \end{tabular}\right) + \left(\begin{tabular}{@{}cc@{}}
                        $c$ & $d$ \\
                        $(D-1)d/4$  & $c + d$
                     \end{tabular}\right) \\
                     &= \beta\left(a + b\frac{1 + \sqrt{D}}{2}\right) +
                        \beta\left(c + d\frac{1 + \sqrt{D}}{2}\right) \\
                     &= \beta(x) + \beta(y).
               \end{align*}

               \textbf{multiplicativity of $\varphi$:} It follows that
               \begin{align*}
                  \beta(xy) &= \beta\left(\left(a + b
                     \frac{1 + \sqrt{D}}{2}\right)
                     \left(c + d \frac{1 + \sqrt{D}}{2}\right)\right) \\
                     &= \beta\left((ac + (D-1)\frac{bd}{4}) + (ad + bc + bd)
                     \frac{1 + \sqrt{D}}{2}\right) \\
                     &= \left(\begin{tabular}{@{}cc@{}}
                        $ac + (D-1)bd/4$ & $ad + bc + bd$ \\
                        $(D-1)(ad + bc + bd)/4$  & $(ac + (D-1)bd/4)+
                         (ad + bc + bd)$
                     \end{tabular}\right) \\
                     &= \left(\begin{tabular}{@{}cc@{}}
                        $a$ & $b$ \\
                        $(D-1)b/4$  & $a + b$
                     \end{tabular}\right)\left(\begin{tabular}{@{}cc@{}}
                        $c$ & $d$ \\
                        $(D-1)d/4$  & $c+d$
                     \end{tabular}\right) \\
                     &= \beta\left(x_1 + x_2\frac{1 + \sqrt{D}}{2}\right)
                        \beta\left(y_1 + y_2\frac{1 + \sqrt{D}}{2}\right) \\
                     &= \beta(x)\beta(y).
               \end{align*}

               It remains to show that $\beta$ is one-to-one and onto. So \\

               \textbf{injectivity of $\beta$:} Suppose that
               $\beta(x) = \beta(y)$. By equating corresponding entries in the
               matrices $\beta(x)$ and $\beta(y)$, we shall get that $a = c$ and
               $b = d$, so that $x = y$, and thus, $\beta$ is one-to-one. \\

               \textbf{surjectivity of $\beta$:} Let $C \in T$. Then
               $$C =  \left(\begin{tabular}{@{}cc@{}}
                  $c_1$ & $c_2$ \\
                  $(D-1)c_2/4$  & $c_1+c_2$
               \end{tabular}\right)$$
               for some $c_1$ and $c_2$ in $\Z$. It follows immediately that
               $\beta$ is onto because
               $$\beta(c_1 + c_2\sqrt{D}) = C.$$
               Thus $\mathcal{O} \cong T$.
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.13%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.13]  Prove that the ring $M_2(\R)$ contains a subring that is
                  isomorphic to $\C$.

      \textbf{Proof.} The map
      $$\alpha : \C \rightarrow M_2(\R) \text{ defined by } a + bi \mapsto
      \left(\begin{tabular}{@{}rc@{}}
         $a$ & $b$ \\
         $-b$  & $a$
      \end{tabular}\right)$$
      is an injective homomorphism of rings (use procedure in Exercise
      7.3.12(b) by setting $D = -1$), so by Corollary 3.17, we have that the
      kernel of $\alpha$ is $\{0\}$, and, by the First Isomorphism
      Theorem, that $\C \cong \C/\{0\} \cong \alpha(\C)$; thus $\C$ is 
      isomorphic to a subring of $M_2(\R)$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.14%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.14]  Prove that the ring $M_4(\R)$ contains a subring that is
                  isomorphic to the real Hamilton Quaternions, $\mathbb{H}$.

      \textbf{Proof.} We will proceed as in Exercise 7.3.13; so it suffices to
      find an injective ring homomorphism from $\mathbb{H}$ into $M_4(\R)$.
      Consider the map:
      $$\varphi : \mathbb{H} \rightarrow M_4(\R) \text{ defined by }
         a + bi + cj + dk \mapsto \left(\begin{tabular}{@{}rrrr@{}}
         $a$  & $b$  & $c$  & $d$ \\
         $-b$ & $a$  & $-d$ & $c$ \\
         $-c$ & $d$  & $a$  & $-b$ \\
         $-d$ & $-c$ & $b$  & $a$
      \end{tabular}\right).$$

      Let $x, y \in \mathbb{H}$. Then
      $$x = a + bi + cj + dk \text{ and } y = e + fi + gj + hk,$$
      for some real numbers $a, b, c, d, e, f, g$, and $h$. Now we will show
      that $\varphi$ is a ring homomorphism. \\

      \textbf{additivity of $\varphi$:} It follows that
      \begin{align*}
         \varphi(x + y) &= \varphi((a + bi + cj + dk) + (e + fi + gj + hk)) \\
            &= \varphi((a + e) + (b + f)i + (c + g)j + (d + h)k) \\
            &= \left(\begin{tabular}{@{}rrrr@{}}
               $a + e$  & $b + f$  & $c + g$  & $d + h$ \\
               $-b - f$ & $a + e$  & $-d - h$ & $c + g$ \\
               $-c - g$ & $d + h$  & $a + e$  & $-b - f$ \\
               $-d - h$ & $-c - g$ & $b + f$  & $a + e$
            \end{tabular}\right) \\
            &= \left(\begin{tabular}{@{}rrrr@{}}
               $a$  & $b$  & $c$  & $d$ \\
               $-b$ & $a$  & $-d$ & $c$ \\
               $-c$ & $d$  & $a$  & $-b$ \\
               $-d$ & $-c$ & $b$  & $a$
            \end{tabular}\right) + \left(\begin{tabular}{@{}rrrr@{}}
               $e$  & $f$  & $g$  & $h$ \\
               $-f$ & $e$  & $-h$ & $g$ \\
               $-g$ & $h$  & $e$  & $-f$ \\
               $-h$ & $-g$ & $f$  & $e$
            \end{tabular}\right) \\
            &= \varphi(a + bi + cj + dk) + \varphi(e + fi + gj + hk) \\
            &= \varphi(x) + \varphi(y).
      \end{align*}

      Let $p = ae - bf - cg - dh$, $q = af + be + ch - dg$,
      $r = ag - bh + ce + df$, and $s = ah + bg - cf + de$.

      \textbf{multiplicativity of $\varphi$:} It follows that
      \begin{align*}
         \varphi(xy) &= \varphi((a + bi + cj + dk)(e + fi + gj + hk)) \\
            &= \varphi(p + qi + rj + sk) \\
            &= \left(\begin{tabular}{@{}rrrr@{}}
               $p$  & $q$  & $r$  & $s$ \\
               $-q$ & $p$  & $-s$ & $r$ \\
               $-r$ & $s$  & $p$  & $-q$ \\
               $-s$ & $-r$ & $q$  & $p$
            \end{tabular}\right) \\
            &= \left(\begin{tabular}{@{}rrrr@{}}
               $a$  & $b$  & $c$  & $d$ \\
               $-b$ & $a$  & $-d$ & $c$ \\
               $-c$ & $d$  & $a$  & $-b$ \\
               $-d$ & $-c$ & $b$  & $a$
            \end{tabular}\right)\left(\begin{tabular}{@{}rrrr@{}}
               $e$  & $f$  & $g$  & $h$ \\
               $-f$ & $e$  & $-h$ & $g$ \\
               $-g$ & $h$  & $e$  & $-f$ \\
               $-h$ & $-g$ & $f$  & $e$
            \end{tabular}\right) \\
            &= \varphi(a + bi + cj + dk)\varphi(e + fi + gj + hk) \\
            &= \varphi(x)\varphi(y).
      \end{align*}

      \textbf{injectivity of $\varphi$:} Suppose $\varphi(x) = \varphi(y)$. By 
      equating corresponding entries in the matrices $\varphi(x)$ and
      $\varphi(y)$, we shall get that $a = e$, $b = f$, $c = g$, and $d = f$, so 
      that $x = y$, and thus, $\varphi$ is one-to-one. Conclude that $M_4(\R)$
      has a subring that is isomorphic to $\mathbb{H}$.

      \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.15%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.15]  Let $X$ be a nonempty set and let $\mathcal{P}(X)$ be the
                  Boolean ring of all subsets of $X$ defined in Exercise 7.1.21.
                  Let $R$ be the ring of all functions from $X$ into $\Z/2\Z$.
                  For each $A \in \mathcal{P}(X)$ define the function
                  $$\chi_A : X \rightarrow \Z/2\Z \quad \text{by} \quad
                    \chi_A(x) = \left\{
                       \begin{array}{ll}
                          1 & \text{if } x \in A \\
                          0 & \text{if } x \notin A
                       \end{array} \right.
                  $$
                  ($\chi_A$ is called the \textit{characteristic function of }
                  $A$ with values in $\Z/2\Z$). Prove that the map
                  $\mathcal{P}(X) \rightarrow R$ defined by $A \mapsto \chi_A$
                  is a ring isomorphism.

      \textbf{Proof.} Consider $\varphi : \mathcal{P}(X) \rightarrow R$, defined 
      by $A \mapsto \chi_A$. First we will show that $\varphi$ is a ring
      homomorphism. So let $A$ and $B$ be subsets of $X$.

      \textbf{additivity of $\varphi$:} Observe that
      $\varphi(A + B) = \varphi(A) + \varphi(B)$ if and only if
      $\chi_{A+B} = \chi_A + \chi_B$ if and only if
      $\chi_{A+B}(x) = \chi_A(x) + \chi_B(x)$ for every $x \in X$. So let
      $x \in X$.

      \textbf{Case 1.} $x \in A$ and $x \in B$. Thus $x \notin A + B$, and we
      have that
      $$\chi_{A+B}(x) = 0 = 1 + 1 = \chi_A(x) + \chi_B(x).$$

      \textbf{Case 2.} $x \in A$ and $x \notin B$. Thus $x \in A + B$, and we
      have that
      $$\chi_{A+B}(x) = 1 = 1 + 0 = \chi_A(x) + \chi_B(x).$$

      \textbf{Case 3.} $x \notin A$ and $x \in B$. Thus $x \in A + B$, and we
      have that
      $$\chi_{A+B}(x) = 1 = 0 + 1 = \chi_A(x) + \chi_B(x).$$

      \textbf{Case 4.} $x \notin A$ and $x \notin B$. Thus $x \notin A + B$, and 
      we have that
      $$\chi_{A+B}(x) = 0 = 0 + 0 = \chi_A(x) + \chi_B(x).$$

      Thus $\chi_{A+B}(x) = \chi_A(x) + \chi_B(x)$ for every $x \in X$ so that
      $\varphi(A + B) = \varphi(A) + \varphi(B)$. \\

      \textbf{multiplicativity of $\varphi$:} Observe that
      $\varphi(AB) = \varphi(A)\varphi(B)$ if and only if
      $\chi_{AB} = \chi_A\chi_B$ if and only if
      $\chi_{AB}(x) = \chi_A(x)\chi_B(x)$ for every $x \in X$. So let
      $x \in X$.

      \textbf{Case 1.} $x \in A$ and $x \in B$. Thus $x \in AB$, and we
      have that
      $$\chi_{AB}(x) = 1 = 1 \cdot 1 = \chi_A(x)\chi_B(x).$$

      \textbf{Case 2.} $x \in A$ and $x \notin B$. Thus $x \notin AB$, and we
      have that
      $$\chi_{AB}(x) = 0 = 1 \cdot 0 = \chi_A(x)\chi_B(x).$$

      \textbf{Case 3.} $x \notin A$ and $x \in B$. Thus $x \notin AB$, and we
      have that
      $$\chi_{AB}(x) = 0 = 0 \cdot 1 = \chi_A(x)\chi_B(x).$$

      \textbf{Case 4.} $x \notin A$ and $x \notin B$. Thus $x \notin AB$, and 
      we have that
      $$\chi_{AB}(x) = 0 = 0 \cdot 0 = \chi_A(x)\chi_B(x).$$

      Thus $\chi_{AB}(x) = \chi_A(x)\chi_B(x)$ for every $x \in X$ so that
      $\varphi(AB) = \varphi(A)\varphi(B)$. We conclude that $\varphi$ is a ring
      homomorphism. Now we must show that $\varphi$ is a bijection.

      \textbf{injectivity of $\varphi$:} Suppose that $\varphi(A) = \varphi(B)$.
      That is $\chi_A(x) = \chi_B(x)$ for every $x \in X$. Now if $y \in A$ we
      have that $\chi_A(y) = 1$; since $\chi_A = \chi_B$, it follows that
      $\chi_B(y) = 1$, so that $y \in B$, and we conclude that $A \subseteq B$.
      Similarly, by symmetry, we have that $B \subseteq A$, so that $A = B$, and
      hence $\varphi$ is injective. 

      \textbf{surjectivity of $\varphi$:} Let $f \in R$. Let
      $C = \{w \in X : f(w) = 1\}$. It follows that $\varphi$ is onto because
      $\varphi(C) = f$.
   
      Conclude that $\mathcal{P}(X) \cong R$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.16%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.16]  Let $\varphi : R \rightarrow S$ be a surjective homomorphism
                  of rings. Prove that the image of the center of $R$ is
                  contained in the center of $S$ (cf. Exercise 7.1.7).

      \textbf{Proof.} Let $Z_R$ be the center of $R$. We want to show that
      $\varphi(Z_R)$ is in the center of $S$; i.e., every element in the image 
      of $\varphi$ commutes with every element of $S$. So let $s \in S$ and
      $y \in \varphi(Z_R)$; thus $y = \varphi(r)$ for some $r \in Z_R$ and since
      $\varphi$ is onto, there exists $x \in R$ such that $s = \varphi(x)$. So
      \begin{align*}
         ys &= \varphi(r)\varphi(x) \\
            &= \varphi(rx) &[\varphi \text{ is a ring homomorphism}] \\
            &= \varphi(xr) &[r \in Z_R] \\
            &= \varphi(x)\varphi(r) &[\varphi \text{ is a ring homomorphism}] \\
            &= sy,
      \end{align*}
      so that every element in the image of $\varphi$ commutes with every
      element of $S$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.17%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.17]  Let $R$ and $S$ be nonzero rings with identity and denote
                  their respective identities by $1_R$ and $1_S$. Let
                  $\varphi : R \rightarrow S$ be a nonzero homomorphism of
                  rings.
                  \begin{enumerate}
                     \item Prove that if $\varphi(1_R) \neq 1_S$ then
                           $\varphi(1_R)$ is a zero divisor in $S$. Deduce that
                           if $S$ is an integral domain then every nonzero ring
                           homomorphism from $R$ to $S$ sends the identity of
                           $R$ to the identity of $S$.
                     \item Prove that if $\varphi(1_R) = 1_S$ then $\varphi(u)$
                           is a unit in $S$ and that
                           $\varphi(u^{-1}) = \varphi(u)^{-1}$ for each unit $u$ 
                           of $R$.
                  \end{enumerate}

      \textbf{Solution.}

      \begin{enumerate}
         \item \textbf{Proof.} Suppose that $\varphi(1_R) \neq 1_S$. Now we have
               that $$\varphi(1_R) = \varphi(1_R \cdot 1_R) =
                     \varphi(1_R)\varphi(1_R),$$
               so that $\varphi(1_R)(\varphi(1_R) - 1_S) = 0$. If
               $\varphi(1_R) = 0$, then since
               $$\varphi(r) = \varphi(r \cdot 1_R) = \varphi(x)\varphi(1_R) =0$$ 
               for every $r \in R$, it follows that $\varphi$ is the zero 
               homomorphism, a contradiction. Thus $\varphi(1_R) \neq 0$. We
               thus conclude from the equality
               $\varphi(1_R)(\varphi(1_R) - 1_S) = 0$ that $\varphi(1_R)$ is a
               zero divisor. Now suppose $S$ is an integral domain; in this
               case, it follows that $\varphi(1_R) = 0$ or
               $\varphi(1_R) - 1_S = 0$. That is, either $\varphi$ is the zero
               homomorphism or $\varphi$ maps $1_R$ to $1_S$. Since $\varphi$ is
               nonzero, we are forced to conclude that $\varphi(1_R) = 1_S$.
               \qed
         \item \textbf{Proof.} Suppose $\varphi(1_R) = 1_S$ and let $u$ be a
               unit in $R$. It follows that
               \begin{align*}
                  \varphi(u)\varphi(u^{-1}) &= \varphi(uu^{-1}) \\
                     &= \varphi(1_R) \\
                     &= 1_S \\
                     &= \varphi(1_R) \\
                     &= \varphi(u^{-1}u) \\
                     &= \varphi(u^{-1})\varphi(u),
               \end{align*}
               so that $\varphi(u^{-1}) = \varphi(u)^{-1}$. \qed
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.18%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.18]  \begin{enumerate}
                     \item If $I$ and $J$ are ideals of $R$ prove that their
                           intersection $I \cap J$ is also an ideal of $R$.
                     \item Prove that the intersection of an arbitrary nonempty
                           collection of ideals is again an ideal (do not assume
                           that the collection is countable).
                  \end{enumerate}

      \textbf{Solution.}

      \begin{enumerate}
         \item \textbf{Proof.} Let $M = \{1, 2\}$, $R_1 = I$, $R_2 = J$. It
               follows by (b) that $I \cap J = R_1 \cap R_2$ is an ideal of $R$. 
               \qed
         \item \textbf{Proof.} Let $M$ be a nonempty indexing set such that
               $R_m$ is an ideal of $R$ for every $m \in M$. Let
               $X = \bigcap_{m\in M}R_m$. We claim that $M$ is an ideal of $R$.

               \textbf{nonempty and closure under addition:} This follows from
               Exercise 2.1.10(b) \\

               \textbf{closure under multiplication by elements of $R$:} Let
               $r \in R$ and $n \in M$, so that $n \in R_m$ for every $m \in M$.
               Since each $R_m$ is an ideal of $R$, it follows that
               $rn, nr \in R_m$ for each $m \in M$, so that $rn, rn \in M$, and
               thus, $M$ is closed under multiplication by elements of $R$. \\

               Conclude that $M$ is an ideal of $R$. \qed
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.19%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.19]  Prove that if $I_1 \subseteq I_2 \subseteq \cdots$ are ideals
                  of $R$ then $\cup_{n=1}^\infty I_n$ is an ideal of $R$.

      \textbf{Proof.} Suppose that $I_1 \subseteq I_2 \subseteq \cdots$ are 
      ideals of $R$. Let $I = \cup_{n=1}^\infty I_n$. We want to show that $I$
      is an ideal of $R$. The set $I$ is nonempty because $I_1$ is nonempty and
      is a subset of $I$. So let $x, y \in I$. It follows that $x = I_i$ and
      $y = I_j$ for some positive integers $i$ and $j$. Assume without loss of 
      generality that $i \le j$.

      \textbf{closure under addition:} Since $i \le j$, we have that
      $I_i \subseteq I_j$, so that $x \in I_j$. Since $I_j$ is an ideal, it 
      follows that $x + y \in I_j$; thus $x+y \in I$ because $I_j \subseteq I$.

      \textbf{closure under multiplication by elements of $R$:} Let $r \in R$.
      Since $I_i$ is an ideal, it follows that $rx, xr \in I_i$, so that
      $rx, xr \in I$. \\

      It follows that $I$ is an ideal of $R$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.20%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.20]  Let $I$ be an ideal of $R$ and let $S$ be a subring of $R$.
                  Prove that $I \cap S$ is an ideal of $S$. Show by example that
                  not every ideal of a subring $S$ of a ring $R$ need be of the
                  form $I \cap S$ for some ideal $I$ of $R$.

      \textbf{Proof.} By Exercise 2.1.10(a), it follows that $I \cap S$ is
      nonempty and closed under addition. So it remains to show that $I \cap S$
      is closed under multiplication by elements of $S$. Let $s \in S$ and
      $x \in I \cap S$. Now $x \in S$, so $xs, sx \in S$ by closure of $S$ under
      multiplication. Since $I$ is an ideal of $R$, $x \in I$ and $s \in S$ 
      imply that $sx, xs \in I$; thus $xs, sx \in I \cap S$, so that $I \cap S$ 
      is an ideal of $S$. \qed

      \textbf{Counterexample.} Let $R = \Q$ and $S = \Z$. By Proposition 7.9(2),
      the ideals of $R$ are $\{0\}$ and $R$. Thus, for every ideal $I$ of $R$,
      $I \cap S \in \{\{0\}, S\}$; observe that $3S$ is an ideal in $S$ and
      $3S$ is equal to neither $\{0\}$ nor $S$.
      
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.21%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.21]  Prove that every (two-sided) ideal of $M_n(R)$ is equal to
                  $M_n(J)$ for some (two-sided) ideal $J$ of $R$. [Use Exercise
                  6(c) of Section 2 to show first that the set of entries of
                  matrices in an ideal of $M_n(R)$ form an ideal in $R$.]

      \textbf{Proof.} Let $I$ be an ideal of $M_n(R)$ and let
      $$J = \{a \in R : a \text{ is an entry in }A, \text{ where }A \in I\}.$$
      We want to show that $J$ is an ideal of $R$. The set $J$ is nonempty
      because $I$ is nonempty, so let $b, c \in J$.

      \textbf{Closure under subtraction.} By definition of $J$, there exist
      indices $i, j, k, l$, and matrices $B, C \in I$ such that the $i, j$
      entry of $B$ is $b$ and the $k, l$ entry of $C$ is c. Let $E_{ps}$ be the
      matrix in $M_n(R)$ such that its $p, s$ entry is 1 while every other entry 
      is 0. Since $I$ is an ideal of $M_n(R)$, it follows that
      $B' = E_{1i}\cdot B\cdot E_{j1}$ and $C' = E_{1k}\cdot C \cdot E_{l1}$
      are matrices in $I$, so that $B'-C' \in I$. Now conclude that $b-c \in J$
      because $b-c$ is the 1, 1 entry of $B' - C'$. Thus $J$ is closed under
      subtraction.

      \textbf{Closure under multiplication by elements of $R$.} Let $r \in R$
      and let $D$ be the matrix in $M_n(R)$ such that its 1, 1 entry is $r$ and
      every other entry is 0. Since $I$ is an ideal and $B' \in I$, it follows
      that $D \cdot B'$ and $B' \cdot D$ are both matrices in $I$. But since the
      1, 1 entry of the former is $rb$ and that of the latter is $br$, it
      follows that $rb, br \in J$, so that $J$ is closed by multiplication by
      elements of $R$.

      Conclude that $J$ is an ideal of $R$. Indeed, $I = M_n(J)$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.22%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.22]  Let $a$ be an element of the ring $R$.
                  \begin{enumerate}
                     \item Prove that $\{x \in R : ax = 0\}$ is right ideal and
                           $\{y \in R : ya = 0\}$ is a left ideal (called
                           respectively the right and left \textit{annihilators}
                           of $a$ in $R$).
                     \item Prove that if $L$ is a left ideal of $R$ then
                           $\{x \in R : xa = 0 \text{ for all } a \in L\}$ is a
                           two-sided ideal (called the left \textit{annihilator}
                           of $L$ in $R$).
                  \end{enumerate}

      \textbf{Solution.}

      \begin{enumerate}
         \item Let $R' = \{x \in R : ax = 0\}$ and $L' = \{y \in R : ya = 0\}$.
               We claim that $R'$ is a right ideal of $R$. \\

               \textbf{Proof.} We have $a \cdot 0 = 0$, so that $0 \in R'$; that 
               is, $R'$ is nonempty, so let $x, y \in R'$(i.e., $ax = ay = 0$), 
               and let $r \in R$.

               \begin{itemize}
                  \item \textbf{Closure under subtraction.} Since
                        $$0 = 0 - 0 = ax - ay = a(x - y),$$
                        it follows that $x - y \in R'$, so that $R'$ is closed 
                        under subtraction.

                  \item \textbf{Closure under right multiplication by $R$.} 
                        Because
                        $$a(xr) = (ax)r = 0 \cdot r = 0,$$
                        it follows that $xr \in R$, so that $R'$ is closed under 
                        right multiplication by $R$.
               \end{itemize}

               We then conclude that $R'$ is a right ideal of $R$, and, by
               symmetry of arguments, that $L'$ is a left ideal of $R$. \qed
         \item Let $L$ be a left ideal of $R$ and claim that
               $I = \{x \in R : xa = 0 \text{ for all } a \in L\}$ is an ideal
               of $R$. \\

               \textbf{Proof.} We have $0 \cdot a = 0$ for all $a \in L$, so
               that $0 \in I$; that is, $I$ is nonempty, so let
               $x, y \in I$(i.e., $xa = ya = 0$ for all $a \in L$), and let
               $r \in R$.

               \begin{itemize}
                  \item \textbf{Closure under subtraction.} Since
                        $$0 = 0 - 0 = xa - ya = (x - y)a,$$
                        for all $a \in L$, it follows that $x - y \in R'$, so 
                        that $I$ is closed under subtraction.
                  \item \textbf{Closure under multiplication by $R$.} Let
                        $l \in L$, so that $xl = 0$. It follows that
                        $rx \in I$ because $(rx)l = r(xl) = r \cdot 0 = 0$. Now
                        $rl \in L$ because $L$ is an ideal of $R$; thus
                        $0 = x(rl) = (xr)l$, so that $xr \in I$. Thus $I$ is 
                        closed under multiplication by $R$.
               \end{itemize}

               We then conclude that $I$ is an ideal of $R$. \qed
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.23%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.23]  Let $S$ be a subring of $R$ and let $I$ be an ideal of $R$.
                  Prove that if $S \cap I = 0$ then $\overline{S} \cong S$,
                  where the bar denotes passage to $R/I$.

      \textbf{Proof.} Suppose that $S \cap I = 0$ and consider the surjective 
      homomorphism
      $\pi : S \rightarrow \overline{S}$, defined by $s \mapsto s + I$. It
      suffices to show that $\pi$ is injective. So suppose that
      $\pi(x) = \pi(y)$ for some $x, y \in S$. That is, $x + I = y + I$, so that
      $x - y \in I$. Since $S$ is a ring, it closed under subtraction, so that
      $x - y \in S$. But the intersection of $I$ and $S$ is trivial; thus,
      $x - y = 0$, so that $x = y$; that is, $\pi$ is injective. So conclude
      that $\pi$ is an isomorphism and thus $S \cong \overline{S}$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.24%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.24]  Let $\varphi : R \rightarrow S$ be a ring homomorphism.
                  \begin{enumerate}
                     \item Prove that if $J$ is an ideal of $S$ then
                           $\varphi^{-1}(J)$ is an ideal of $R$. Apply this to
                           the special case when $R$ is a subring of $S$ and
                           $\varphi$ is the inclusion homomorphism to deduce
                           that if $J$ is an ideal of $S$ then $J \cap R$ is an
                           ideal of $R$.
                     \item Prove that if $\varphi$ is surjective and $I$ is an
                           ideal of $R$ then $\varphi(I)$ is an ideal of $S$.
                           Give an example where this fails if $\varphi$ is not
                           surjective.
                  \end{enumerate}

      \textbf{Solution.}

      \begin{enumerate}
         \item Let $J$ be an ideal of $S$. We want to show that
               $\varphi^{-1}(J)$ is an ideal of $R$.

               \textbf{Proof.} Since $\varphi(0) = 0 \in J$, it follows that
               $0 \in \varphi^{-1}(J)$, so that $\varphi^{-1}(J)$ is nonempty. 
               Let $x, y \in \varphi^{-1}(J)$. That is,
               $\varphi(x), \varphi(y) \in J$.
               \begin{itemize}
                  \item \textbf{Closure under subtraction.} Since $J$ is an
                        ideal, it is closed under subtraction so that 
                        $\varphi(x - y) = \varphi(x) - \varphi(y) \in J$, and
                        thus, $x - y \in \varphi^{-1}(J)$. This says that
                        $\varphi^{-1}(J)$ is closed under subtraction.
                  \item \textbf{Closure under multiplication by $R$.} Let
                        $r \in R$. Since $J$ is an ideal of $S$, it follows that
                        $\varphi(rx) = \varphi(r)\varphi(x) \in J$ and
                        $\varphi(xr) = \varphi(x)\varphi(r) \in J$, so that
                        $rx, xr \in \varphi^{-1}(J)$. Thus $\varphi^{-1}(J)$ is
                        closed under multiplication by $R$.
               \end{itemize}
               Conclude that $\varphi^{-1}(J)$ is an ideal of $R$.

               \textbf{Special Case.} Now suppose that $R \subseteq S$ and
               $\varphi$ is the inclusion homomorphism; that is,
               $\varphi(t) = t$ for every $t \in R$. In this case, if
               $x \in \varphi^{-1}(J)$, then $x = \varphi(x) \in J$; since $x$
               is also in $R$, it follows that $x \in J \cap R$, so that
               $\varphi^{-1}(J) \subseteq J \cap R$. Now if $j \in J \cap R$,
               then we particularly have that $j \in R$, so that
               $\varphi(j) = j$. But $j \in J$; thus $\varphi(j) \in J$, so that
               $j \in \varphi^{-1}(J)$. Thus
               $\varphi^{-1}(J) \supseteq J \cap R$. Conclude by main proof that
               $\varphi^{-1}(J) = J \cap R$ is an ideal of $R$. \qed
         \item Suppose that $\varphi$ is surjective and let $I$ be an ideal of
               $R$. We claim that $\varphi(I)$ is an ideal of $S$.

               \textbf{Proof.} Let $x, y \in \varphi(I)$. So $x = \varphi(i_1)$
               and $y = \varphi(i_2)$ for some $i_1, i_2 \in I$.
               \begin{itemize}
                  \item \textbf{Closure under subtraction.} By closure, we have
                        $i_1 - i_2 \in I$, so that
                        $$x - y = \varphi(i_1)-\varphi(i_2) =
                          \varphi(i_1 - i_2)\in \varphi(I).$$
                        That is, $\varphi(I)$ is closed under subtraction.
                  \item \textbf{Closure under multiplication by $S$.} Let
                        $s \in S$. Since $\varphi$ is onto, there exists $r$ in
                        $R$ such that $\varphi(r) = s$. Now $ri_1 \in I$
                        because $I$ is an ideal of $R$. Thus
                        $$sx = \varphi(r)\varphi(i_1) =
                          \varphi(ri_1) \in \varphi(I).$$
                        Thus $\varphi(I)$ is closed under multiplication by $S$.
               \end{itemize}

               Conclude that $\varphi(I)$ is an ideal of $S$.

               \textbf{Example.} Let $R = \Z$, $S = \Q$, and let $\varphi$ be
               the inclusion homomorphism. Although $2\Z$ is an ideal of $\Z$,
               $\varphi(2\Z) = 2\Z$ is not an ideal of $\Q$. \qed
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.25%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.25]  Assume $R$ is a commutative ring with 1. Prove that the
                  Binomial Theorem
                  $$(a + b)^n = \sum_{k=0}^n\binom{n}{k}a^kb^{n-k}$$
                  holds in $R$, where the binomial coefficient $\binom{n}{k}$ is
                  interpreted in $R$ as the sum $1 + 1 + \cdots + 1$ of the
                  identity 1 in $R$ taken $\binom{n}{k}$ times.

      \textbf{Proof.} Let $a, b \in R$. We shall proceed by induction on $n$.

      \textbf{Base Case.} $n = 1$.  We have that
      $$
         \sum_{k=0}^1\binom{1}{k}a^kb^{1-k} = \binom{1}{0}a^0b^1 +
            \binom{1}{1}a^1b^0 = b + a = a + b,
      $$
      where the last equality follows from the commutativity of $R$. So the
      Binomial Theorem holds whenever $n = 1$.

      \textbf{Inductive Hypothesis.} Suppose that the Binomial Theorem holds for
      some positive integer $m$. We must now show that it also holds for $m+1$.
      Recall this identity from probability:
      $$\binom{a + 1}{b} = \binom{a}{b} + \binom{a}{b - 1},$$
      for integers $a$ and $b$; let $\binom{a}{b} = 0$ if $b < 0$ or $b > a$.
      It follows that
      \begin{align*}
         \sum_{k=0}^{m+1}\binom{m+1}{k}a^kb^{m+1-k} &=
            \sum_{k=0}^{m+1}\left[\binom{m}{k} +
            \binom{n}{k - 1}\right]a^kb^{m+1-k} \\
            &= \sum_{k=0}^{m+1}\binom{m}{k}a^kb^{m+1-k} +
               \sum_{k=0}^{m+1}\binom{m}{k-1}a^kb^{m+1-k} \\
            &= \binom{m}{m+1}a^{m+1} + \sum_{k=0}^{m}\binom{m}{k}a^kb^{m+1-k} +
               \sum_{k=0}^{m+1}\binom{m}{k-1}a^kb^{m+1-k} \\
            &= \sum_{k=0}^{m}\binom{m}{k}a^kb^{m+1-k} + \binom{m}{-1}b^{m+1} + 
               \sum_{k=1}^{m+1}\binom{m}{k-1}a^kb^{m+1-k} \\
            &= b\sum_{k=0}^{m}\binom{m}{k}a^kb^{m-k} + 
               a\sum_{k=1}^{m+1}\binom{m}{k-1}a^{k-1}b^{m+1-k} \\
            &= b\sum_{k=0}^{m}\binom{m}{k}a^kb^{m-k} + 
               a\sum_{k=0}^{m}\binom{m}{k}a^{k}b^{m-k} \\
            &= b(a + b)^m + a(a + b)^m \qquad\qquad
                  \text[\text{Inductive Hypothesis}] \\
            &= (a + b)^m(b + a) = (a + b)^{m+1},
      \end{align*}
      where the last equality follows from the commutativity of $R$. Thus the
      Binomial Theorem holds for $m + 1$. We conclude by Induction that it holds
      for every postive integer $n$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.26%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.26]  The \textit{characteristic} of a ring $R$ is the smallest
                  positive integer $n$ such that $1 + 1 + \cdots + 1 = 0$
                  ($n$ times) in $R$; if no such integer exists the 
                  characteristic of $R$ is said to be 0. For example,
                  $\Z/n\Z$ is a ring of characteristic $n$ for each positive 
                  integer $n$ and $\Z$ is a ring of characteristic 0.
                  \begin{enumerate}
                     \item Prove that the map $\Z \rightarrow R$ defined by
                           \begin{equation*}
                              k \mapsto \left\{
                                 \begin{array}{ll}
                                    1 + 1 + \cdots + 1 (k \text{ times}) &
                                       \text{if } k > 0 \\
                                    0 & \text{if } k = 0 \\
                                    -1 - 1 - \cdots - 1 (-k \text{ times}) &
                                       \text{if } k < 0
                                 \end{array} \right.
                           \end{equation*}
                           is a ring homomorphism whose kernel is $n\Z$, where
                           $n$ is the characteristic of $R$ (this explains the
                           use of the terminology ``characteristic 0" instead of
                           the archaic phrase ``characteristic $\infty$" for
                           rings in which no sum of 1's is zero).
                     \item Determine the characteristics of the rings $\Q$,
                           $\Z[x]$, $\Z/n\Z[x]$.
                     \item Prove that if $p$ is a prime and if $R$ is a
                           commutative ring of characteristic $p$, then
                           $(a + b)^p = a^p + b^p$ for all $a, b \in R$.
                  \end{enumerate}

      \textbf{Solution.}

      \begin{enumerate}
         \item \textbf{Proof.} Let $\varphi$ be the map and $1_R$ the identity
               of $R$. Recall that if $G$ is an additive group, then, according 
               to Exercise 1.1.19(c)
               $$(a + b)g = ag + bg$$
               for every $g \in G$ and integers $a$ and $b$ (see first paragraph
               on Page 20 for definition of $ag$, where $a \in \Z$ and
               $g \in G$). Thus it follows that $\varphi(k) = k1_R$ for each 
               integer $k$. To avoid confusion, we will write $k \cdot r$, 
               instead of $kr$, where $k \in \Z$ and $r \in R$, and we will use
               $\times$ to denote the multiplication in $R$ and $S$. We will now
               show that $\varphi$ is a ring homomorphism.
               \begin{itemize}
                  \item \textbf{Additivity of $\varphi$.} For integers $x$ and
                        $y$, it follows by the definition of $\varphi$ and 
                        Exercise 1.1.19(c) that
                        $$\varphi(x + y) = (x + y)\cdot1_R = (x\cdot1_R) +
                           (y\cdot1_R) = \varphi(x) + \varphi(y);$$
                        thus $\varphi$ is an additive homomorphism. 
                  \item \textbf{Multiplicativity of $\varphi$.} For an integer
                        $n$, let $P(n)$ be the statement that
                        $\varphi(m \times n) = \varphi(m)\times\varphi(n)$ for
                        every integer $m$. Now we will first show by induction 
                        on $n$ that $P(n)$ holds for all $n \ge 1$. So let
                        $m \in \Z$.
         
                        \textbf{Base Case.} $n = 1$. It follows that
                        $$\varphi(m \times 1) = \varphi(m) = m \cdot 1_R =
                          (m\cdot1_R) \times 1_R = \varphi(m)\times\varphi(1).$$
                        So $P(1)$ holds.
         
                        \textbf{Inductive Hypothesis.} Suppose $P(k)$ holds for 
                        some for some positive integer $k$. Now it follows that
                        \begin{align*}
                           \varphi(m \times (k+1)) &= \varphi(m \times k + m) \\
                              &= \varphi(m \times k) + \varphi(m)
                                 &[\varphi\text{ is an additive homomorphism}]\\
                              &= \varphi(m) \times \varphi(k) + \varphi(m)
                                 &[\text{Inductive Hypothesis}] \\
                              &= \varphi(m) \times (\varphi(k) + 1_R) \\
                              &= \varphi(m) \times (\varphi(k) + \varphi(1)) \\
                              &= \varphi(m) \times \varphi(k + 1),
                              &[\varphi \text{ is an additive homomorphism}] 
                        \end{align*}
                        and thus, $P(k + 1)$ holds. It follows by induction that 
                        $P(n)$ holds for every positive integer $n$; if $n$ is 
                        0, it follows that
                        $$\varphi(m \times 0) = \varphi(0) = 0 =
                          (m \cdot 1_R) \times 0 = \varphi(m)\times\varphi(0),$$
                        so that $P(0)$ holds. Now suppose that $n < 0$, so that 
                        $n = -t$ for some positive integer $t$. It follows that
                        \begin{align*}
                           \varphi(m \times n) &= \varphi(m \times -t) \\
                              &= \varphi(-(m \times t)) \\
                              &= -\varphi(m \times t)
                                 &[\text{Exercise 1.6.1(b)}] \\
                              &= -[\varphi(m)\times\varphi(t)]
                                 &[P(t) \text{ holds}] \\
                              &= \varphi(m) \times -\varphi(t) \\
                              &= \varphi(m) \times \varphi(-t)
                                 &[\text{Exercise 1.6.1(b)}] \\
                              &= \varphi(m) \times \varphi(n).
                        \end{align*}
                        It follows that $P(n)$ holds for every integer $n$, and 
                        we conclude that $\varphi$ is a ring homomorphism.
               \end{itemize}

               \textbf{Kernel of $\varphi$.} Let $K$ be the kernel of $\varphi$.
               If the characteristic of $R$ is 0, then no finite sum of $1_R$
               equals 0; thus the only integer that maps to $0 \in R$ is
               $0 \in \Z$, so that $K = 0\Z$; if, however, the characteristic of
               $R$ is $w \in \Z^+$. Then $w \in K$; indeed, by minimality, $w$
               is the smallest positive integer in $K$, so that $K = w\Z$. \qed
         \item The characteristics of the rings $\Q$, $\Z[x]$, and $\Z/n\Z[x]$ 
               are 0, 0, and $n$ respectively.
         \item \textbf{Proof.} Suppose $R$ is commutative with a prime 
               characteristic $p$. Let $a, b \in R$. Let $r$ be a positive 
               integer that is less than $p$. Since
               $$\binom{p}{r} = \frac{p(p-1)(p-2)\cdots(p-r+1)}{r!}$$
               is an integer, it follows that $r!$ divides
               $p(p-1)(p-2)\cdots(p-r+1)$. Now $\gcd(x, p) = 1$ for every
               positive integer $x \le r$ because $r < p$. Thus
               $\gcd(r!, p) = 1$, so that $r! \mid (p-1)(p-2)\cdots(p-r+1)$.
               Thus $p \mid \binom{p}{r}$, so that $\binom{p}{r} = pt$ for some
               integer $t$. Hence, using the notations from (a), we have
               \begin{align*}
                  \binom{p}{r} &= \underbrace{1_R + \cdots +
                        1_R}_{p \times t \text{ times}}
                           &[\text{Definition from Exercise 7.3.25}] \\
                     &= (p \times t) \cdot 1_R \\
                     &= \varphi(p \times t) =
                        \varphi(p)\times\varphi(t) = 0 \times t = 0.
               \end{align*}

               It follows by the Binomial Theorem (Exercise 7.3.25) that
               \begin{align*}
                  (a + b)^p &= \sum_{k=0}^p\binom{p}{k}a^kb^{p-k} \\
                     &= \binom{p}{0}a^0b^p + \binom{p}{1}ab^{p-1} + \cdots +
                        \binom{p}{p-1}a^{p-1}b + \binom{p}{p}a^pb^0 \\
                     &= a^p + b^p + \binom{p}{1}ab^{p-1} +
                        \binom{p}{2}a^2b^{p-2}\cdots +
                        \binom{p}{p-1}a^{p-1}b \\
                     &= a^p + b^p + 0 \times ab^{p-1} + 0 \times a^2b^{p-2}+ 
                        \cdots + 0 \times a^{p-1}b\\
                     &= a^p + b^p.
               \end{align*} \qed
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.27%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.27]  Prove that a nonzero Boolean ring has characteristic 2
                  (cf. Exericse 7.1.15).

      \textbf{Proof.} Let $R$ be a nonzero Boolean ring (i.e., the square of 
      every element in $R$ equals itself). Since $R$ is nonzero,
      it follows that $1 \neq 0$; thus
      $$1 + 1 = (1 + 1)(1 + 1) = 1(1 + 1) + 1(1 + 1) = 1 + 1 + 1 + 1,$$
      so that $1 + 1 = 0$. Thus the characteristic of $R$ is 2. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.28%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.28]  Prove that an integral domain has characteristic $p$, where
                  $p$ is either a prime or 0 (cf Exercise 7.3.26).

      \textbf{Proof.} Let $R$ be an integral domain with characteristic $p$ and
      suppose that $p \neq 0$. It suffices to show that $p$ is prime. Suppose to
      the contrary that $p$ is not prime. Then $p = rs$ for some positive 
      integers $r$ and $s$ such that $r < p$ and $s < p$. Consider the map
      $\varphi : \Z \rightarrow R$, where, for each $z \in \Z$, $\varphi$ is 
      defined as in Exercise 7.3.25. Thus $\varphi$ is a ring homomorphism by
      the same Exercise. Since $p$ is the characteristic of $R$, it 
      follows that
      $$0 = \varphi(p) = \varphi(rs) = \varphi(r)\varphi(s).$$
      But since $R$ is an integral we must then have that $\varphi(r) = 0$ or
      $\varphi(s) = 0$, both of which are contradictions because either
      statement says that the characteristic of $R$ is less than $p$. Hence $p$
      is a prime. \qed      
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.29%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.29]  Let $R$ be a commutative ring. Recall (cf. Exercise 7.1.13)
                  that an element $x \in R$ is nilpotent if $x^n = 0$ for some
                  $n \in \Z^+$. Prove that the set of nilpotent elements form an 
                  ideal---called the \textit{nilradical} of $R$ and denoted by
                  $\mathfrak{N}(R)$. [Use the Binomial Theorem to show
                  $\mathfrak{N}(R)$ is closed under addition.]

      \textbf{Proof.} First let us make the following observation: if $x \in R$
      is nilpotent, so that $x^r = 0$ for some $r \in \Z^+$, then $x^j = 0$ for
      all $j \ge r$; this is so because if $j \ge r$, then
      $$x^j = x^rx^{j-r} = 0 \cdot x^{j-r} = 0.$$
      Since $0^1 = 0$, it follows that $0 \in \mathfrak{N}(R)$. That is,
      $\mathfrak{N}(R)$ is nonempty. So let $a, b \in \mathfrak{N}(R)$. Thus
      $a^m = b^n = 0$ for some $m, n \in \Z^+$.
      \begin{itemize}
         \item \textbf{Closure under subtraction.} Let $c = -b$, so that
               $c^n = (-1 \cdot b)^n = (-1)^n \cdot b^n = 0$. By the Binomial 
               Theorem (Exercise 7.3.25), it follows that
               $$(a - b)^{m+n} = (a + c)^{m+n} =
                 \sum_{i=0}^{m+n}B(i)a^ic^{m+n-i},$$
               where $B(i) = \binom{m+n}{i}$. If $i \ge m$, then $a^i = 0$; if,
               however, $i < m$ then $m + n - i$ is greater than $n$, so that
               $c^{m+n-i} = 0$. In either case we have $B(i)a^ic^{m+n-i} = 0$
               for $0 \le i \le m + n$. Hence $(a - b)^{m+n} = 0$, so that
               $a - b \in \mathfrak{N}(R)$, and thus, $\mathfrak{N}(R)$ is
               closed under subtraction.
         \item \textbf{Closure under multiplication by $R$.} Let $r \in R$.
               Using the commutativity of $R$, we get
               $$(ra)^m = r^ma^m = r^m \cdot 0 = 0,$$
               so that $ra \in \mathfrak{N}(R)$, and thus, $\mathfrak{N}(R)$ is
               closed under multiplication by $R$.
      \end{itemize}
      Thus $\mathfrak{N}(R)$ is an ideal of $R$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.30%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.30]  Prove that if $R$ is a commutative ring and $\mathfrak{N}(R)$
                  is its nilradical (cf. the preceding exercise) then zero is
                  the only nilpotent element of $R/\mathfrak{N}(R)$ i.e., prove
                  that $\mathfrak{N}(R/\mathfrak{N}(R)) = 0$.

      \textbf{Proof.} Suppose $R$ is a commutative ring. Let
      $\overline{r} \in R/\mathfrak{N}(R)$ be nilpotent. Then there exists
      $m \in \Z^+$, so that
      $\overline{r^m} = \overline{r}^m = 0 = \mathfrak{N}(R)$. Thus
      $r^m \in \mathfrak{N}(R)$, so that $(r^m)^n = r^{mn} = 0$ for some
      $n \in \Z^+$; that is, $r \in \mathfrak{N}(R)$, so that
      $\overline{r} = 0$. It follows that $\mathfrak{N}(R/\mathfrak{N}(R)) = 0$.
      \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.31%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.31]  Prove that the elements $\left(\begin{tabular}{@{}cc@{}}
                     0 & 1 \\
                     0 & 0
                  \end{tabular}\right)$ and $\left(\begin{tabular}{@{}cc@{}}
                     0 & 0 \\
                     1 & 0
                  \end{tabular}\right)$ are nilpotent elements of $M_2(\Z)$
                  whose sum is not nilpotent (note that these two matrices do
                  not commute). Deduce that the set of nilpotent elements in the
                  noncommutative ring $M_2(\Z)$ is not an ideal.

      \textbf{Proof.} Let $A$ denote the first matrix and let $B$ denote the
      second matrix. It immediately follows that $A$ and $B$ are nilpotent
      elements of $M_2(\Z)$ because $A^2 = B^2 = 0$. The matrix $A + B$ is not
      nilpotent because $(A + B)^n$ is itself if $n$ is odd and the identity
      matrix if $n$ is even. Thus the set of nilpotent elements in $M_2(\Z)$ is
      not closed under addition, so that this set is not an ideal of $M_2(\Z)$.
      \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.32%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.32]  Let $\varphi : R \rightarrow S$ be a homomorphism of rings.
                  Prove that if $x$ is a nilpotent element of $R$ then
                  $\varphi(x)$ is nilpotent in $S$.

      \textbf{Proof.} Let $x$ be a nilpotent element of $R$. Thus $x^n = 0$ for
      some positive integer $n$. It follows immediately that $\varphi(x)$ is a
      nilpotent element of $S$ because
      $$\varphi(x)^n = \underbrace{\varphi(x) \cdots
        \varphi(x)}_{n\text{ times}} =
        \varphi(\underbrace{x \cdots x}_{n \text{ times}}) = \varphi(x^n) =
        \varphi(0) = 0.$$
      \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.33%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.33]  Assume $R$ is commutative. Let
                  $p(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots + a_1x + a_0$ be an
                  element of the polynomial ring $R[x]$.
                  \begin{enumerate}
                     \item Prove that $p(x)$ is unit in $R[x]$ if and only if
                           $a_0$ is a unit and $a_1, a_2, \ldots, a_n$ are
                           nilpotent in $R$. [See Exercise 7.1.14]
                     \item Prove that $p(x)$ is nilpotent in $R[x]$ if and only
                           if $a_0, a_1, \ldots, a_n$ are nilpotent elements of
                           $R$.
                  \end{enumerate}

      \textbf{Solution.}

      \begin{enumerate}
         \item \textbf{Proof.}

               ($\Leftarrow$) Suppose $a_0$ is a unit and
               $a_1, a_2, \ldots, a_n$ are nilpotent in $R$. Observe that if
               $b \in R$ is nilpotent (so that $b^m = 0$ for some $m \in \Z^+$)
               then $bx^i \in R[x]$ is nilpotent for all $i \ge 0$; this is so
               because $(bx^i)^m = b^mx^{im} = 0 \cdot x^{im} = 0$ for all
               $i \ge 0$. Thus $a_1x, a_2x^2, \ldots, a_nx^n$ are all nilpotents 
               in $R[x]$. By Exercise 7.3.29, it follows that
               $a_1x+a_2x^2+\cdots+a_nx^n$ is also a nilopent element of $R[x]$. 
               Conclude by Exercise 7.1.14 that
               $p(x) = a_0 + (a_1x+a_2x^2+\cdots+a_nx^n)$ is a unit in $R[x]$.

               ($\Rightarrow$) Suppose that $p(x)$ is a unit in $R[x]$; let
               $P(i)$ be the statement: if $r(x) = \sum_{j=0}^ir_jx^j \in R[x]$ 
               is a unit, then $r_0$ is a unit and $r_1, \ldots, r_i$ are 
               nilpotent in $R$. Now we will show by induction on $i$ that
               $P(i)$ holds for $i \ge 0$.
               
               \begin{itemize}
                  \item \textbf{base case:} $i = 0$. Suppose that $r(x)$ is a
                        unit in $R[x]$ of degree 0; i.e., $r(x) = r_0$
                        for some unit $r_0 \in R$, so that $P(0)$ holds.
                  \item \textbf{inductive hypothesis:} For some nonnegative $k$
                        suppose that $P(i)$ holds for $0 \le i \le k$.
               \end{itemize}
               Now suppose that $r(x) = \sum_{j=0}^{k+1}r_jx^j \in R[x]$ is a
               unit in $R[x]$ of degree $k+1$. Let
               $q(x) = \sum_{j=0}^{m}q_jx^j \in R[x]$ be the inverse of $r(x)$.
               It follows by the definition of multiplication that
               $$1 = r(x)q(x) = \sum_{w=0}^{k+1+m}\left(
                 \sum_{t=0}^wr_tq_{w-t}\right)x^w.$$
               Use the equation above to equate corresponding  coefficients; \\

               coefficient of $x^{k+1+m}$:
               $$r_{k+1}q_m = 0;$$

               coefficient of $x^{k+m}$:              
               $$r_kq_m + r_{k+1}q_{m-1} = 0;$$
               multiply the preceding equation by $r_{k+1}$ and use the first
               equation to conclude that ${r_{k+1}}^2q_{m-1} = 0$; \\

               coefficient of $x^{k+m-1}$:
               $$r_{k-1}q_m + r_kq_{m-1} + r_{k+1}q_{m-2} = 0;$$
               multiply the preceding equation by ${r_{k+1}}^2$ and use the
               first two equations to conclude that ${r_{k+1}}^3q_{m-2} = 0$;
               inductively, it follows that ${r_{k+1}}^{m+1}q_{0} = 0$. Since
               $r_0q_0 = 1$, it follows that $r_0$ and $q_0$ are units in $R$;
               thus ${r_{k+1}}^{m+1}q_{0} = 0$ implies that
               ${r_{k+1}}^{m+1} = 0$, so that $r_{k+1}$ is a nilpotent in $R$,
               and thus, $r_{k+1}x^{k+1}$ is nilpotent in $R[x]$. It follows by
               Exercise 7.1.14(d) that
               $$r(x) - r_{k+1}x^{k+1} = r_kx^k + \cdots + r_1x + r_0$$
               is a unit in $R[x]$; thus the inductive hypothesis says that
               $r_k, r_{k-1}, \ldots, r_1$ are nilpotents in $R$. That is,
               $P(k+1)$ holds and we conclude that $P(i)$ holds for all
               $i \ge 0$. Particularly $P(n)$ holds; thus $a_0$ is a unit and
               $a_1, \ldots, a_n$ are nilpotent in $R$. \qed
         \item \textbf{Proof.}

               ($\Leftarrow$) Suppose that $p(x)$ is a unit in $R[x]$. Let
               $P(i)$ be the statement:
               \begin{quote}
                  if $r(x) = \sum_{j=0}^ir_jx^j$ is nilpotent in $R[x]$, then 
                  $r_0, \ldots, r_n$ are nilpotent in $R$.
               \end{quote}
               Now we will show by induction on $i$ that $P(i)$ holds for
               $i \ge 0$.
               
               \begin{itemize}
                  \item \textbf{base case:} $i = 0$. This follows trivially, so
                        $P(0)$ holds.
                  \item \textbf{inductive hypothesis:} For some nonnegative $k$
                        suppose that $P(i)$ holds for $0 \le i \le k$.
               \end{itemize}
               Now suppose that $r(x) = \sum_{j=0}^{k+1}r_jx^j$ is nilpotent in 
               $R[x]$. Thus $(r(x))^m = 0$ for some $m \in \Z^+$; that is,
               ${r_{k+1}}^m = 0$, so that $r_{k+1}$ (resp. $r_{k+1}x^{k+1}$) is
               nilpotent in $R$ (resp. $R[x]$). Exercise 7.3.29 says that
               $$r(x) - r_{k+1}x^{k+1} = r_kx^k + \cdots + r_1x + r_0$$
               is nilpotent. Thus $r_k, \ldots, r_1, r_0$ are nilpoent in $R$ by
               the inductive hypothesis. That is, $P(k+1)$ holds, and we
               conclude by induction that $P(i)$ holds for every $i \ge 0$.
               Particularly $P(n)$ holds; i.e., $a_0, \ldots, a_n$ are nilpotent
               in $R$.

               ($\Rightarrow$) If $a_0, \ldots, a_n$ are nilpotent in $R$, then
               $a_0, a_1x, \ldots, a_nx^n$ are nilpotent in $R[x]$; Exercise 
               7.3.29 says that the sum of nilpotent elements is also nilpotent.
               Thus $p(x)$ is nilpotent in $R[x]$. \qed
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.34%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.34]  Let $I$ and $J$ be ideals of $R$.
                  \begin{enumerate}
                     \item Prove that $I + J$ is the smallest ideal of $R$
                           containing both $I$ and $J$.
                     \item Prove that $IJ$ is an ideal contained in $I \cap J$.
                     \item Give an example where $IJ \neq I \cap J$.
                     \item Prove that if $R$ is commutative and if $I + J = R$
                           then $IJ = I \cap J$.
                  \end{enumerate}

      \textbf{Solution.}

      \begin{enumerate}
         \item \textbf{Proof.} Let $K$ be an ideal of $R$ containing $I$ and
               $J$ (there is at least one, namely $R$). Let $a \in I + J$. Then
               $a = i + j$ for some $i \in I$ and $j \in J$. Since
               $I \subseteq K$ and $J \subseteq K$, we have $i, j \in K$.
               Conclude by the closure of $K$ that $a = i + j \in K$. Thus
               $I + J \subseteq K$, so that $I + J$ is contained in every ideal
               of $R$ that contains $I$ and $J$. That is, $I + J$ is the 
               smallest ideal of $R$ containing both $I$ and $J$. \qed
         \item \textbf{Proof.} The set $IJ$ is nonempty because $0 \in I$ and
               $0 \in J$, so that $0 \cdot 0 = 0 \in IJ$. So let $a, b \in IJ$. 
               Then there exist $m, n \in \Z^+$ such that
               $$a = i_1j_1 + \cdots + i_nj_n \text{ and }
                 b = i_1'j_1' + \cdots + i_m'j_m'$$
               where $i_k \in I, j_k \in J$, with $1 \le k \le n$ and
               $i_k' \in I, j_k' \in J$, with $1 \le k \le m$. First we will
               show that $IJ$ is an ideal of $R$.

               \begin{itemize}
                  \item \textbf{closure under subtraction.} Since $I$ is
                        closed under additive inverses, we have that
                        $-i_k' \in I$ for $1 \le k \le m$. It follows that
                        $$a - b = i_1j_1 + \cdots + i_nj_n +
                          (-i_1')j_1' + \cdots + (-i_m')j_m' \in IJ$$
                        by the definition of $IJ$. Thus $IJ$ is closed under
                        subtraction.
                  \item \textbf{closure under multiplication by $R$.} Let
                        $r \in R$. Since $I$ is closed under left multiplication
                        and $J$ is closed under right multiplication by $R$, it
                        follows that
                        $$ra = (ri_1)j_1 + \cdots + (ri_n)j_n \in IJ
                          \text{ and } ar = i_1(j_1r) + \cdots +
                          i_n(j_nr) \in IJ,$$
                        so that $IJ$ is closed under multiplication by $R$.
               \end{itemize}
               Thus $IJ$ is an ideal of $R$. Now since $I$ is closed under
               addition and right multiplication by $R$, it follows that
               $a \in I$; similarly, $a \in J$ because $J$ is closed under
               addition and left multiplication by $R$. Thus $a \in I \cap J$,
               and we conclude that $IJ \subseteq I \cap J$. \qed
         \item \textbf{Example.} Let $R = \Z$ and $I = J = 2\Z$. We have
               $$4\Z = IJ \neq 2\Z = I \cap J.$$
         \item Suppose that $R$ is commutative. We already showed in (b) that
               $IJ \subseteq I \cap J$, so it suffices to show containment in
               the other direction. So let $x \in I cap J$. Since $I + J = R$
               and $1 \in R$, it follows that $i + j = 1$ for some $i \in I$ and
               $j \in J$. Thus $x(i + j) = x \cdot $ so that $xi + xj = x$.
               Since $R$ is commutative, it follows that $ix + xj = x$. Now
               $ix \in IJ$ because $i \in I$ and $x \in J$; similarly,
               $xj \in IJ$ because $x \in I$ and $j \in J$. Thus
               $x = ix + xj \in IJ$ so that $I \cap J \subseteq IJ$. That is,
               $I \cap J = IJ$.

               \qed
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.35%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.35]  Let $I, J, K$ be ideals of $R$.
                  \begin{enumerate}
                     \item Prove that $I(J + K) = IJ + IK$ and
                           $(I + J)K = IK + JK$.
                     \item Prove that if $J \subseteq I$ then
                           $I \cap (J + K) = J + (I \cap K)$.
                  \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.36%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.36]  Show that if $I$ is the ideal of all polynomials in $\Z[x]$
                  with zero constant term then $I^n = \{a_nx^n + a_{n+1}x^{n+1} 
                  + \cdots + a_{n+m}x^{n+m} : a_i \in \Z, m \ge 0\}$ is the set
                  of polynomials whose first nonzero term has degree at least
                  $n$.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.3.37%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.3.37]  An ideal $N$ is called $\textit{nilpotent}$ if $N^n$ is the
                  zero ideal for some $n \ge 1$. Prove that the ideal
                  $p\Z/p^m\Z$ is a nilpotent ideal in the ring $\Z/p^m\Z$.
\end{enumerate}
