% Haven't Finished 7.2.3(a)

Let $R$ be a commutative ring with 1.
\begin{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.2.1%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.2.1]   Let $p(x) = 2x^3 - 3x^2 + 4x - 5$ and let
                  $q(x) = 7x^3 + 33x - 4$. In each of parts (a), (b), and (c)
                  compute $p(x) + q(x)$ and $p(x)q(x)$ under the assumption that
                  the coefficients of the two given polynomials are taken from
                  the specified ring (where the integer coefficients are taken
                  mod $n$ in parts (b) and (c)):
                  
                  (\textbf{a}) $R = \Z$, \quad (\textbf{b}) $R = \Z/2\Z$, \quad
                  (\textbf{c}) $R = \Z/3\Z$.

      \textbf{Solution.}
   
      \begin{enumerate} 
         \item\begin{IEEEeqnarray*}{lCl} 
                  p(x) + q(x) &=& (2x^3 - 3x^2 + 4x - 5) + (7x^3 + 33x - 4)  \\
                              &=& 9x^3 - 3x^2 + 37x - 9, \text{ and } \\
                  p(x)q(x)    &=& (2x^3 - 3x^2 + 4x - 5)(7x^3 + 33x - 4) \\
                              &=& 2x^3(7x^3 + 33x - 4) - 3x^2(7x^3 + 33x - 4) \\
                                && + \: 4x (7x^3 + 33x - 4) -5(7x^3 +33x - 4) \\
                              &=& 14x^6 + 66x^4 - 8x^3 - 21x^5 - 99x^3 +12x^2 \\
                                && + \: 28x^4 + 132x^2 - 16x-35x^3 - 165x+ 20 \\
                              &=& 14x^6 - 21x^5 + 94x^4 - 142x^3 + 144x^2 - 181x
                                 + 20.
               \end{IEEEeqnarray*}
         \item \begin{align*}
                  p(x) + q(x) &= (2x^3 - 3x^2 + 4x - 5) + (7x^3 + 33x - 4)  \\
                     &= (x^2 + 1) + (x^3 + x) \\
                     &= x^3 + x^2 + x + 1, \text{ and } \\
                  p(x)q(x) &= (2x^3 - 3x^2 + 4x - 5) + (7x^3 + 33x - 4) \\
                           &= (x^2 + 1)(x^3 + x) \\
                           &= x^5 + x^3 + x^3 + x \\
                           &= x^5 + x.
               \end{align*}
         \item \begin{align*}
                  p(x) + q(x) &= (2x^3 - 3x^2 + 4x - 5) + (7x^3 + 33x - 4)  \\
                     &= (2x^3 + x + 1) + (x^3 + 2) \\
                     &= x, \text{ and } \\
                  p(x)q(x) &= (2x^3 - 3x^2 + 4x - 5) + (7x^3 + 33x - 4) \\
                           &= (2x^3 + x + 1) + (x^3 + 2) \\
                           &= 2x^3(x^3 + 2) + x(x^3 + 2) + 1(x^3 + 2)  \\
                           &= 2x^6 + x^3 + x^4 + 2x + x^3 + 2 \\
                           &= 2x^6 + 2x^3 + x^4 + 2x + 2.
               \end{align*}
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.2.2%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.2.2]   Let $p(x) = a_nx^n + a_{n-1}x^{n-1}+\cdots+a_1x+a_0$ be an
                  element of the polynomial ring $R[x]$. Prove that $p(x)$ is a
                  zero divisor in $R[x]$ if and only if there is a nonzero 
                  $b \in R$ such that $bp(x) = 0$. [Let $g(x) = b_mx^m +
                  b_{m-1}x^{m-1} + \cdots + b_0$ be a nonzero polynomial of
                  minimal degree such that $g(x)p(x) = 0$. Show that
                  $b_ma_n = 0$ and so $a_ng(x)$ is a polynomial of degree less
                  than $m$ that also gives 0 when multiplied by $p(x)$. Conclude
                  that $a_ng(x) = 0$. Apply a similar argument to show by
                  induction on $i$ that $a_{n-i}g(x) = 0$ for
                  $i = 0, 1, \ldots, n$, and show that this implies
                  $b_mp(x) = 0$.]

      \textbf{Proof.} ($\Rightarrow$) Let $S$ be the set of degrees of nonzero
      polynomials $h(x) \in R[x]$ such that $p(x)h(x) = 0$. The set $S$ is
      nonempty because $p(x)$ is a zero divisor; thus $S$ has a minimum element
      by the Well Ordering Principle. Let
      $$g(x) = b_mx^m + b_{m-1}x^{m-1} + \cdots + b_0 \in R[x]$$
      such that degree$(g(x)) = m = \min(S)$. We now want to show by induction
      on $i$ that $a_{n-i}g(x) = 0$ for each nonnegative integer $i$, where
      $a_t$ is defined to be 0 for each negative integer $t$. For a nonnegative
      integer $i$, let $P(i)$ denote the statement: $a_{n-i}g(x) = 0$.

      \textbf{Base Case.} $i = 0$. Since $p(x)g(x) = 0$, it follows that the
      coefficients of $p(x)g(x)$ are all zero; particularly, we have that
      $a_nb_m = 0$; if $a_ng(x) \neq 0$, then $a_ng(x) \in S$ because
      $a_ng(x)p(x) = 0$, a contradiction because
      $\text{degree}(a_ng(x)) < \text{degree}(g(x)) = \min(S)$.
      Thus $a_ng(x) = 0$, so that $P(0)$ holds.

      \textbf{Inductive Hypothesis.} Assume that $P(0), P(1), \ldots, P(j-1)$
      are true for some positive integer $j$. We want to show that $P(j)$ holds.
      Observe that if $j \ge n + 1$, then $a_{n - j} = 0$ since $n - j < 0$, so
      that $P(j)$ holds. Hence we can assume that $1 \le j \le n$. The inductive
      hypothesis tells us that $a_{n-i}g(x) = 0$ so that
      \begin{equation} \label{7_2_2_1}
         a_{n-i}b_m = a_{n-i}b_{m-1} = \cdots = a_{n-i}b_0 = 0
      \end{equation}
      for $i = 0, 1, \ldots, j - 1$. The coefficient of $x^{m+j}$ in $p(x)g(x)$
      is
      \begin{equation*}
         \left\{
            \begin{array}{lcl}
               b_ma_j + b_{m-1}a_{j+1} + \cdots + b_{m-n+j}a_n &= 0 & \text{if }
                  m + j \ge n,\\
               b_ma_j + b_{m-1}a_{j+1} + \cdots + b_0a_{m+j} &= 0 & \text{if }
                  m + j < n
            \end{array} \right.
      \end{equation*}
      It follows by \eqref{7_2_2_1} that $b_ma_j = 0$, so that $a_jg(x)$ is a
      polynomial in $R[x]$ of degree less than $\min(S)$. The minimality of
      $\min(S)$ tells us that $a_jg(x) = 0$ (since otherwise $a_jg(x)$ would be
      a member of $S$ contradicting the minimality of $\min(S)$); i.e., $P(j)$
      holds. It follow by induction that $P(i)$ holds for every nonnegative
      integer $i$. Particularly, we have that $P(0), \ldots, P(n)$ hold so
      that $a_ng(x) = a_{n-1}g(x) = \cdots = a_0g(x) = 0$; i.e.,
      $$a_{n}b_m = a_{n-1}b_m = \cdots = a_{0}b_m = 0,$$
      and thus
      $b_mp(x) = 0$. Since $\text{degree}(g(x)) = m$, it follows that
      $b_m \neq 0$.

      $(\Leftarrow)$ This follows from the definition of a zero divisor. \qed      
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.2.3%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.2.3]   Define the set $R[[x]]$ of \textit{formal power series} in the
                  indeterminate $x$ with coefficients from $R$ to be all formal
                  infinite sums
                  $$\sum_{n=0}^\infty a_nx^n = a_0 + a_1x +
                       a_2x^2 + a_3x^3 + \cdots.$$
                  Define addition and multiplication of power series in the same
                  way as for power series with real or complex coefficients
                  i.e., extend polynomial addition and multiplication to power
                  series as though they were ``polynomials of infinite degree":
                  \begin{align*}
                     \sum_{n=0}^\infty a_nx^n + \sum_{n=0}^\infty b_nx^n &=
                        \sum_{n=0}^\infty (a_n + b_n)x^n \\
                     \sum_{n=0}^\infty a_nx^n \times \sum_{n=0}^\infty b_nx^n &=
                        \sum_{n=0}^\infty\left(\sum_{k=0}^na_kb_{n-k}\right)x^n. 
                  \end{align*}
                  (The term ``formal" is used here to indicate that convergence
                  is not considered, so that formal power series need not
                  represent functions on $R$.)
                  \begin{enumerate}
                     \item Prove that $R[[x]]$ is a commutative ring with 1.
                     \item Show that $1- x$ is a unit in $R[[x]]$ with inverse
                           $1 + x + x^2 + \cdots$.
                     \item Prove that $\sum_{n=0}^\infty a_nx^n$ is a unit in
                           $R[[x]]$ if and only if $a_0$ is a unit in $R$.
                  \end{enumerate}

      \textbf{Solution.}

      \begin{enumerate}
         \item \textbf{Proof.} Let $a = \sum_{n=0}^\infty a_nx^n$,
               $b = \sum_{n=0}^\infty b_nx^n$, and
               $c = \sum_{n=0}^\infty c_nx^n \in R[[x]]$.

               ($R[[x]]$ is an additive abelian group.) Closure and asociativity
               of addition follows because $R$ is closed and associative under
               addition. The 0 of $R$ is also the 0 of $R[[x]]$; the additive
               inverse of a sum is the resulting sum wherein the coefficients of
               the original sum have been replaced with their additive inverses
               in $R$. Thus $(R[[x]], +)$ is an additive abelian group.

               ($R[[x]]$ is closed under multiplication.) This follows from the
               closure of $R$ under multiplication.

               ($R[[x]]$ is commutative.) We have that
               \begin{align*}
                  a \times b &= \sum_{n=0}^\infty a_nx^n \times
                     \sum_{n=0}^\infty b_nx^n \\
                    &= \sum_{n=0}^\infty\left(
                       \sum_{k=0}^na_kb_{n-k}\right)x^n \\
                    &= \sum_{n=0}^\infty\left(\sum_{k=0}^nb_{n-k}a_k\right)x^n
                       &[R \text{ is commutative}] \\
                    &= \sum_{n=0}^\infty\left(\sum_{i=n}^0b_ia_{n-i}\right)x^n\\
                    &= \sum_{n=0}^\infty\left(\sum_{i=0}^nb_ia_{n-i}\right)x^n\\
                    &= \sum_{n=0}^\infty b_nx^n\times\sum_{n=0}^\infty a_nx^n\\
                    &= b \times a.
               \end{align*}

               ($R[[x]]$ is associative under $\times$.) We have that
               \begin{align*}
                  (a \times b) \times c &= \left(\sum_{n=0}^\infty a_nx^n \times
                     \sum_{n=0}^\infty b_nx^n\right) \times
                     \sum_{n=0}^\infty c_nx^n \\
                    &= \sum_{n=0}^\infty\left(
                       \sum_{k=0}^na_kb_{n-k}\right)x^n \times
                       \sum_{n=0}^\infty c_nx^n \\
                    &= \sum_{n=0}^\infty\left(\sum_{k=0}^n\left(\sum_{i=0}^k
                        a_ib_{k-i}\right)c_{n-k}\right)x^n \\
                    &= \sum_{n=0}^\infty\left(\sum_{k=0}^n\left(\sum_{i=0}^k
                        a_{k-i}b_i\right)c_{n-k}\right)x^n \\
               \end{align*}
         \item \textbf{Proof.} Let $a = \sum_{n = 1}^\infty x^n \in R[[x]]$. The
               polynomial $1 - x$ is a unit in $R[[x]]$ because
               \begin{align*}
                  (1 - x)(1 + x + x^2 + \cdots) &= 1(1 + x + x^2 + \cdots) -
                     x(1 + x + x^2 + \cdots) \\
                     &= (1 + x + x^2 + \cdots) - (x + x^2 + x^3 + \cdots) \\
                     &= (1 + a) - a = 1.
               \end{align*} \qed
         \item \textbf{Proof.} Let $a = \sum_{n = 0}^\infty a_nx^n \in R[[x]]$.

               $(\Leftarrow)$ Suppose $a_0$ is a unit in $R$. Consider the
               element $b = \sum_{n = 0}^\infty b_nx^n \in R[[x]]$, where
               $b_0 = a_0^{-1}$ and $b_i = -(a_ib_0 + a_{i-1}b_1 + \cdots +
                a_1b_{i-1})a_0^{-1}$ for each $i \ge 1$. Thus the coefficient of
               $x^i$ in $ab$ is 0 for each $i \ge 1$ and the constant term in
               $ab$ is $a_0b_0 = 1$, so that $ab = 1$. Thus $a$ is a unit with
               inverse $b$.

               $(\Rightarrow)$ Now suppose conversely that $a$ is a unit in
               $R[[x]]$. Thus there exists
               $c = \sum_{n = 0}^\infty c_nx^n \in R[[x]]$ such that $ac = 1$.
               Particularly we have that $a_0c_0 = 1$, so that $a_0$ is a unit
               in $R$.\qed
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.2.4%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.2.4]   Prove that if $R$ is an integral domain then the ring of
                  formal power series $R[[x]]$ is also an integral domain.

      \textbf{Proof.} Suppose $R$ is an integral domain. Let
      $$a = a_0 + a_1x + a_2x^2 + \cdots \text{ and }
        b = b_0 + b_1x + b_2x^2 + \cdots$$
      be nonzero elements in $R[[x]]$. Let $a_i$ and $b_j$ be the smallest
      nonnegative integers $i$ and $j$ such that $a_i$ and $b_j$ are both
      nonzero. The coefficient of $x^{i + j}$ in the product $ab$ is
      $$a_{i + j}b_0 + a_{i + j- 1}b_1 + \cdots + a_{i + 1}b_{j - 1} + a_ib_j +
        a_{i - 1}b_{j + 1} + \cdots + a_0b_{i + j}.$$
      By minimality of $a_i$ and $a_j$, it follows that
      $$b_0 = b_1 = \cdots = b_{j - 1} = a_{i - 1} = \cdots = a_0 = 0,$$
      so that the coefficient of $x^{i + j}$ in $ab$ is $a_ib_j$. Since $a_i$
      and $b_j$ are both nonzero elements of the integral domain $R$, it follows
      that $a_ib_j \neq 0$, so that $ab \neq 0$; thus $R[[x]]$ is an integral
      domain. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.2.5%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.2.5]   Let $F$ be a field and define the ring $F((x))$ of
                  \textit{formal Laurent series} with coefficients from $F$ by
                  $$F((x)) = \left\{\sum_{n \ge N}^\infty a_nx^n : a_n \in F
                    \text{ and } N \in \Z\right\}.$$
                  (Every element of $F((x))$ is a power series in $x$ plus
                  polynomial in $1/x$, i.e., each element of $F((x))$ has only a
                  finite number of terms with negative powers of $x$.)
                  \begin{enumerate}
                     \item Prove that $F((x))$ is a field.
                     \item Define the map
                           $$\nu : F((x))^\times \rightarrow \Z \quad\text{ by }
                             \quad\nu\left(\sum_{n \ge N}^\infty
                              a_nx^n\right) = N$$
                           where $a_N$ is the first nonzero coefficient of the
                           series (i.e., $N$ is the ``order of zero or pole of
                           the series at 0"). Prove that $\nu$ is a discrete
                           valuation on $F((x))$ whose discrete valuation ring
                           is $F[[x]]$, the ring of formal power series
                           (cf. Exercise 7.1.26).
                  \end{enumerate}

      \textbf{Solution.}

      \begin{enumerate}
         \item \textbf{Proof.} Let $a \in F((x))$ be a nonzero element; thus,
               there exists an integer $M$ such that
               $a = \sum_{n \ge M}^\infty a_nx^n$, where $M$ is the smallest
               integer such that $a_M \neq 0$. That is, $a_M$ is a unit in $F$,
               so that $b = \sum_{n=0}^\infty a_{M+n}x^n$ is a unit by Exercise
               7.2.3(c). But $a = x^Mb$, so that $x^{-M}b^{-1}$ is the inverse
               of $a$, and thus, $a$ is a unit in $F((x))$. We conclude that
               $F((x))$ is a field. \qed
         \item \textbf{Proof.}

               \textit{$\nu$ is a discrete valuation}.

               \begin{itemize}
                  \item \textit{$\nu$ is a homomorphism}. Let
                        $a = \sum_{n \ge M}^\infty a_nx^n,
                         b = \sum_{n \ge N}^\infty b_nx^n \in F((x))^\times$,
                        where $N$ and $M$ are the order of zero of $a$ and $b$.
                        The coefficient of $x^{M+N}$ in $ab$ is $a_Mb_N$, a
                        nonzero element of $F$ because $a_M \neq 0$ and
                        $b_N \neq 0$. Consider an integer $i < M + N$.
                        The coefficient of $x^i$ in $ab$ is
                        $$\sum_{r+s=i}a_rb_s = \sum_{r\in\Z}a_rb_{i-r} =
                          \sum_{r=M}^\infty a_rb_{i-r}.$$
                        Now consider $b_{i - r}$ for some $r \ge M$. The
                        inequality $r \ge M$ implies that $i - r \le i - M$, and
                        since $i < M + N$ by assumption, it follows that
                        $i - r \le i - M < N$. Thus $b_{i - r} = 0$ since
                        $b_j = 0$ for all $j < N$. It follows that the
                        coefficient of $x^i$ is 0 for all $i < M + N$. Thus the
                        order of zero of $ab$ is $N + M$. Hence
                        $$\nu(ab) = M + N = \nu(a) + \nu(b),$$
                        so that $\nu$ is a homorphism.
                  \item \textit{$\nu$ is surjective}. For $z \in Z$, we have
                        that
                        $$\nu\left(\sum_{n \ge z}^\infty x^n\right) = z,$$
                        so that $\nu$ is onto.
                  \item $\nu(a + b) \ge \min\{\nu(a), \nu(b)$\}, $a + b \neq 0$,
                        \textit{ and } $a, b \in F((x))$. Let
                        $$a = \sum_{n \ge M}^\infty a_nx^n \text{ and }
                         b = \sum_{n \ge N}^\infty b_nx^n \in F((x))^\times,$$
                        where $a + b \neq 0$. We have $\nu(a) = N$ and
                        $\nu(b) = M$. Assume without loss of generality that
                        $M \le N$, so that $a_i = b_i$ for every $i < M$; i.e.,
                        $a_i + b_i = 0$ for every $i < M$, so that the order of
                        zero of $a + b$ is at least $M$; in order words
                        $$\nu(a + b) \ge M = \{\nu(a), \nu(b)\}.$$
               \end{itemize}
               The above shows that $\nu$ is a discrete valuation on $F((x))$.
               Let $R$ be the discrete valuation ring of $\nu$. Since the order
               of zero of every nonzero formal power series in $F[[x]]$ is at
               least 0 and since $0 \in F[[x]]$, it follows that
               $F[[x]] \subseteq R$. Conversely, the order of zero of every
               nonzero formal Laurent series in $R$ is at least 0, so that every
               nonzero Laurent series in $R$ is a power series. It follows that
               $F[[x]] \supseteq R$ and we conclude that $R = F[[x]]$. \qed
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.2.6%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.2.6]   Let $S$ be a ring with identity $1 \neq 0$. Let $n \in \Z^+$ 
                  and let $A$ be an $n \times n$ matrix with entries from $S$
                  whose $i, j$ entry is $a_{ij}$. Let $E_{ij}$ be the element of
                  $M_n(S)$ whose $i, j$ entry is 1 and whose other entries are
                  all 0.
                  \begin{enumerate}
                     \item Prove that $E_{ij}A$ is the matrix whose
                           $i^{\text{th}}$ row equals the $j^{\text{th}}$ row of
                           $A$ and all other rows are zero.
                     \item Prove that $AE_{ij}$ is the matrix whose
                           $j^{\text{th}}$ column equals the $i^{\text{th}}$
                           column of $A$ and all other columns are zero.
                     \item Deduce that $E_{pq}AE_{rs}$ is the matrix whose
                           $p, s$ entry is $a_{qr}$ and all other entries are
                           zero.
                  \end{enumerate}

      \textbf{Proof.} Fix positive integers $i$, $j$, $p$, $q$, $r$, and $s$.
      Now let $e_{lm}$ be the $l$, $m$ entry of $E_{ij}$.
      \begin{enumerate}
         \item Let $c_{lm}$ be the $l$, $m$ entry of $C = E_{ij}A$. To show that 
               the $i^{\text{th}}$ row of $C$ equals the $j^{\text{th}}$ row of
               $A$, it suffices to show that $c_{ik} = a_{jk}$ for
               $k = 1, 2, \ldots, n$, so consider $c_{ik}$,
               where $1 \le k \le n$. By definition of matrix multiplication, it 
               follows that
               \begin{align*}
                  c_{ik} &= \sum_{t=1}^ne_{it}a_{tk} \\
                         &= e_{ij}a_{jk} &[e_{it} = 0 \text{ if } t \neq j] \\
                         &= 1 \cdot a_{jk} = a_{jk}.
               \end{align*}
               That is, the $i^{\text{th}}$ row of $C$ equals the
               $j^{\text{th}}$ row of $A$. Now consider $c_{lk}$, where
               $l, k \in \{1, 2, \ldots, n\}$ and $l \neq i$. Then it follows
               that
               \begin{align*}
                  c_{lk} &= \sum_{t=1}^ne_{lt}a_{tk} \\
                         &= \sum_{t=1}^n0 \cdot a_{tk} &[\text{Since }e_{lk} = 0
                            \text{ if } l \neq i] \\
                         &= 0.
               \end{align*}
               Our last result says that every entry of $C$ not in the
               $i^{\text{th}}$ row is 0; thus every other row of $C$ save for
               the $i^{\text{th}}$ row is 0.
         \item Let $d_{lm}$ be the $l$, $m$ entry of $D = AE_{ij}$. To show that 
               the $j^{\text{th}}$ column of $D$ equals the $i^{\text{th}}$
               column of $A$, it suffices to show that $d_{kj} = a_{ki}$ for
               $k = 1, 2, \ldots, n$, so consider $d_{kj}$,
               where $1 \le k \le n$. By definition of matrix multiplication, it 
               follows that
               \begin{align*}
                  d_{kj} &= \sum_{t=1}^na_{kt}e_{tj} \\
                         &= a_{ki}e_{ij} &[e_{tj} = 0 \text{ if } t \neq i] \\
                         &= a_{ki} \cdot 1 = a_{ki}.
               \end{align*}
               That is, the $j^{\text{th}}$ column of $D$ equals the
               $i^{\text{th}}$ column of $A$. Now consider $d_{kl}$, where
               $l, k \in \{1, 2, \ldots, n\}$ and $l \neq j$. Then it follows
               that
               \begin{align*}
                  d_{kl} &= \sum_{t=1}^na_{kt}e_{tl} \\
                         &= \sum_{t=1}^na_{kt} \cdot 0 &[e_{tl} = 0
                            \text{ if } l \neq j] \\
                         &= 0.
               \end{align*}
               Our last result says that every entry of $D$ not in the
               $j^{\text{th}}$ column is 0; thus every other column of $D$ save 
               for the $j^{\text{th}}$ column is 0.
         \item Let $X = E_{pq}A$, $Y = XE_{rs}$, $y_{lm}$ and $x_{lm}$ the $l$, 
               $m$ entries of $Y$ and $X$ respectively. By definition of 
               matrix multiplication, it follows that
               \begin{align*}
                  y_{ps} &= \sum_{t=1}^nx_{pt}e_{ts} \\
                     &= \sum_{t=1}^na_{qt}e_{ts} &[\text{By }(a)] \\
                     &= a_{qr}e_{rs} &[e_{ts} = 0 \text{ if } t \neq r] \\
                     &= a_{qr} \cdot 1 = a_{qr}. 
               \end{align*}
               Now consider $y_{lk}$, where $l, k \in \{1, 2, \cdots, n\}$ and
               $l \neq p$. It follows that
               \begin{align*}
                  y_{lk} &= \sum_{t=1}^nx_{lt}e_{tk} \\
                     &= \sum_{t=1}^n0 \cdot e_{tk} &[\text{By }(a)] \\
                     &= 0.
               \end{align*}
               If no restriction is placed on $l$ and $k \neq s$, it follows
               that
               \begin{align*}
                  y_{lk} &= \sum_{t=1}^nx_{lt}e_{tk} \\
                     &= \sum_{t=1}^nx_{lt} \cdot 0 &[e_{tk} = 0 \text{ if }
                        k \neq s] \\
                     &= 0,
               \end{align*}
               so that if $y_{lk}$ is an entry of $Y$, where $l \neq p$ or
               $k \neq s$, then $y_{lk} = 0$.
      \end{enumerate} \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.2.7%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.2.7]   Prove that the center of the ring $M_n(R)$ is the set of
                  scalar matrices (cf. Exercise 7.1.7). [Use the preceding
                  exercise.]

      \textbf{Proof.} Let $A = (a_{ij}), B \in M_n(R)$, where $A$ is a scalar
      matrix. Thus $A = aI_n$ for some $a \in A$ and $I_n$ the $n \times n$
      identity. It follows immediately that every scalar matrix in $M_n(R)$ is
      in the center of $M_n(R)$ because
      $$AB = (aI_n)B = aB = B(aI_n) = BA.$$
      Now suppose that $A$ is not a scalar matrix, so that $n \ge 2$. Let
      $E_{rs}$ be the element of $M_n(S)$ whose $r, s$ entry is 1 and whose
      other entries are all 0. Let us now investigate the following cases:

      \textbf{Case 1.} \textit{$A$ has a nonzero entry not on the diagonal}.
      Thus there exist unequal indices $p$ and $q$ such that $a_{pq} \neq 0$. By
      Exercise 7.2.6, the $q, q$ entry of $E_{qp}A$ is $a_{pq}$ while the $q, q$
      entry of $AE_{qp}$ is 0; since $a_{pq} \neq 0$, it follows that
      $E_{qp}A \neq AE_{qp}A$, so that $A$ is not in the center of $M_n(R)$.

      \textbf{Case 2.} \textit{$A$ has two unequal entries on its main
      diagonal}. So $a_{pp} \neq a_{qq}$ for some unequal indices $p$ and $q$.
      The $p, q$ entry of $E_{pq}A$ is $a_{qq}$ while the $p, q$ entry of
      $AE_{pq}$ is $a_{pp}$ and since $a_{pp} \neq a_{qq}$, it follows that
      $A$ does not commute with $E_{pq}$, so that $A$ is not in the center of
      $M_n(R)$.

      Thus it follows from above that the center of $M_n(R)$ is the set of all
      scalar matrices. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.2.8%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.2.8]   Let $S$ be any ring and let $n \ge 2$ be an integer. Prove
                  that if $A$ is any strictly upper triangular matrix in
                  $M_n(S)$ then $A^n = 0$ (a strictly upper triangular matrix is
                  one whose entries on and below the main diagonal are all
                  zero).

      \textbf{Proof.} Let $P(n)$ be the statement that the $n^{\text{th}}$ power
      of any strictly upper triangular matrix in $M_n(S)$ equals 0. We shall
      proceed by induction on $n$ to show for each $n \ge 2$, $P(n)$ holds.

      \textbf{Base Case.} $n = 2$. Let $A$ be any strictly upper triangular
      matrix in $M_2(S)$. That is, the $1, 2$ entry of $A$ is an arbitrary
      member of $S$ while every other entry is 0; thus $A^2 = 0$. So $P(2)$
      holds.

      \textbf{Inductive Hypothesis.} Suppose that $P(k)$ holds, where $k$ is
      some integer that is at least 2. Now let $B$ be any strictly upper
      triangular matrix in $M_{k+1}(S)$. Using block matrix notation, we can
      write
      $$B = \left(\begin{tabular}{@{}cc@{}}
         $B_1$ & $B_2$ \\
         0 & 0
      \end{tabular}\right),$$
      where $B_1$ is a $k \times k$ strictly upper triangular matrix, $B_2$ is a
      $k \times 1$ matrix, and (by abuse of notation) the bottom left 0 is the
      $1 \times k$ zero matrix while the bottom right 0 is the $1 \times 1$ zero
      matrix. Thus it follows that
      $$B^{k+1} = \left(\begin{tabular}{@{}cc@{}}
         $B_1^{k+1}$ & $B_1^kB_2$ \\
         0 & 0
      \end{tabular}\right).$$
      By the inductive hypothesis, we have that $B_1^k = 0$, so that
      $B_1^{k+1} = B_1^k \cdot B_1 = 0$. Thus $B^{k+1} = 0$, so that $P(k+1)$
      holds. Thus, it holds by Mathematical Induction that $P(n)$ holds for
      every integer $n \ge 2$. \qed      
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.2.9%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.2.9]   Let $\alpha = r + r^2 - 2s$ and $\beta = -3r^2 + rs$ be the
                  two elements of the integral group ring $\Z D_8$ described in
                  this section. Compute the following elements of $\Z D_8$:
                  
                  (\textbf{a}) $\beta\alpha$, \quad (\textbf{b}) $\alpha^2$,
                  \quad (\textbf{c}) $\alpha\beta - \beta\alpha$, \quad
                  (\textbf{d}) $\beta\alpha\beta$.

      \textbf{Solution.}

      \begin{enumerate}
         \item \begin{align*}
                  \beta\alpha &= (-3r^2 + rs)(r + r^2 - 2s) \\
                     &= -3r^2(r + r^2 - 2s) + rs(r + r^2 - 2s) \\
                     &= -3r^3 - 3 + 6r^2s + s + r^3s - 2r.
               \end{align*}
         \item \begin{align*}
                  \alpha^2 &= (r + r^2 - 2s)(r + r^2 - 2s) \\
                     &= r(r + r^2 - 2s) + r^2(r + r^2 -2s) - 2s(r + r^2 - 2s) \\
                     &= r^2 + r^3 - 2rs + r^3 + 1 - 2r^2s - 2r^3s - 2r^2s + 4 \\
                     &= 2r^3 + r^2 - 2rs - 4r^2s - 2r^3s + 5
               \end{align*}
         \item \begin{align*}
                  \alpha\beta &= (r + r^2 - 2s)(-3r^2 + rs) \\
                     &= r(-3r^2 + rs) + r^2(-3r^2 + rs) - 2s(-3r^2 + rs) \\
                     &= -3r^3 + r^2s - 3 + r^3s + 6r^2s - 2r^3 \\
                     &= -5r^3 + 7r^2s + r^3s - 3,
               \end{align*}
               so
               \begin{align*}
                  \alpha\beta - \beta\alpha &= (-5r^3 + 7r^2s + r^3s - 3) -
                     (-3r^3 - 3 + 6r^2s + s + r^3s - 2r) \\
                     &= -2r^3 + 2r + r^2s - s.
               \end{align*}
         \item \begin{align*}
                  \beta\alpha\beta &= (-3r^2 + rs)(-5r^3 + 7r^2s + r^3s - 3) \\
                     &= -3r^2(-5r^3 + 7r^2s + r^3s - 3) +
                           rs(-5r^3 + 7r^2s + r^3s - 3) \\
                     &= 15r - 21s - 3rs + 9r^2 - 5r^2s + 7r^3 + r^2 - 3rs \\
                     &= 7r^3 + 10r^2 + 15r - 5r^2s -6rs - 21s.
               \end{align*}
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.2.10%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.2.10]  Consider the following elements of the integral group ring
                  $\Z S_3$:
                  $$\alpha = 3(1\;2) - 5(2\;3) + 14(1\;2\;3) \text{ and }
                    \beta = 6(1) + 2(2\;3) - 7(1\;3\;2)$$
                  (where (1) is the identity of $S_3$). Compute the following
                  elements:
            
                  (\textbf{a}) $\alpha + \beta$, \quad
                  (\textbf{b}) $2\alpha - 3\beta$, \quad
                  (\textbf{c}) $\alpha\beta$, \quad
                  (\textbf{d}) $\beta\alpha$,
                  (\textbf{e}) $\alpha^2$.

      \textbf{Solution.}

      \begin{enumerate}
         \item \begin{align*}
                  \alpha + \beta &= 3(1\;2) - 5(2\;3) + 14(1\;2\;3) +
                     6(1) + 2(2\;3) - 7(1\;3\;2) \\
                     &= 6(1) + 3(1\;2) - 3(2\;3) + 14(1\;2\;3) - 7(1\;3\;2).
               \end{align*}
         \item \begin{align*}
                  2\alpha - 3\beta &= 6(1\;2) - 10(2\;3) + 28(1\;2\;3) -
                     18(1) - 6(2\;3) + 21(1\;3\;2) \\
                     &= -18(1) + 6(1\;2) - 16(2\;3) + 28(1\;2\;3) + 21(1\;3\;2).
               \end{align*}
         \item \begin{IEEEeqnarray*}{rCl}
                  \alpha\beta &=& (3(1\;2) - 5(2\;3) + 14(1\;2\;3))(6(1) +
                     2(2\;3) - 7(1\;3\;2)) \\
                  &=& 18(1\;2) + 6(1\;2\;3) - 21(1\;3) - 30(2\;3) - 10(1) + \\
                     && 35(1\;2) + 84(1\;2\;3) + 28(1\;2) - 98(1) \\
                  &=& -108(1) + 81(1\;2) - 21(1\;3) - 30(2\;3) + 90(1\;2\;3).
               \end{IEEEeqnarray*}
         \item \begin{IEEEeqnarray*}{rCl}
                  \beta\alpha &=& (6(1) + 2(2\;3) - 7(1\;3\;2))(3(1\;2) -
                     5(2\;3) + 14(1\;2\;3)) \\
                  &=& 18(1\;2) - 30(2\;3) + 84(1\;2\;3) + 6(1\;3\;2) - 10(1)+ \\
                     && 28(1\;3) - 21(2\;3) + 35(1\;3) - 98(1) \\
                  &=& -108(1) + 18(1\;2) + 63(1\;3) - 51(2\;3) + 84(1\;2\;3) +
                     6(1\;3\;2)
               \end{IEEEeqnarray*}
         \item \begin{IEEEeqnarray*}{rCl}
                  \alpha^2 &=& (3(1\;2) - 5(2\;3) + 14(1\;2\;3))(3(1\;2) -
                     5(2\;3) + 14(1\;2\;3)) \\
                  &=& 9(1) - 15(1\;2\;3) + 42(2\;3) - 15(1\;3\;2) + 25(1) - \\
                     && 70(1\;3) + 42(1\;3) - 70(1\;2\;3) + 196(1) \\
                  &=& 230(1) + 112(1\;3) + 42(2\;3) - 85(1\;2\;3) - 15(1\;3\;2).
               \end{IEEEeqnarray*}
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.2.11%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.2.11]  Repeat the preceding exercise under the assumption that the
                  coefficients of $\alpha$ and $\beta$ are in $\Z/3\Z$ (i.e.,
                  $\alpha$, $\beta \in \Z/3\Z S_3$).

      \textbf{Solution.}

      \begin{enumerate}
         \item $\alpha + \beta = 2(1\;2\;3) + 2(1\;3\;2)$.
         \item $2\alpha - 3\beta = 2(2\;3) + 1(1\;2\;3)$.
         \item $\alpha\beta = 0$.
         \item $\beta\alpha = 0$.
         \item $\alpha^2 = 2(1) + 1(1\;3) + 2(1\;2\;3)$.
      \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.2.12%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.2.12]  Let $G = \{g_1, \ldots, g_n\}$ be a finite group. Prove that
                  the element $N = g_1 + g_2 + \cdots + g_n$ is in the center of
                  the group ring $RG$ (cf. Exercise 7, Section 1).

      \textbf{Proof.} Assume without loss of generality that $g_1$ the identity
      of $G$. Let $I_n = \{1, 2, \ldots, n\}$. Consider the element $g_i$ for
      some $i \in I_n$. Recall that in the left (or right) action of $G$ on $G$
      by left (or right) multiplication, every element of $g \in G$ induces a
      permutation of $G$. Since the terms in $N$ are precisely the elements of
      $G$, it follows that premultiplying $N$ or postmultiplying $N$ by $g_i$
      has the effect of permuting(i.e., rearranging) the terms in $N$. Thus
      $g_iN = Ng_i = N$. Let $r \in R$. First observe that
      $$rg_i = (1r)(g_ig_1) = (1g_i)(rg_1) = g_ir,$$
      so that elements of $R$ in $RG$ commute with elements of $G$ in $RG$. Thus
      \begin{align*}
         (rg_i)N &= r(g_iN) \\
            &= r(Ng_i) \\
            &= (rN)g_i \\
            &= (r(g_1 + g_2 + \cdots + g_n))g_i \\
            &= (rg_1 + rg_2 + \cdots + rg_n)g_i \\
            &= (g_1r + g_2r + \cdots + g_nr)g_i \\
            &= (g_1 + g_2 + \cdots + g_n)rg_i = N(rg_i).
      \end{align*}
      That is, for each $i \in I_n$ and $r \in R$, $rg_i$ commutes with $N$. Now
      let $A \in RG$, so that $A = r_1g_1 + r_2g_2 + \cdots + r_ng_n$, where
      $r_j \in R$, for each $j \in I_n$. Since
      \begin{align*}
         AN &= (r_1g_1 + r_2g_2 + \cdots + r_ng_n)N \\
            &= (r_1g_1)N + (r_2g_2)N + \cdots + (r_ng_n)N \\
            &= N(r_1g_1) + N(r_2g_2) + \cdots + N(r_ng_n) \\
            &= N(r_1g_1 + r_2g_2 + \cdots + r_ng_n) \\
            &= NA,
      \end{align*}
      it follows that $N$ is in the center of $RG$. \qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%7.2.13%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   \item[7.2.13]  Let $\mathcal{K} = \{k_1, \ldots, k_m\}$ be a conjugacy class
                  in the finite group $G$.
                  \begin{enumerate}
                     \item Prove that the element $K = k_1 + \cdots + k_m$ is in
                           the center of the group ring $RG$
                           (cf. Exercise 7.1.7). [Check that $g^{-1}Kg = K$ for
                           all $g \in G$.]
                     \item Let $\mathcal{K}_1, \ldots, \mathcal{K}_r$ be the
                           conjugacy classes of $G$ and for each $\mathcal{K}_i$
                           let $K_i$ be the element of $RG$ that is the sum of
                           the members of $\mathcal{K}_i$. Prove that an element
                           $\alpha \in RG$ is in the center of $RG$ if and only
                           if $\alpha = a_1K_1 + a_2K_2 + \cdots + a_rK_r$ for
                           some $a_1, a_2, \ldots, a_r \in R$.
                  \end{enumerate}

      \textbf{Solution.} Let $G = \{g_1, \ldots, g_n\}$, where $g_1$ is the
      identity.

      \begin{enumerate}
         \item \textbf{Proof.} Consider the action of $G$ on $\mathcal{K}$ by
               conjugation. Thus each element of $G$ induces a permutation of
               $\mathcal{K}$. Since the terms in $K$ are precisely the elements
               of $\mathcal{K}$, it follows that conjugating $K$ by $g \in G$
               (i.e., $gKg^{-1}$) has the effect of permuting(i.e., rearranging)
               the terms in $K$. Thus $gKg^{-1} = K$, (that is, $gK = Kg$), so
               that $g$ commutes with $K$ for every $g \in G$. Let $A \in RG$,
               so that $A = r_1g_1 + \cdots + r_ng_n$, for some
               $r_1, \ldots, r_n \in R$. We shall use the fact that
               $r_jK = Kr_j$ for each $j = 1, 2, \ldots, n$ because, as proved
               in Exercise 7.2.12, each element of $R$ in $RG$ commutes with
               each element of $G$ in $RG$. So
               \begin{align*}
                  AK &= (r_1g_1 + \cdots + r_ng_n)K \\
                     &= r_1(g_1K) + \cdots + r_n(g_nK) \\
                     &= r_1(Kg_1) + \cdots + r_n(Kg_n) \\
                     &= (r_1K)g_1 + \cdots + (r_nK)g_n \\
                     &= (Kr_1)g_1 + \cdots + (Kr_n)g_n \\
                     &= K(r_1g_1) + \cdots + K(r_ng_n) \\
                     &= K(r_1g_1 + \cdots + r_ng_n) \\
                     &= KA,
               \end{align*}
               so that $K$ is in the center of $RG$. \qed
         \item \textbf{Proof.}

               ($\Leftarrow$) Suppose $\alpha = a_1K_1 + \cdots + a_rK_r$ for
               some $a_1, \ldots, a_r \in R$. Let $A \in RG$, so that
               $A = r_1g_1 + \cdots +r_ng_n$, for some $r_1, \ldots, r_n \in R$.
               By definition of multiplication in $RG$ and comutativity in $R$,
               it follows that $A$ commutes with $a_i$ for each
               $i = 1, 2, \ldots, r$. Thus $\alpha$ is in the center of $RG$
               because
               \begin{align*}
                  A\alpha &= A(a_1K_1 + \cdots + a_rK_r) \\
                     &= (Aa_1)K_1 + \cdots + (Aa_r)K_r \\
                     &= (a_1A)K_1 + \cdots + (a_rA)K_r \\
                     &= a_1(AK_1) + \cdots + a_r(AK_r) \\
                     &= a_1(K_1A) + \cdots + a_r(K_rA) &[\text{7.2.13(a)}]\\
                     &= (a_1K_1 + \cdots + a_rK_r)A \\
                     &= \alpha A,
               \end{align*}
               for every $A \in RG$.

               ($\Rightarrow$) Let
               $S = \{b_1K_1 + \cdots + b_rK_r : b_1, \ldots, b_r \in R\}$ and
               $\alpha \in RG$. Then
               $$\alpha = c_1g_1 + \cdots + c_ng_n, \text{ for some }
                  c_1, \ldots, c_n \in R.$$
               We shall instead prove the contrapositive of the forward
               direction. So suppose that $\alpha \notin S$. It suffices to show
               that $\alpha$ is not in the center of $RG$. Now if $G$ were
               abelian, then the conjugacy classes would be singletons so that
               $S = RG$; i.e., $\alpha \in S$, a contradiction. Thus $G$ must
               necesarily be nonabelian. Since $\alpha \notin S$, there exists
               two members of the same conjugacy class of $G$, say $g_2$ and
               $g_3$, such that their coefficients for $\alpha$ (taken from $R$)
               are unequal (i.e., $c_2 \neq c_3$). Note that we have used the
               fact that since $G$ is nonabelian, it has at least six elements
               and it has a conjugacy class with at least two elements. Since
               $g_2$ and $g_3$ are conjugates, it follows that
               $hg_2h^{-1} = g_3$ for some $h \in G$. Now recall that, under
               conjugation, $h$ induces a permutation of $G$; thus,
               $h\alpha h^{-1}$ has the effect of permuting the elements of $G$
               in $\alpha$. Now the coefficient of $g_3$ in $h\alpha h^{-1}$ is
               $c_2$; thus since $c_2 \neq c_3$, it follows that
               $h\alpha h^{-1} \neq \alpha$, so that $\alpha$ does not commute
               with $h$, and thus $\alpha$ is not in the center of $RG$. \qed
      \end{enumerate}
\end{enumerate}
